<meta http-equiv="Content-Type" content="text/html; charset= ">
<style type="text/css">body { margin-left:0;margin-right:0;margin-top:0; }#google-cache-hdr {background:#f5f5f5 !important;font:13px arial,sans-serif !important;text-align:left !important;color:#202020 !important;border:0 !important;margin:0 !important;border-bottom:1px solid #cecece !important;line-height:16px !important ;padding:16px 28px 24px 28px !important;}#google-cache-hdr * {display:inline !important;font:inherit !important;text-align:inherit !important;color:inherit !important;line-height:inherit !important;background:none !important;border:0 !important;margin:0 !important;padding:0 !important;letter-spacing:0 !important;}#google-cache-hdr a {text-decoration:none !important;color:#1a0dab !important;}#google-cache-hdr a:hover { text-decoration:underline !important; }#google-cache-hdr a:visited { color:#609 !important; }#google-cache-hdr div { display:block !important;margin-top:4px !important; }#google-cache-hdr b {font-weight:bold !important;display:inline-block !important;direction:ltr !important;}pre { word-wrap:break-word; }pre { white-space:pre-wrap; }</style><div id="google-cache-hdr"  dir=ltr><div>This is the html version of the file <a href="https://numenta.com/assets/pdf/whitepapers/hierarchical-temporal-memory-cortical-learning-algorithm-0.2.1-jp.pdf" dir="ltr">https://numenta.com/assets/pdf/whitepapers/hierarchical-temporal-memory-cortical-learning-algorithm-0.2.1-jp.pdf</a>.<br><b>Google</b> automatically generates html versions of documents as we crawl the web.</div></div><div style="position:relative;margin:8px;">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset= ">
<meta name="Author" content=" ">
<meta name="Creator" content="MicrosoftR Office Word 2007">
<meta name="CreationDate" content="D:20110125193756">
<meta name="ModDate" content="D:20110125193756">
<meta name="Producer" content="MicrosoftR Office Word 2007">
<title>HIERARCHICAL TEMPORAL MEMORY</title>
</head><body  bgcolor=#ffffff vlink="blue" link="blue">
<table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=1><b>Page 1</b></a></font></td></tr></table><font size=5 face="Times"><span style="font-size:37px;font-family:Times">
<div style="position:absolute;top:527;left:176"><nobr><b>H<font style="font-size:28px">IERARCHICAL </font>T<font style="font-size:28px">EMPORAL </font>M<font style="font-size:28px">EMORY</font></b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:588;left:420"><nobr><b>including</b></nobr></div>
</span></font>
<font size=4 face="Times"><span style="font-size:21px;font-family:Times">
<div style="position:absolute;top:626;left:265"><nobr><b>HTM Cortical Learning Algorithms</b></nobr></div>
<div style="position:absolute;top:896;left:289"><nobr><b>V<font style="font-size:16px">ERSION </font>0.2, D<font style="font-size:16px">ECEMBER </font>10, 2010</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:13px;font-family:Times">
<div style="position:absolute;top:940;left:383"><nobr><b>cNumenta, Inc. 2010</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:994;left:166"><nobr>Use of Numenta’s software and intellectual property, including the ideas contained in this</nobr></div>
<div style="position:absolute;top:1021;left:198"><nobr>document, are free for non-commercial research purposes. For details, see</nobr></div>
</span></font>
<font size=3 color="#0000ff" face="Times"><span style="font-size:12px;font-family:Times;color:#0000ff">
<div style="position:absolute;top:1048;left:256"><nobr><a href="http://www.numenta.com/software-overview/licensing.php">http://www.numenta.com/software-overview/licensing.php</a></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:19px;font-family:Times">
<div style="position:absolute;top:1141;left:281"><nobr>翻訳 株式会社アルトーク 2011/1/25</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:11px;font-family:Times">
<div style="position:absolute;top:1185;left:138"><nobr>出典: <a href="http://www.numenta.com/htm-overview/education/HTM_CorticalLearningAlgorithms.pdf"></a><font color="#0000ff"><a href="http://www.numenta.com/htm-overview/education/HTM_CorticalLearningAlgorithms.pdf">http://www.numenta.com/htm-overview/education/HTM_CorticalLearningAlgorithms.pdf</a></font></nobr></div>
<div style="position:absolute;top:1212;left:138"><nobr>脚注はすべて訳者による注釈である。本書の改訂版を確認するには <a href="http://ai.altalk.com/"></a><font color="#0000ff"><a href="http://ai.altalk.com/">http://ai.altalk.com </a></font>参照。 </nobr></div>
</span></font>

<div style="position:absolute;top:1437;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=2><b>Page 2</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:2619;left:442"><nobr><b>2</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:1651;left:128"><nobr><b>Numenta </b>翻訳ライセンス（参考和訳）</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:1699;left:128"><nobr>Copyright (c) 2010, 2011 Numenta, Inc.</nobr></div>
<div style="position:absolute;top:1753;left:128"><nobr>All rights reserved.</nobr></div>
<div style="position:absolute;top:1809;left:128"><nobr>ここに含まれる文章、アルゴリズム、サンプルコード、擬似コード、及びその他の記述は、</nobr></div>
<div style="position:absolute;top:1834;left:128"><nobr>Numenta Inc.が発行した hierarchical temporal memory (“HTM”) 技術に関する記述の翻訳な</nobr></div>
<div style="position:absolute;top:1863;left:128"><nobr>いしこれに基づいて得られたものである。原著の著作権及びここで翻訳された HTM やそのアル</nobr></div>
<div style="position:absolute;top:1890;left:128"><nobr>ゴリズムに関する特許権は Numenta が保有している。独立した HTM システムの開発及び使用</nobr></div>
<div style="position:absolute;top:1917;left:128"><nobr>に関して、それが商用目的ないし製品化目的ではなく、研究目的である限り、Numenta はその</nobr></div>
<div style="position:absolute;top:1944;left:128"><nobr>特許権を主張しないことに同意する。Numenta の特許権に抵触する商用目的ないし製品化目的</nobr></div>
<div style="position:absolute;top:1971;left:128"><nobr>のいかなる HTM 技術の使用も、Numenta から商用ライセンスを取得しなければならない。</nobr></div>
<div style="position:absolute;top:2025;left:128"><nobr>上記に基づいて Numenta は貴方に、商用目的ないし製品化目的の使用ではなく、研究目的に限</nobr></div>
<div style="position:absolute;top:2052;left:128"><nobr>り、これらのアルゴリズム及び著作を使用することを認可する。前述の「商用目的ないし製品化</nobr></div>
<div style="position:absolute;top:2079;left:128"><nobr>目的の使用」は、訓練された HTM ネットワークないしアプリケーションを後に商用目的ないし</nobr></div>
<div style="position:absolute;top:2106;left:128"><nobr>製品化目的で適用することを意図している場合、HTM ネットワークを訓練することを含む。前</nobr></div>
<div style="position:absolute;top:2133;left:128"><nobr>述の「商用目的ないし製品化目的の使用」はまた、商用目的ないし製品化目的で HTM 技術の出</nobr></div>
<div style="position:absolute;top:2160;left:128"><nobr>力結果を使用ないし他者に使用を許可することを含む。この記述を頒布・出版・複製したあらゆ</nobr></div>
<div style="position:absolute;top:2187;left:128"><nobr>る記述には、この翻訳ライセンスの全文が英文及び翻訳対象言語の両方で含まれていなければな</nobr></div>
<div style="position:absolute;top:2214;left:128"><nobr>らない。</nobr></div>
<div style="position:absolute;top:2268;left:128"><nobr>このライセンスは明示的にも暗黙的にも特許権の使用を何ら許可しない。ここで許可された翻訳</nobr></div>
<div style="position:absolute;top:2295;left:128"><nobr>物の品質ないし正確さに関して Numenta は義務も責任も負わない。 </nobr></div>
</span></font>

<div style="position:absolute;top:2699;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=3><b>Page 3</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:3881;left:442"><nobr><b>3</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:2899;left:128"><nobr><b>Numenta Translation License</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:2934;left:128"><nobr>Copyright (c) 2010, 2011 Numenta, Inc.</nobr></div>
<div style="position:absolute;top:2988;left:128"><nobr>All rights reserved.</nobr></div>
<div style="position:absolute;top:3042;left:128"><nobr>The text, algorithms, sample code, pseudo code and other work included herein are based</nobr></div>
<div style="position:absolute;top:3069;left:128"><nobr>upon or translated from certain works related to hierarchical temporal memory (“HTM”)</nobr></div>
<div style="position:absolute;top:3096;left:128"><nobr>technology published by Numenta Inc.  Numenta holds the copyright in the original works</nobr></div>
<div style="position:absolute;top:3123;left:128"><nobr>and patent rights related to HTM and the algorithms translated herein.  Numenta has</nobr></div>
<div style="position:absolute;top:3150;left:128"><nobr>agreed not to assert its patent rights against development or use of independent HTM</nobr></div>
<div style="position:absolute;top:3177;left:128"><nobr>systems, as long as such development or use is for research purposes only, and not for any</nobr></div>
<div style="position:absolute;top:3204;left:128"><nobr>commercial or production use.  Any commercial or production use of HTM technology that</nobr></div>
<div style="position:absolute;top:3231;left:128"><nobr>infringes on Numenta’s patents will require a commercial license from Numenta.</nobr></div>
<div style="position:absolute;top:3285;left:128"><nobr>Based on the foregoing, Numenta grants you a license to use these algorithms and works for</nobr></div>
<div style="position:absolute;top:3312;left:128"><nobr>research purposes only and not for any commercial or production use.  For purposes of this</nobr></div>
<div style="position:absolute;top:3339;left:128"><nobr>license, &quot;commercial or production use&quot; includes training an HTM network with the intent of</nobr></div>
<div style="position:absolute;top:3366;left:128"><nobr>later deploying the trained network or application for commercial or production purposes,</nobr></div>
<div style="position:absolute;top:3393;left:128"><nobr>and using or permitting others to use the output from HTM technology for commercial or</nobr></div>
<div style="position:absolute;top:3420;left:128"><nobr>production purposes.  Any distribution, publication, or copying of this work must include</nobr></div>
<div style="position:absolute;top:3447;left:128"><nobr>the full text of this Translation License in both English and the target language.</nobr></div>
<div style="position:absolute;top:3501;left:128"><nobr>NO EXPRESS OR IMPLIED LICENSES TO ANY PATENT RIGHTS ARE GRANTED BY</nobr></div>
<div style="position:absolute;top:3528;left:128"><nobr>THIS LICENSE.  NUMENTA SPECIFICALLY DISCLAIMS ANY LIABILITY OR</nobr></div>
<div style="position:absolute;top:3555;left:128"><nobr>RESPONSIBILITY FOR THE QUALITY OR ACCURACY OF ANY TRANSLATIONS</nobr></div>
<div style="position:absolute;top:3582;left:128"><nobr>LICENSED HEREUNDER. </nobr></div>
</span></font>

<div style="position:absolute;top:3961;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=4><b>Page 4</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:5143;left:442"><nobr><b>4</b></nobr></div>
<div style="position:absolute;top:4115;left:128"><nobr>最初にお読み下さい！</nobr></div>
<div style="position:absolute;top:4142;left:155"><nobr>本書は、この資料のドラフトである。読者が知っておくべき事柄のうち、欠落して</nobr></div>
<div style="position:absolute;top:4169;left:128"><nobr>いるものがいくつかある。</nobr></div>
<div style="position:absolute;top:4223;left:128"><nobr>本書に含まれること：</nobr></div>
<div style="position:absolute;top:4250;left:155"><nobr>本書は Numenta が 2010 年に開発した学習と予測に関する新しいアルゴリズムの</nobr></div>
<div style="position:absolute;top:4277;left:128"><nobr>詳細を説明している。この新しいアルゴリズムについて、プログラマが理解でき、もし</nobr></div>
<div style="position:absolute;top:4304;left:128"><nobr>望むならこれを実装可能なほど十分詳細に説明している。最初の章で概念説明をしてい</nobr></div>
<div style="position:absolute;top:4331;left:128"><nobr>る。もし読者が Numenta についてよく知っていて、我々のこれまでの論文のいくつか</nobr></div>
<div style="position:absolute;top:4358;left:128"><nobr>を読んだことがあるなら、それらは馴染み深いであろう。それ以後の章は新しい事柄に</nobr></div>
<div style="position:absolute;top:4385;left:128"><nobr>ついて述べる。</nobr></div>
<div style="position:absolute;top:4439;left:128"><nobr>本書に含まれないこと：</nobr></div>
<div style="position:absolute;top:4466;left:155"><nobr>この新しいアルゴリズムの実装に関するいくつかの話題は、この初期の草稿に含ま</nobr></div>
<div style="position:absolute;top:4493;left:128"><nobr>れていない。</nobr></div>
<div style="position:absolute;top:4546;left:128"><nobr>- アルゴリズムの多くの側面は実装及びテストされているが、テスト結果については</nobr></div>
<div style="position:absolute;top:4574;left:155"><nobr>述べられていない。</nobr></div>
<div style="position:absolute;top:4600;left:128"><nobr>- アルゴリズムを実際の問題にどのように適用可能であるかについての記述はない。</nobr></div>
<div style="position:absolute;top:4628;left:155"><nobr>センサーないしデータベースからのデータを、このアルゴリズムに適した分散表現</nobr></div>
<div style="position:absolute;top:4655;left:155"><nobr>に変換する方法の記述が抜けている。</nobr></div>
<div style="position:absolute;top:4681;left:128"><nobr>- アルゴリズムはオンライン学習ができる。オンライン学習を完全に実装するために、</nobr></div>
<div style="position:absolute;top:4709;left:155"><nobr>ある特殊な状況下で必要となるいくつかの詳細は記述されていない。</nobr></div>
<div style="position:absolute;top:4735;left:128"><nobr>- 執筆予定のその他の議論として次のものがある。疎分散表現の特徴に関する議論、</nobr></div>
<div style="position:absolute;top:4763;left:155"><nobr>利用例・応用例、付録への引用。</nobr></div>
<div style="position:absolute;top:4817;left:155"><nobr>我々は現時点で紹介可能な範囲でこの資料を作成した。他の人々もこれに関心を持</nobr></div>
<div style="position:absolute;top:4844;left:128"><nobr>つだろうと考えたためである。意欲のある研究者であれば、この資料の欠落している部</nobr></div>
<div style="position:absolute;top:4871;left:128"><nobr>分は、アルゴリズムを理解し実験をする上で妨げにならないだろうと考える。我々は今</nobr></div>
<div style="position:absolute;top:4898;left:128"><nobr>後の進展に伴って随時この資料を改訂する。 </nobr></div>
</span></font>

<div style="position:absolute;top:5223;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=5><b>Page 5</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:6405;left:442"><nobr><b>5</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:5434;left:128"><nobr>目次</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:5484;left:155"><nobr><a href="#2">Numenta 翻訳ライセンス（参考和訳） ................................................................. 2</a></nobr></div>
<div style="position:absolute;top:5511;left:155"><nobr><a href="#3">Numenta Translation License ............................................................................... 3</a></nobr></div>
<div style="position:absolute;top:5540;left:155"><nobr><a href="#8">序文 ........................................................................................................................ 8</a></nobr></div>
<div style="position:absolute;top:5567;left:171"><nobr><a href="#8">想定読者 .............................................................................................................. 8</a></nobr></div>
<div style="position:absolute;top:5594;left:171"><nobr><a href="#9">ソフトウェアのリリース ..................................................................................... 9</a></nobr></div>
<div style="position:absolute;top:5621;left:171"><nobr><a href="#9">以前の文書との関係 ............................................................................................ 9</a></nobr></div>
<div style="position:absolute;top:5646;left:171"><nobr><a href="#9">Numenta 社について .......................................................................................... 9</a></nobr></div>
<div style="position:absolute;top:5675;left:171"><nobr><a href="#10">著者について ..................................................................................................... 10</a></nobr></div>
<div style="position:absolute;top:5702;left:171"><nobr><a href="#10">改訂記録 ............................................................................................................ 10</a></nobr></div>
<div style="position:absolute;top:5729;left:155"><nobr><a href="#11">第１章： HTM 概説 .......................................................................................... 11</a></nobr></div>
<div style="position:absolute;top:5754;left:171"><nobr><a href="#12">HTM 原論 ......................................................................................................... 12</a></nobr></div>
<div style="position:absolute;top:5783;left:188"><nobr><a href="#12">階層構造 ........................................................................................................ 12</a></nobr></div>
<div style="position:absolute;top:5810;left:188"><nobr><a href="#15">リージョン ..................................................................................................... 15</a></nobr></div>
<div style="position:absolute;top:5837;left:188"><nobr><a href="#16">疎分散表現 ..................................................................................................... 16</a></nobr></div>
<div style="position:absolute;top:5864;left:188"><nobr><a href="#17">時間の役割 ..................................................................................................... 17</a></nobr></div>
<div style="position:absolute;top:5891;left:188"><nobr><a href="#19">学習 ............................................................................................................... 19</a></nobr></div>
<div style="position:absolute;top:5918;left:188"><nobr><a href="#20">推論 ............................................................................................................... 20</a></nobr></div>
<div style="position:absolute;top:5945;left:188"><nobr><a href="#21">予測 ............................................................................................................... 21</a></nobr></div>
<div style="position:absolute;top:5972;left:188"><nobr><a href="#23">行動 ............................................................................................................... 23</a></nobr></div>
<div style="position:absolute;top:5997;left:171"><nobr><a href="#23">HTM の実装に向けての進捗状況 ...................................................................... 23</a></nobr></div>
<div style="position:absolute;top:6026;left:155"><nobr><a href="#24">第２章： HTM 大脳皮質性学習アルゴリズム .................................................... 24</a></nobr></div>
<div style="position:absolute;top:6053;left:171"><nobr><a href="#24">用語説明 ............................................................................................................ 24</a></nobr></div>
<div style="position:absolute;top:6080;left:188"><nobr><a href="#24">セル状態 ........................................................................................................ 24</a></nobr></div>
<div style="position:absolute;top:6107;left:188"><nobr><a href="#25">樹状突起セグメント ....................................................................................... 25</a></nobr></div>
<div style="position:absolute;top:6134;left:188"><nobr><a href="#25">シナプス ........................................................................................................ 25</a></nobr></div>
<div style="position:absolute;top:6161;left:171"><nobr><a href="#26">概要 ................................................................................................................... 26</a></nobr></div>
<div style="position:absolute;top:6188;left:171"><nobr><a href="#32">共通概念 ............................................................................................................ 32</a></nobr></div>
<div style="position:absolute;top:6215;left:188"><nobr><a href="#32">二値ウェイト ................................................................................................. 32</a></nobr></div>
<div style="position:absolute;top:6242;left:188"><nobr><a href="#33">永続値 ............................................................................................................ 33</a></nobr></div>
<div style="position:absolute;top:6269;left:188"><nobr><a href="#33">樹状突起セグメント ....................................................................................... 33</a></nobr></div>
<div style="position:absolute;top:6296;left:188"><nobr><a href="#33">シナプス候補 ................................................................................................. 33</a></nobr></div>
<div style="position:absolute;top:6323;left:188"><nobr><a href="#33">学習 ............................................................................................................... 33</a></nobr></div>
</span></font>

<div style="position:absolute;top:6485;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=6><b>Page 6</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:7667;left:442"><nobr><b>6</b></nobr></div>
<div style="position:absolute;top:6639;left:171"><nobr><a href="#34">空間プーリングの概念 ....................................................................................... 34</a></nobr></div>
<div style="position:absolute;top:6666;left:171"><nobr><a href="#36">空間プーリングの詳細 ....................................................................................... 36</a></nobr></div>
<div style="position:absolute;top:6693;left:171"><nobr><a href="#36">時間プーリングの概念 ....................................................................................... 36</a></nobr></div>
<div style="position:absolute;top:6720;left:171"><nobr><a href="#38">時間プーリングの詳細 ....................................................................................... 38</a></nobr></div>
<div style="position:absolute;top:6747;left:171"><nobr><a href="#39">一次と可変長のシーケンスと予測 ..................................................................... 39</a></nobr></div>
<div style="position:absolute;top:6774;left:155"><nobr><a href="#43">第３章：　空間プーリングの実装と疑似コード ................................................... 43</a></nobr></div>
<div style="position:absolute;top:6801;left:188"><nobr><a href="#43">初期化 ............................................................................................................ 43</a></nobr></div>
<div style="position:absolute;top:6828;left:188"><nobr><a href="#44">フェーズ 1: オーバラップ ............................................................................. 44</a></nobr></div>
<div style="position:absolute;top:6855;left:188"><nobr><a href="#44">フェーズ 2: 抑制 ........................................................................................... 44</a></nobr></div>
<div style="position:absolute;top:6882;left:188"><nobr><a href="#44">フェーズ 3: 学習 ........................................................................................... 44</a></nobr></div>
<div style="position:absolute;top:6909;left:171"><nobr><a href="#46">データ構造と補助関数 ....................................................................................... 46</a></nobr></div>
<div style="position:absolute;top:6936;left:155"><nobr><a href="#48">第４章：　時間プーリングの実装と疑似コード ................................................... 48</a></nobr></div>
<div style="position:absolute;top:6963;left:171"><nobr><a href="#48">時間プーリング疑似コード： 推論だけのバージョン ....................................... 48</a></nobr></div>
<div style="position:absolute;top:6990;left:188"><nobr><a href="#48">フェーズ 1 ..................................................................................................... 48</a></nobr></div>
<div style="position:absolute;top:7017;left:188"><nobr><a href="#49">フェーズ 2 ..................................................................................................... 49</a></nobr></div>
<div style="position:absolute;top:7044;left:171"><nobr><a href="#49">時間プーリング疑似コード： 推論と学習を含むバージョン............................. 49</a></nobr></div>
<div style="position:absolute;top:7071;left:188"><nobr><a href="#49">フェーズ 1 ..................................................................................................... 49</a></nobr></div>
<div style="position:absolute;top:7098;left:188"><nobr><a href="#51">フェーズ 2 ..................................................................................................... 51</a></nobr></div>
<div style="position:absolute;top:7125;left:188"><nobr><a href="#51">フェーズ 3 ..................................................................................................... 51</a></nobr></div>
<div style="position:absolute;top:7152;left:171"><nobr><a href="#52">実装の詳細と用語説明 ....................................................................................... 52</a></nobr></div>
<div style="position:absolute;top:7179;left:155"><nobr><a href="#57">付録 A: 生体ニューロンと HTM セルの比較 ........................................................ 57</a></nobr></div>
<div style="position:absolute;top:7206;left:171"><nobr><a href="#57">生体ニューロン ................................................................................................. 57</a></nobr></div>
<div style="position:absolute;top:7233;left:188"><nobr><a href="#58">細胞体 ............................................................................................................ 58</a></nobr></div>
<div style="position:absolute;top:7260;left:188"><nobr><a href="#58">主要樹状突起 ................................................................................................. 58</a></nobr></div>
<div style="position:absolute;top:7287;left:188"><nobr><a href="#58">末梢樹状突起 ................................................................................................. 58</a></nobr></div>
<div style="position:absolute;top:7314;left:188"><nobr><a href="#59">シナプス ........................................................................................................ 59</a></nobr></div>
<div style="position:absolute;top:7341;left:188"><nobr><a href="#60">ニューロンの出力 .......................................................................................... 60</a></nobr></div>
<div style="position:absolute;top:7368;left:171"><nobr><a href="#60">単純な人工ニューロン ....................................................................................... 60</a></nobr></div>
<div style="position:absolute;top:7393;left:171"><nobr><a href="#61">HTM セル ......................................................................................................... 61</a></nobr></div>
<div style="position:absolute;top:7422;left:188"><nobr><a href="#61">主要樹状突起 ................................................................................................. 61</a></nobr></div>
<div style="position:absolute;top:7449;left:188"><nobr><a href="#62">末梢樹状突起 ................................................................................................. 62</a></nobr></div>
<div style="position:absolute;top:7476;left:188"><nobr><a href="#63">シナプス ........................................................................................................ 63</a></nobr></div>
<div style="position:absolute;top:7503;left:188"><nobr><a href="#63">セル出力 ........................................................................................................ 63</a></nobr></div>
<div style="position:absolute;top:7530;left:171"><nobr><a href="#64">参考文献 ............................................................................................................ 64</a></nobr></div>
<div style="position:absolute;top:7557;left:155"><nobr><a href="#65">付録 B: 新皮質の層と HTM リージョンの比較..................................................... 65</a></nobr></div>
<div style="position:absolute;top:7584;left:171"><nobr><a href="#65">新皮質の神経回路網 .......................................................................................... 65</a></nobr></div>
</span></font>

<div style="position:absolute;top:7747;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=7><b>Page 7</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:8929;left:442"><nobr><b>7</b></nobr></div>
<div style="position:absolute;top:7901;left:188"><nobr><a href="#66">層 ................................................................................................................... 66</a></nobr></div>
<div style="position:absolute;top:7928;left:188"><nobr><a href="#67">リージョンの違いによる層のバリエーション ................................................ 67</a></nobr></div>
<div style="position:absolute;top:7955;left:188"><nobr><a href="#68">カラム ............................................................................................................ 68</a></nobr></div>
<div style="position:absolute;top:7982;left:188"><nobr><a href="#69">ミニカラム ..................................................................................................... 69</a></nobr></div>
<div style="position:absolute;top:8009;left:188"><nobr><a href="#70">カラム反応の例外 .......................................................................................... 70</a></nobr></div>
<div style="position:absolute;top:8036;left:171"><nobr><a href="#71">なぜ層とカラムがあるのか？ ............................................................................ 71</a></nobr></div>
<div style="position:absolute;top:8063;left:171"><nobr><a href="#72">異なる層が何をするのかに関する仮説 .............................................................. 72</a></nobr></div>
<div style="position:absolute;top:8088;left:188"><nobr><a href="#75">HTM リージョンは新皮質の何に相当するか？ ............................................. 75</a></nobr></div>
<div style="position:absolute;top:8117;left:171"><nobr><a href="#75">まとめ ............................................................................................................... 75</a></nobr></div>
<div style="position:absolute;top:8144;left:155"><nobr><a href="#77">用語の説明 ............................................................................................................ 77</a></nobr></div>
</span></font>

<div style="position:absolute;top:9009;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=8><b>Page 8</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:10191;left:442"><nobr><b>8</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:9220;left:128"><nobr>序文</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:9272;left:155"><nobr>人間には簡単にできて、コンピュータには今のところできないようなことがたくさ</nobr></div>
<div style="position:absolute;top:9299;left:128"><nobr>んある。画像パターン認識、話し言葉の理解、触ることで対象物を理解したり操作する</nobr></div>
<div style="position:absolute;top:9326;left:128"><nobr>こと、複雑な世界を行き来することなどは人間にとっては簡単なことである。ところが</nobr></div>
<div style="position:absolute;top:9353;left:128"><nobr>数十年にも及ぶ研究にも関わらず、コンピュータ上で実行可能な人らしい行為をするア</nobr></div>
<div style="position:absolute;top:9380;left:128"><nobr>ルゴリズムはわずかしかない。</nobr></div>
<div style="position:absolute;top:9407;left:155"><nobr>人の場合、これらの能力は主に新皮質によって成される。Hierarchical Temporal</nobr></div>
<div style="position:absolute;top:9432;left:128"><nobr>Memory (HTM) は、新皮質がこの様な機能を発揮する様子をモデル化する技術である。</nobr></div>
<div style="position:absolute;top:9459;left:128"><nobr>HTM は人間と同等あるいはそれ以上の多くの認識性能を持つ機械を製造可能とするこ</nobr></div>
<div style="position:absolute;top:9488;left:128"><nobr>とを約束する。</nobr></div>
<div style="position:absolute;top:9515;left:155"><nobr>本書は HTM 技術について述べる。第１章は HTM を幅広く概説する。階層構造の</nobr></div>
<div style="position:absolute;top:9542;left:128"><nobr>重要性、疎分散表現<font style="font-size:8px">1</font>、時間的な変化に基づく学習について述べる。第２章は HTM 大</nobr></div>
<div style="position:absolute;top:9569;left:128"><nobr>脳皮質性学習アルゴリズム<font style="font-size:8px">2</font>について詳細に述べる。第３章と第 4 章は HTM 学習アル</nobr></div>
<div style="position:absolute;top:9596;left:128"><nobr>ゴリズムの疑似コードを、空間プーリング及び時間プーリングの２つのパートに分けて</nobr></div>
<div style="position:absolute;top:9623;left:128"><nobr>説明する。第２章から第４章を読めば、熟練したソフトウェア技術者であればこの技術</nobr></div>
<div style="position:absolute;top:9650;left:128"><nobr>を実装して実験することができるだろう。我々の成果のさらに先を行き、あるいは拡張</nobr></div>
<div style="position:absolute;top:9677;left:128"><nobr>を試みる読者が現れることを望んでいる。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:9757;left:128"><nobr>想定読者</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:9806;left:155"><nobr>本書は技術教育を受けた読者を想定している。ニューロサイエンスに関する予備知</nobr></div>
<div style="position:absolute;top:9833;left:128"><nobr>識を必要とはしていないものの、読者が数学やコンピュータ科学の概念を理解できるこ</nobr></div>
<div style="position:absolute;top:9860;left:128"><nobr>とを仮定している。我々は、この文書が授業の教科書として利用可能なように執筆した。</nobr></div>
<div style="position:absolute;top:9887;left:128"><nobr>最も想定される読者はコンピュータ科学や認知科学の学生、あるいは人の脳と同様の原</nobr></div>
<div style="position:absolute;top:9914;left:128"><nobr>理で機能する人工認知システムを作成するソフトウェア開発者である。</nobr></div>
<div style="position:absolute;top:9941;left:155"><nobr>本書のいくつかの部分、特に第１章の HTM 概説は技術者でない読者にも役立つ。 </nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:10050;left:128"><nobr>1 <font style="font-size:12px">sparse distributed representation。本書を理解する上で重要な概念だが、冒頭で述べられているよ</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:10071;left:141"><nobr>うに、残念ながら本書では説明されていない。理論的基礎は Pentti Kanerva 著 Sparse Distributed</nobr></div>
<div style="position:absolute;top:10093;left:141"><nobr>Memory に詳しい。Kanerva 氏は Jeff Hawkins 氏が設立した Redwood Neuroscience Institute</nobr></div>
<div style="position:absolute;top:10110;left:141"><nobr>（現在は Redwood Center for Theoretical Neuroscience)の研究員。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:10126;left:128"><nobr>2 <font style="font-size:12px">HTM cortical learning algorithms </font></nobr></div>
</span></font>

<div style="position:absolute;top:10271;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=9><b>Page 9</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:11453;left:442"><nobr><b>9</b></nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:10437;left:128"><nobr>ソフトウェアのリリース</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:10485;left:155"><nobr>本書に述べられたアルゴリズムに基づくソフトウェアリリースは 2011 年中頃を予</nobr></div>
<div style="position:absolute;top:10512;left:128"><nobr>定している。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:10592;left:128"><nobr>以前の文書との関係</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:10639;left:155"><nobr>HTM 理論の一部は 2004 年の On Intelligence<font style="font-size:8px">3</font>、Numenta 社から発行されたホワ</nobr></div>
<div style="position:absolute;top:10668;left:128"><nobr>イトペーパー、Numenta の従業員が執筆した論文などで述べている。読者がこれらの</nobr></div>
<div style="position:absolute;top:10695;left:128"><nobr>書類を読んでいることは前提としていない。これらの多くは本書でカバーされ、更新さ</nobr></div>
<div style="position:absolute;top:10722;left:128"><nobr>れている。第２章から第４章で述べている HTM 学習アルゴリズムは、これまで発表さ</nobr></div>
<div style="position:absolute;top:10749;left:128"><nobr>れたことはない。この新しいアルゴリズムは、Zeta 1 と呼ばれていた我々の第一世代ア</nobr></div>
<div style="position:absolute;top:10776;left:128"><nobr>ルゴリズムを置き換えるものである。初期の頃はこの新しいアルゴリズムのことを</nobr></div>
<div style="position:absolute;top:10801;left:128"><nobr>“Fixed-density Distributed Representations” ないし “FDR” と呼んでいたが、我々は</nobr></div>
<div style="position:absolute;top:10830;left:128"><nobr>もはやこの用語を使用していない。新しいアルゴリズムは HTM 大脳皮質性学習アルゴ</nobr></div>
<div style="position:absolute;top:10857;left:128"><nobr>リズム<font style="font-size:8px">4</font>、あるいは単に HTM 学習アルゴリズムと呼んでいる。</nobr></div>
<div style="position:absolute;top:10884;left:155"><nobr>我々は、Numenta 社創設者の一人である Jeff Hawkins と Sandra Blakeslee によ</nobr></div>
<div style="position:absolute;top:10911;left:128"><nobr>って書かれた On Intelligence を読まれることを推奨する。この本は HTM という名前</nobr></div>
<div style="position:absolute;top:10938;left:128"><nobr>で述べてはいないものの、それは HTM 理論とその背景にあるニューロサイエンスにつ</nobr></div>
<div style="position:absolute;top:10965;left:128"><nobr>いて、読みやすくかつあまり技術よりにならずに説明している。On Intelligence が執</nobr></div>
<div style="position:absolute;top:10992;left:128"><nobr>筆された当時、我々は HTM の基本原理を理解していたが、これをコンピュータアルゴ</nobr></div>
<div style="position:absolute;top:11019;left:128"><nobr>リズムとして実装する方法を知らなかった。本書は On Intelligence から始まった研究</nobr></div>
<div style="position:absolute;top:11046;left:128"><nobr>の続きと考えることができる。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:11130;left:128"><nobr><b>Numenta </b>社について</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:11173;left:155"><nobr>Numenta, Inc. (<a href="http://www.numenta.com/"></a><font color="#0000ff"><a href="http://www.numenta.com/">www.numenta.com</a></font><a href="http://www.numenta.com/"></a>)は HTM 技術を商業的ないし学術的利用のため</nobr></div>
<div style="position:absolute;top:11202;left:128"><nobr>に開発することを目的として 2005 年に設立された。この目的を達成するため、我々は</nobr></div>
<div style="position:absolute;top:11229;left:128"><nobr>我々の進捗及び発見を完全に文書化している。我々はまた、我々が開発したソフトウェ</nobr></div>
<div style="position:absolute;top:11256;left:128"><nobr>アを他の人が研究目的や商業目的で利用できるように提供している。我々は、独立系の</nobr></div>
<div style="position:absolute;top:11283;left:128"><nobr>アプリケーション開発コミュニティが立ち上がることを支援できるように、このソフト</nobr></div>
<div style="position:absolute;top:11310;left:128"><nobr>ウェアを構築した。Numenta 社のソフトウェアや知的所有権を研究目的で自由に利用</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:11370;left:128"><nobr>3 <font style="font-size:12px">邦訳 「考える脳 考えるコンピューター」ランダムハウス講談社</font></nobr></div>
<div style="position:absolute;top:11388;left:128"><nobr>4 <font style="font-size:12px">HTM Cortical Learning Algorithms </font></nobr></div>
</span></font>

<div style="position:absolute;top:11533;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=10><b>Page 10</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:12715;left:437"><nobr><b>10</b></nobr></div>
<div style="position:absolute;top:11687;left:128"><nobr>してよい。我々は商業目的での技術サポートの提供、ソフトウェアライセンス販売、知</nobr></div>
<div style="position:absolute;top:11714;left:128"><nobr>的所有権のライセンス販売で収益を得ている。我々は常に開発パートナーを求めており、</nobr></div>
<div style="position:absolute;top:11741;left:128"><nobr>彼らと我々自身の成功を追い求めている。</nobr></div>
<div style="position:absolute;top:11766;left:155"><nobr>Numenta 社はカリフォルニア州 Redwood City に拠点をおき、自己資本で運営され</nobr></div>
<div style="position:absolute;top:11795;left:128"><nobr>ている。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:11875;left:128"><nobr>著者について</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:11924;left:155"><nobr>本書は Numenta 社の従業員の協力と努力によって執筆された。各章の主な著者の</nobr></div>
<div style="position:absolute;top:11951;left:128"><nobr>名前は改訂記録に記載した。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:12032;left:128"><nobr>改訂記録</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:12080;left:155"><nobr>各版の主な変更点を下表に示す。細かな修正や整形などは記載していない。</nobr></div>
<div style="position:absolute;top:12108;left:128"><nobr>版</nobr></div>
<div style="position:absolute;top:12108;left:210"><nobr>日付</nobr></div>
<div style="position:absolute;top:12108;left:338"><nobr>変更点</nobr></div>
<div style="position:absolute;top:12108;left:603"><nobr>主な著者</nobr></div>
<div style="position:absolute;top:12143;left:128"><nobr>0.1 </nobr></div>
<div style="position:absolute;top:12143;left:210"><nobr>2010/11/9</nobr></div>
<div style="position:absolute;top:12143;left:338"><nobr>1. 序文、1,2,3,4 章、用語集の初</nobr></div>
<div style="position:absolute;top:12168;left:365"><nobr>版</nobr></div>
<div style="position:absolute;top:12143;left:603"><nobr>Jeff Hawkins,</nobr></div>
<div style="position:absolute;top:12170;left:603"><nobr>Subutai Ahmad,</nobr></div>
<div style="position:absolute;top:12197;left:603"><nobr>Donna Dubinsky </nobr></div>
<div style="position:absolute;top:12225;left:128"><nobr>0.1.1 </nobr></div>
<div style="position:absolute;top:12225;left:210"><nobr>2010/11/23</nobr></div>
<div style="position:absolute;top:12225;left:338"><nobr>1. 第 1 章のリージョンの節で、</nobr></div>
<div style="position:absolute;top:12250;left:365"><nobr>レベル、カラム、層などの用</nobr></div>
<div style="position:absolute;top:12277;left:365"><nobr>語を明確化するため編集した</nobr></div>
<div style="position:absolute;top:12306;left:338"><nobr>2. 付録Ａの初版</nobr></div>
<div style="position:absolute;top:12225;left:603"><nobr>Jeff Hawkins </nobr></div>
<div style="position:absolute;top:12334;left:128"><nobr>0.2</nobr></div>
<div style="position:absolute;top:12334;left:210"><nobr>2010/12/10</nobr></div>
<div style="position:absolute;top:12334;left:338"><nobr>1. 第２章： 明確化のため修正</nobr></div>
<div style="position:absolute;top:12361;left:338"><nobr>2. 第４章：行番号を修正、37行</nobr></div>
<div style="position:absolute;top:12386;left:365"><nobr>と39行のコードを修正</nobr></div>
<div style="position:absolute;top:12415;left:338"><nobr>3. 付録Ｂの初版</nobr></div>
<div style="position:absolute;top:12334;left:603"><nobr>Hawkins </nobr></div>
<div style="position:absolute;top:12361;left:603"><nobr>Ahmad </nobr></div>
<div style="position:absolute;top:12415;left:603"><nobr>Hawkins </nobr></div>
</span></font>

<div style="position:absolute;top:12795;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=11><b>Page 11</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:13977;left:437"><nobr><b>11</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:13006;left:128"><nobr>第１章： HTM 概説</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:13056;left:155"><nobr>Hierarchical Temporal Memory (HTM) は、新皮質の構造的・アルゴリズム的性質</nobr></div>
<div style="position:absolute;top:13085;left:128"><nobr>を捉えることを目指した機械学習技術である。</nobr></div>
<div style="position:absolute;top:13112;left:155"><nobr>新皮質は哺乳類の脳にある、知的思考の中枢である。ハイレベルな視覚・聴覚・触</nobr></div>
<div style="position:absolute;top:13139;left:128"><nobr>覚・運動・言語・行動計画はすべて新皮質で行われる。そのような様々な認知機能があ</nobr></div>
<div style="position:absolute;top:13166;left:128"><nobr>ると聞くと、新皮質がそれぞれに対応して特化されたニューラル・アルゴリズムを実装</nobr></div>
<div style="position:absolute;top:13193;left:128"><nobr>していると読者は考えるかも知れない。しかしそうではない。新皮質は実に均一なパタ</nobr></div>
<div style="position:absolute;top:13220;left:128"><nobr>ーンのニューラル回路である。生物学的な証拠によれば、新皮質は多くの異なった知的</nobr></div>
<div style="position:absolute;top:13247;left:128"><nobr>機能を実行する共通のアルゴリズム一式を実装していることが示されている。</nobr></div>
<div style="position:absolute;top:13272;left:155"><nobr>HTM は新皮質及びその多くの能力を理解する理論的な枠組みを提供する。現在</nobr></div>
<div style="position:absolute;top:13301;left:128"><nobr>我々は、この理論的な枠組みの小さなサブセットを実装している。今後より一層多くの</nobr></div>
<div style="position:absolute;top:13328;left:128"><nobr>理論が実装されるだろう。現在我々は、新皮質の商業的ないし科学的価値のうちの十分</nobr></div>
<div style="position:absolute;top:13355;left:128"><nobr>なサブセットを実装したと信じる。</nobr></div>
<div style="position:absolute;top:13380;left:155"><nobr>HTM のプログラミングは伝統的なコンピュータプログラミングとは異なる。今日</nobr></div>
<div style="position:absolute;top:13409;left:128"><nobr>のコンピュータでは、プログラマは特定の問題を解くために特化したプログラムを作成</nobr></div>
<div style="position:absolute;top:13436;left:128"><nobr>する。これに比べて、HTM はセンサーから得られたデータの流れに触れることで訓練</nobr></div>
<div style="position:absolute;top:13463;left:128"><nobr>される。HTM の能力はそれがどのようなデータに触れたかによって主に決められる。</nobr></div>
<div style="position:absolute;top:13492;left:155"><nobr>HTM はニューラルネットワークの一類型と考えられる。新皮質の構造的詳細をモデ</nobr></div>
<div style="position:absolute;top:13517;left:128"><nobr>ル化しようとするどんなシステムもニューラルネットワークと定義することができる。</nobr></div>
<div style="position:absolute;top:13544;left:128"><nobr>しかしながら、「ニューラルネットワーク」という用語は非常に多くのシステムで用い</nobr></div>
<div style="position:absolute;top:13571;left:128"><nobr>られているため、不用意に使えない。HTM がモデル化するニューロン（HTM ではセル</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:8px;font-family:Times">
<div style="position:absolute;top:13597;left:128"><nobr>5<font style="font-size:14px">と呼ぶ）は、カラム</font>6<font style="font-size:14px">、層</font>7<font style="font-size:14px">、リージョン</font>8<font style="font-size:14px">、階層構造</font>9<font style="font-size:14px">の中に配置される。これらの詳細</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:13625;left:128"><nobr>及び HTM 理論はニューラルネットワークの新しい形態である。</nobr></div>
<div style="position:absolute;top:13652;left:155"><nobr>名前が示すように HTM は基本的にメモリベースのシステムである。HTM ネットワ</nobr></div>
<div style="position:absolute;top:13679;left:128"><nobr>ークは時間的に変化するたくさんのデータによって訓練され、多くのパターンとシーケ</nobr></div>
<div style="position:absolute;top:13706;left:128"><nobr>ンス<font style="font-size:8px">10</font>の蓄積に依存している。データを格納及びアクセスする方法は、一般にプログラ</nobr></div>
<div style="position:absolute;top:13733;left:128"><nobr>マが使用する標準的なモデルとは論理的に異なっている。伝統的なコンピュータメモリ</nobr></div>
<div style="position:absolute;top:13760;left:128"><nobr>はフラットに構成され、それ自体は時間に関する概念を持たない。プログラムはフラッ</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:13824;left:128"><nobr>5 <font style="font-size:12px">cell</font></nobr></div>
<div style="position:absolute;top:13841;left:128"><nobr>6 <font style="font-size:12px">column</font></nobr></div>
<div style="position:absolute;top:13859;left:128"><nobr>7 <font style="font-size:12px">layer</font></nobr></div>
<div style="position:absolute;top:13876;left:128"><nobr>8 <font style="font-size:12px">region</font></nobr></div>
<div style="position:absolute;top:13893;left:128"><nobr>9 <font style="font-size:12px">hierarchy</font></nobr></div>
<div style="position:absolute;top:13912;left:128"><nobr>10 <font style="font-size:12px">sequence。連続して起こる事柄、ないしその順序を意味する。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:14057;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=12><b>Page 12</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:15239;left:437"><nobr><b>12</b></nobr></div>
<div style="position:absolute;top:14211;left:128"><nobr>トなコンピュータメモリ上に任意の種類のデータ構造を実装できる。プログラマは情報</nobr></div>
<div style="position:absolute;top:14238;left:128"><nobr>がどこにどのような形で格納されるかを制御する。これに比べて、HTM のメモリはも</nobr></div>
<div style="position:absolute;top:14265;left:128"><nobr>っと制限がある。HTM のメモリは階層的な構造であり、時刻の概念が内在している。</nobr></div>
<div style="position:absolute;top:14292;left:128"><nobr>情報は常に分散型の様式で保存される。HTM の利用者は階層のサイズを指定し、何に</nobr></div>
<div style="position:absolute;top:14319;left:128"><nobr>対してそのシステムを訓練するのかを決める。しかし情報がどこにどのように格納され</nobr></div>
<div style="position:absolute;top:14346;left:128"><nobr>るかは HTM が制御する。</nobr></div>
<div style="position:absolute;top:14375;left:155"><nobr>HTM ネットワークは伝統的なコンピュータとかなり違うものの、階層構造、時間と</nobr></div>
<div style="position:absolute;top:14400;left:128"><nobr>疎分散表現（詳しくは後述する）の主要機能を包含する限り、我々は汎用的なコンピュ</nobr></div>
<div style="position:absolute;top:14427;left:128"><nobr>ータを使ってモデル化することができる。我々はいずれ、HTM ネットワークに特化し</nobr></div>
<div style="position:absolute;top:14454;left:128"><nobr>たハートウェアを作ることになると信じている。</nobr></div>
<div style="position:absolute;top:14481;left:155"><nobr>本書では我々は HTM の特徴と原理を、人の視覚・触覚・聴覚・言語・行動を例に</nobr></div>
<div style="position:absolute;top:14508;left:128"><nobr>して表す。これらの例は直感的で容易に感じ取ることができるため便利である。しかし</nobr></div>
<div style="position:absolute;top:14535;left:128"><nobr>ながら、HTM の能力は汎用的であることを心に留めておくことは重要である。それら</nobr></div>
<div style="position:absolute;top:14562;left:128"><nobr>をレーダーや赤外線のような非人間的センサーのデータに触れさせることも容易であ</nobr></div>
<div style="position:absolute;top:14589;left:128"><nobr>り、あるいは金融マーケットデータ、天候データ、Web アクセスパターン、文字列情</nobr></div>
<div style="position:absolute;top:14616;left:128"><nobr>報などのような純粋な情報主体のデータに触れさせることもできる。HTM は学習と予</nobr></div>
<div style="position:absolute;top:14643;left:128"><nobr>測の機械であり、様々な種類の問題に適用可能である。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:14727;left:128"><nobr><b>HTM </b>原論</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:14772;left:155"><nobr>本節では、HTM のいくつかの核となる原論を述べる： なぜ階層的な組織が重要な</nobr></div>
<div style="position:absolute;top:14799;left:128"><nobr>のか、HTM のリージョンはどのように構成されるか、なぜデータを疎分散表現で格納</nobr></div>
<div style="position:absolute;top:14826;left:128"><nobr>するのか、なぜ時間ベースの情報がクリティカルであるのか。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:14894;left:128"><nobr>階層構造</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:14930;left:155"><nobr>HTM ネットワークは階層的に配置されたリージョンからなる。リージョンは HTM</nobr></div>
<div style="position:absolute;top:14955;left:128"><nobr>における記憶と予測の主要構成要素であり、次節でより詳しく述べる。通常、各 HTM</nobr></div>
<div style="position:absolute;top:14982;left:128"><nobr>リージョンは階層構造の 1 レベルを表す。階層構造を上がるに伴って、常に集約<font style="font-size:8px">11</font>があ</nobr></div>
<div style="position:absolute;top:15009;left:128"><nobr>る。子リージョンの複数の要素が親リージョンの一つの要素に集約する。一方、階層構</nobr></div>
<div style="position:absolute;top:15036;left:128"><nobr>造を下がるに伴って、フィードバック接続による情報の発散<font style="font-size:8px">12</font>がある。（リージョンと</nobr></div>
<div style="position:absolute;top:15063;left:128"><nobr>レベルはほとんど同義である。リージョンの内部的な機能について述べるときに「リー</nobr></div>
<div style="position:absolute;top:15090;left:128"><nobr>ジョン」の用語を用い、特に階層構造の中でのリージョンの役割を指すときに「レベル」</nobr></div>
<div style="position:absolute;top:15117;left:128"><nobr>の用語を用いる）</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:15159;left:128"><nobr>11 <font style="font-size:12px">convergence</font></nobr></div>
<div style="position:absolute;top:15174;left:128"><nobr>12 <font style="font-size:12px">divergence </font></nobr></div>
</span></font>

<div style="position:absolute;top:15319;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=13><b>Page 13</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:16501;left:437"><nobr><b>13</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:11px;font-family:Times">
<div style="position:absolute;top:15853;left:234"><nobr>図 １−１ ４階層の階層構造に配置された４つの HTMリージョンを単純化</nobr></div>
<div style="position:absolute;top:15880;left:234"><nobr>して表した図。情報は階層間及び階層内部で通信される。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:15932;left:155"><nobr>複数の HTM ネットワークを結合することもできる。この様な構造は、１つ以上の</nobr></div>
<div style="position:absolute;top:15959;left:128"><nobr>情報源やセンサからのデータがあるときに有意義である。例えば、一つのネットワーク</nobr></div>
<div style="position:absolute;top:15986;left:128"><nobr>が音声情報を処理し、他のネットワークが映像情報を処理する場合がある。各個別のネ</nobr></div>
<div style="position:absolute;top:16013;left:128"><nobr>ットワークがトップに向かうにつれて集約される。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:11px;font-family:Times">
<div style="position:absolute;top:16366;left:304"><nobr>図 １−２ 異なるセンサから集約するネットワーク </nobr></div>
</span></font>

<div style="position:absolute;top:16581;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=14><b>Page 14</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:17763;left:437"><nobr><b>14</b></nobr></div>
<div style="position:absolute;top:16735;left:155"><nobr>階層的な構造の利点は効率にある。階層構造の各レベルで学習されたパターンが上</nobr></div>
<div style="position:absolute;top:16762;left:128"><nobr>位のレベルで組み合わせて再利用されることで、それは学習時間とメモリ消費を非常に</nobr></div>
<div style="position:absolute;top:16789;left:128"><nobr>節約する。説明のため、視覚について考えてみよう。階層構造の最下位レベルでは、脳</nobr></div>
<div style="position:absolute;top:16816;left:128"><nobr>は縁<font style="font-size:8px">13</font>や角などの視覚のごく一部分に関する情報を格納する。縁は世の中の様々な物体</nobr></div>
<div style="position:absolute;top:16843;left:128"><nobr>を構成する基本的な構成要素である。これらの下位レベルのパターンは中間レベルで集</nobr></div>
<div style="position:absolute;top:16870;left:128"><nobr>約されて、例えば曲線や模様などのより複雑な構成要素に集約される。円弧は耳の縁に</nobr></div>
<div style="position:absolute;top:16897;left:128"><nobr>なりうるし、車のハンドルの上部にも、コーヒーカップの取っ手にもなりうる。これら</nobr></div>
<div style="position:absolute;top:16924;left:128"><nobr>の中間レベルのパターンはさらに集約されて、頭、車、家などの高レベルな物体の特徴</nobr></div>
<div style="position:absolute;top:16951;left:128"><nobr>を表す。高レベルな物体を学習するとき、その構成要素を再度学習する必要がなくなる。</nobr></div>
<div style="position:absolute;top:16978;left:155"><nobr>他の例として、新しい単語を学習するとき、文字や文節、発音を再度学習する必要</nobr></div>
<div style="position:absolute;top:17005;left:128"><nobr>はない。</nobr></div>
<div style="position:absolute;top:17032;left:155"><nobr>階層構造間で表現を共有することはまた、予期される行動の一般化にもなる。もし</nobr></div>
<div style="position:absolute;top:17059;left:128"><nobr>新しい動物を見たとき、口や歯を見れば、その動物がその口で食べることや、あるいは</nobr></div>
<div style="position:absolute;top:17086;left:128"><nobr>噛み付く可能性があることを予測できるだろう。階層構造により、世の中の新しい物体</nobr></div>
<div style="position:absolute;top:17113;left:128"><nobr>がその構成要素が持つ既に分かっている特徴を引き継いでいることを知ることができ</nobr></div>
<div style="position:absolute;top:17140;left:128"><nobr>る。</nobr></div>
<div style="position:absolute;top:17167;left:155"><nobr>一つの HTM 階層構造はいくつの事柄を学習できるだろうか？ 言い換えれば、階層</nobr></div>
<div style="position:absolute;top:17194;left:128"><nobr>構造にはいくつのレベルが必要だろうか？ 各レベルに割り当てるメモリと、必要なレ</nobr></div>
<div style="position:absolute;top:17221;left:128"><nobr>ベル数の間にはトレードオフがある。幸い、HTM は入力の統計及び割り当てられたリ</nobr></div>
<div style="position:absolute;top:17248;left:128"><nobr>ソースの量とから、各レベルの最適な表現を自動的に学習する。もしあるレベルにより</nobr></div>
<div style="position:absolute;top:17275;left:128"><nobr>多くのメモリを割り当てたなら、そのレベルはより大きくより複雑な表現を構成し、従</nobr></div>
<div style="position:absolute;top:17302;left:128"><nobr>って必要となる階層構造のレベルはより少なくなるだろう。もし少ないメモリを割り当</nobr></div>
<div style="position:absolute;top:17329;left:128"><nobr>てたなら、より小さく単純な表現を構成し、従って必要となる階層構造のレベルはより</nobr></div>
<div style="position:absolute;top:17356;left:128"><nobr>多くなるだろう。</nobr></div>
<div style="position:absolute;top:17383;left:155"><nobr>ここからは、視覚の推論<font style="font-size:8px">14</font>のような難しい問題について述べる（推論はパターン認</nobr></div>
<div style="position:absolute;top:17410;left:128"><nobr>識と似たものである）。しかし多くの価値ある問題は視覚より単純で、一つの HTM リ</nobr></div>
<div style="position:absolute;top:17437;left:128"><nobr>ージョンでも十分であると認められる。例えば我々は、人が Web サイトを眺めていた</nobr></div>
<div style="position:absolute;top:17464;left:128"><nobr>ときに次にどこをクリックするか予測する問題に HTM を適用してみた。この問題は、</nobr></div>
<div style="position:absolute;top:17491;left:128"><nobr>一連の Web クリックのデータを HTM ネットワークに流し込むことで行った。この問</nobr></div>
<div style="position:absolute;top:17518;left:128"><nobr>題では空間的階層構造はわずかしか認められない。解決策は主に時間的な統計を見つけ</nobr></div>
<div style="position:absolute;top:17545;left:128"><nobr>ることが求められる。即ち、一般的なユーザのパターンを認識することで、ユーザが次</nobr></div>
<div style="position:absolute;top:17572;left:128"><nobr>にどこをクリックするかを予測する。HTM の時間的学習アルゴリズムはこのような問</nobr></div>
<div style="position:absolute;top:17599;left:128"><nobr>題に適している。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:17680;left:128"><nobr>13 <font style="font-size:12px">edge。へり・ふち。</font></nobr></div>
<div style="position:absolute;top:17698;left:128"><nobr>14 <font style="font-size:12px">inference </font></nobr></div>
</span></font>

<div style="position:absolute;top:17843;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=15><b>Page 15</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:19025;left:437"><nobr><b>15</b></nobr></div>
<div style="position:absolute;top:17997;left:155"><nobr>まとめると、階層構造は学習時間を節約し、メモリ消費を節約し、一般化をもたら</nobr></div>
<div style="position:absolute;top:18024;left:128"><nobr>す。しかしながら、単純な予測問題の多くは一つの HTM リージョンでも解決しうる。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:18092;left:128"><nobr>リージョン</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:18126;left:155"><nobr>階層構造に連結されたリージョン<font style="font-size:8px">15</font>の表現は、生物学からもたらされた。新皮質は</nobr></div>
<div style="position:absolute;top:18153;left:128"><nobr>厚さ 2mm のニューロンの大きな皮である。生物学では主にそれらが互いにどのように</nobr></div>
<div style="position:absolute;top:18180;left:128"><nobr>接続しているかに基づいて、新皮質を異なる領域ないしリージョンに区分けする。ある</nobr></div>
<div style="position:absolute;top:18207;left:128"><nobr>リージョンはセンサから直接入力を受け取るが、他のリージョンは他のいくつかのリー</nobr></div>
<div style="position:absolute;top:18234;left:128"><nobr>ジョンを経由してから入力を受け取る。階層構造を決めるのはリージョンからリージョ</nobr></div>
<div style="position:absolute;top:18261;left:128"><nobr>ンへの接続関係である。</nobr></div>
<div style="position:absolute;top:18288;left:155"><nobr>新皮質のすべてのリージョンの細部は似ているように見える。そのサイズや階層構</nobr></div>
<div style="position:absolute;top:18315;left:128"><nobr>造の中のどこに位置するかということについての違いはあるものの、その他は似ている。</nobr></div>
<div style="position:absolute;top:18342;left:128"><nobr>厚さ 2mm の新皮質リージョンを縦にスライスしたなら、6 つの層を見ることができる。</nobr></div>
<div style="position:absolute;top:18367;left:128"><nobr>5 つはセルの層で、1 つはセルではない層である（少しの例外はあるが、これが一般的</nobr></div>
<div style="position:absolute;top:18396;left:128"><nobr>な規則である）。新皮質リージョンの各層はカラム状に数多くの相互接続されたセルが</nobr></div>
<div style="position:absolute;top:18423;left:128"><nobr>ある。</nobr></div>
<div style="position:absolute;top:18448;left:155"><nobr>HTM リージョンもまた、高度に相互接続されたセルがカラム状に配列された皮か</nobr></div>
<div style="position:absolute;top:18477;left:128"><nobr>らなっている。新皮質の第 3 層はニューロンの主要なフィード・フォワード層である。</nobr></div>
<div style="position:absolute;top:18502;left:128"><nobr>HTM リージョンのセルはおおまかに言えば新皮質のリージョンの第 3 層にあるニュー</nobr></div>
<div style="position:absolute;top:18531;left:128"><nobr>ロンと等価である。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:11px;font-family:Times">
<div style="position:absolute;top:18857;left:223"><nobr>図 １−３ HTM リージョンの区画。HTM リージョンは数多くのセルからなる。</nobr></div>
<div style="position:absolute;top:18884;left:223"><nobr>セルは二次元のカラム状に配置される。この図では、1 カラム当たり 4 つのセ</nobr></div>
<div style="position:absolute;top:18911;left:223"><nobr>ルで構成される HTM リージョンの小さな区画を表している。各カラムは入力</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:18960;left:128"><nobr>15 <font style="font-size:12px">region。体の部位、局部などの意。訳文では単独の region はそのままリージョンとした。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:19105;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=16><b>Page 16</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:20287;left:437"><nobr><b>16</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:11px;font-family:Times">
<div style="position:absolute;top:19261;left:223"><nobr>の一部に接続され、各セルは同一リージョン内の他のセルに接続する（接続は</nobr></div>
<div style="position:absolute;top:19288;left:223"><nobr>図示していない）。この HTM リージョン及びそのカラム構造は新皮質リージ</nobr></div>
<div style="position:absolute;top:19315;left:223"><nobr>ョンの一つの層に等価である点に注意。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:19365;left:155"><nobr>HTM リージョンは新皮質リージョンのほんの一部と等価であるに過ぎないものの、</nobr></div>
<div style="position:absolute;top:19394;left:128"><nobr>複雑なデータ列の推論と予測を実行することができ、多くの問題に有益である。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:19462;left:128"><nobr>疎分散表現</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:19496;left:155"><nobr>新皮質のニューロンは高度に相互接続しているが、わずかなパーセンテージのニュ</nobr></div>
<div style="position:absolute;top:19523;left:128"><nobr>ーロンだけが一度にアクティブになるように抑制ニューロンによって保護されている。</nobr></div>
<div style="position:absolute;top:19550;left:128"><nobr>よって脳内の情報は常に、数多く存在するニューロンのうちのわずかなパーセンテージ</nobr></div>
<div style="position:absolute;top:19577;left:128"><nobr>のアクティブなニューロンによって表されている。この様なコード化は「疎分散表現」</nobr></div>
<div style="position:absolute;top:19604;left:128"><nobr>と呼ばれる。「疎」とは、わずかなパーセンテージのニューロンだけが一度にアクティ</nobr></div>
<div style="position:absolute;top:19631;left:128"><nobr>ブになることを意味している。「分散」とは、何かを表現するためには多くのニューロ</nobr></div>
<div style="position:absolute;top:19658;left:128"><nobr>ンがアクティブになる必要があることを意味している。一つのアクティブなニューロン</nobr></div>
<div style="position:absolute;top:19685;left:128"><nobr>は何らかの意味表現に関わっているが、いくつかのニューロンの文脈の中で解釈されて</nobr></div>
<div style="position:absolute;top:19712;left:128"><nobr>初めて完全に意味を成すことができる。</nobr></div>
<div style="position:absolute;top:19737;left:155"><nobr>HTM リージョンもまた、疎分散表現を使用している。実際、HTM リージョンの記</nobr></div>
<div style="position:absolute;top:19766;left:128"><nobr>憶の仕組みは疎分散表現に依存しており、それなしには機能しない。HTM リージョン</nobr></div>
<div style="position:absolute;top:19793;left:128"><nobr>の入力は常に分散表現であるが、必ずしも疎であるとは限らないので、HTM リージョ</nobr></div>
<div style="position:absolute;top:19820;left:128"><nobr>ンが最初に行うべきことは入力を疎分散表現に変換することである。</nobr></div>
<div style="position:absolute;top:19847;left:155"><nobr>例えば、あるリージョンが 20,000 ビットの入力を受け取るとする。入力ビットの</nobr></div>
<div style="position:absolute;top:19874;left:128"><nobr>中の”1”や”0”の割合は、時間と共に非常に頻繁に変化するだろう。あるときは 5,000 個</nobr></div>
<div style="position:absolute;top:19901;left:128"><nobr>のビットが”1”であったり、またあるときは 9,000 個のビットが”1”であったりする。HTM</nobr></div>
<div style="position:absolute;top:19928;left:128"><nobr>リージョンはこの入力を 10,000 ビットの内部表現に変換して、入力のうちの何ビット</nobr></div>
<div style="position:absolute;top:19955;left:128"><nobr>が”1”であろうがその 2%にあたる 200 ビットが一度にアクティブになるようにする。</nobr></div>
<div style="position:absolute;top:19985;left:128"><nobr>HTM リージョンの入力が時間と共に変化するに従って、内部表現もまた変化するが、</nobr></div>
<div style="position:absolute;top:20012;left:128"><nobr>10,000 ビットのうち約 200 ビットが常にアクティブになる。</nobr></div>
<div style="position:absolute;top:20036;left:155"><nobr>リージョン内で表現可能なものの数よりも起こりうる入力パターンの数の方がずっ</nobr></div>
<div style="position:absolute;top:20063;left:128"><nobr>と大きいから、この処理によって多くの情報が失われるのではないか、と思われるかも</nobr></div>
<div style="position:absolute;top:20090;left:128"><nobr>知れない。しかしながら、どちらの数も途方もなく大きい。リージョンが入力からどの</nobr></div>
<div style="position:absolute;top:20117;left:128"><nobr>ようにして疎表現を作成するかについては後述する。理論的な情報のロスは、実際上は</nobr></div>
<div style="position:absolute;top:20144;left:128"><nobr>問題にならない。 </nobr></div>
</span></font>

<div style="position:absolute;top:20367;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=17><b>Page 17</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:21549;left:437"><nobr><b>17</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:11px;font-family:Times">
<div style="position:absolute;top:20847;left:225"><nobr>図 １−４ HTM リージョンのセルが疎分散的にアクティブになっている様子</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:20899;left:155"><nobr>疎分散表現はいくつかの望ましい特徴を有し、HTM の動作になくてはならない。</nobr></div>
<div style="position:absolute;top:20926;left:128"><nobr>後ほど、この点について再度述べる。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:20994;left:128"><nobr>時間の役割</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:21028;left:155"><nobr>時間は、学習・推論・予測において極めて重要な役割を果たす。</nobr></div>
<div style="position:absolute;top:21055;left:155"><nobr>推論から始めよう。時間を用いなければ、我々は触覚や聴覚からほとんど何も推論</nobr></div>
<div style="position:absolute;top:21082;left:128"><nobr>できない。例えば仮に読者が目が不自由だとして、誰かが貴方の手の上にりんごを置い</nobr></div>
<div style="position:absolute;top:21109;left:128"><nobr>たとしよう。ほんの数秒間触ってみることでそれが何かが分かるだろう。りんごの上で</nobr></div>
<div style="position:absolute;top:21136;left:128"><nobr>指を動かせば、触覚から得られる情報が常に変化しているにも関わらず、その物体その</nobr></div>
<div style="position:absolute;top:21163;left:128"><nobr>もの ― そのりんごや貴方が持つ「りんご」という高レベルの認識 ― は変化しない。</nobr></div>
<div style="position:absolute;top:21190;left:128"><nobr>しかしながら、もし貴方が手のひらを開いて、その上にりんごが置かれて、しかも手や</nobr></div>
<div style="position:absolute;top:21217;left:128"><nobr>指先を動かしてはいけないと言われたなら、それがレモンではなくりんごであると識別</nobr></div>
<div style="position:absolute;top:21244;left:128"><nobr>するのは非常に難しいだろう。</nobr></div>
<div style="position:absolute;top:21271;left:155"><nobr>同じことは聴覚についても言える。変化しない音はわずかな意味しか持たない。「り</nobr></div>
<div style="position:absolute;top:21298;left:128"><nobr>んご」という言葉や、誰かがりんごを噛んだときの音などは、時間と共に素早く順序的</nobr></div>
<div style="position:absolute;top:21325;left:128"><nobr>に変化する数十から数百の音階の列によってのみ理解しうる。</nobr></div>
<div style="position:absolute;top:21352;left:155"><nobr>視覚は対照的に、混在したケースである。触覚や聴覚とは異なり、人は画像が一瞬</nobr></div>
<div style="position:absolute;top:21379;left:128"><nobr>だけ目の前をすばやく通り過ぎた場合でも識別可能である。よって視覚の推論では必ず</nobr></div>
<div style="position:absolute;top:21406;left:128"><nobr>しも時間的な入力の変化を必要としない。しかしながら、通常の視覚では我々は常時、</nobr></div>
<div style="position:absolute;top:21433;left:128"><nobr>目や頭や体を動かしており、物体もまた周囲を動き回っている。素早く変化する視覚的</nobr></div>
<div style="position:absolute;top:21460;left:128"><nobr>変化の中から推論する我々の能力は、視覚の統計的な特徴と長年の訓練によってもたら</nobr></div>
</span></font>

<div style="position:absolute;top:21629;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=18><b>Page 18</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:22811;left:437"><nobr><b>18</b></nobr></div>
<div style="position:absolute;top:21783;left:128"><nobr>される特別なケースである。視覚・聴覚・触覚における一般的な場合では、推論には時</nobr></div>
<div style="position:absolute;top:21810;left:128"><nobr>間的に変化する入力が必要である。</nobr></div>
<div style="position:absolute;top:21837;left:155"><nobr>推論の一般的なケースと、静的な画像を推論するときの視覚の特別なケースを押さ</nobr></div>
<div style="position:absolute;top:21864;left:128"><nobr>えたところで、学習について見てみよう。学習するには、すべての HTM システムは訓</nobr></div>
<div style="position:absolute;top:21891;left:128"><nobr>練の間、時間的に変化する入力に触れる必要がある。視覚では静的な画像の推論がとき</nobr></div>
<div style="position:absolute;top:21918;left:128"><nobr>には可能なものの、物体がどのようなものであるかを学習するためにはその物体が変化</nobr></div>
<div style="position:absolute;top:21945;left:128"><nobr>する様子を見る必要がある。例えば、犬が読者に向かって走ってくる様子を想像してみ</nobr></div>
<div style="position:absolute;top:21972;left:128"><nobr>よう。時間的なそれぞれの瞬間において、犬の画像が貴方の眼の奥の網膜に一連のパタ</nobr></div>
<div style="position:absolute;top:21999;left:128"><nobr>ーンを形成する。貴方はこれらのパターンを同じ犬の異なる視点を表していると受け止</nobr></div>
<div style="position:absolute;top:22026;left:128"><nobr>めるが、数学的に言えばそれらのパターンはほとんど似ても似つかない。脳はこれらの</nobr></div>
<div style="position:absolute;top:22053;left:128"><nobr>異なるパターンが同じものを意味しているということを、その順序的な変化を観察する</nobr></div>
<div style="position:absolute;top:22080;left:128"><nobr>ことによって知る。時間はどの空間的なパターンが一緒に現れるかを教えてくれる「先</nobr></div>
<div style="position:absolute;top:22107;left:128"><nobr>生」である。</nobr></div>
<div style="position:absolute;top:22134;left:155"><nobr>センサから得られる入力が変化するだけでは十分ではない点に注意されたい。無関</nobr></div>
<div style="position:absolute;top:22161;left:128"><nobr>係な入力パターンが続けて現れても混乱するだけである。時間的に変化する入力は、</nobr></div>
<div style="position:absolute;top:22188;left:128"><nobr>世界のある固定した情報源からもたらされなければならない。また、我々が人の感覚器</nobr></div>
<div style="position:absolute;top:22215;left:128"><nobr>官を例として取り上げているものの、非人間的なセンサもまた一般に適用できる点にも</nobr></div>
<div style="position:absolute;top:22242;left:128"><nobr>注意されたい。もし発電所の温度・振動・雑音のパターンを認識するように HTM を訓</nobr></div>
<div style="position:absolute;top:22269;left:128"><nobr>練したいのなら、HTM はこれらのセンサの時間的な変化からもたらされるデータで訓</nobr></div>
<div style="position:absolute;top:22296;left:128"><nobr>練する必要がある。</nobr></div>
<div style="position:absolute;top:22323;left:155"><nobr>普通、HTM ネットワークは多くのデータで訓練する必要がある。読者が犬を識別す</nobr></div>
<div style="position:absolute;top:22350;left:128"><nobr>ることを学習するには、一匹の犬の一枚の写真ではなく、数多くの種類の犬を何度も見</nobr></div>
<div style="position:absolute;top:22377;left:128"><nobr>る必要がある。HTM アルゴリズムの仕事は、入力データの時系列の流れを学習するこ</nobr></div>
<div style="position:absolute;top:22404;left:128"><nobr>とにあり、そしてどのパターンに続いて別のどのパターンが現れるかというモデルを構</nobr></div>
<div style="position:absolute;top:22431;left:128"><nobr>築することにある。この時系列がいつ始まりいつ終わるのかがわからないので、この仕</nobr></div>
<div style="position:absolute;top:22458;left:128"><nobr>事は難しい。同時に複数の時系列が重なりあって起こることもある。学習は継続的に行</nobr></div>
<div style="position:absolute;top:22485;left:128"><nobr>われ、またノイズがある中で行われなければならない。</nobr></div>
<div style="position:absolute;top:22512;left:155"><nobr>シーケンスの学習と認識は予測を形成する基準となる。どのパターンが他のどのパ</nobr></div>
<div style="position:absolute;top:22539;left:128"><nobr>ターンに続くかを HTM が学習すれば、与えられた現在の入力とその直前の入力に対し</nobr></div>
<div style="position:absolute;top:22566;left:128"><nobr>て次にどのパターンが現れる可能性が高いかを予測することができる。予測は後に詳し</nobr></div>
<div style="position:absolute;top:22593;left:128"><nobr>く述べる。</nobr></div>
<div style="position:absolute;top:22623;left:155"><nobr>HTM の 4 つの基本的な機能に戻ろう：学習・推論・予測・行動<font style="font-size:8px">16</font>である。各 HTM</nobr></div>
<div style="position:absolute;top:22647;left:128"><nobr>リージョンは最初の 3 つの機能、学習・推論・予測を実行する。しかしながら行動は異</nobr></div>
<div style="position:absolute;top:22674;left:128"><nobr>なる。生物学によれば、多くの新皮質のリージョンが行動を形成することが分かってい</nobr></div>
<div style="position:absolute;top:22701;left:128"><nobr>る。しかし我々は、多くの興味深いアプリケーションにおいてこれは重要ではないと信</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:22746;left:128"><nobr>16 <font style="font-size:12px">behavior </font></nobr></div>
</span></font>

<div style="position:absolute;top:22891;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=19><b>Page 19</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:24073;left:437"><nobr><b>19</b></nobr></div>
<div style="position:absolute;top:23045;left:128"><nobr>じている。よって行動は現在の HTM の実装に含まれていない。ここでは議論の完全性</nobr></div>
<div style="position:absolute;top:23072;left:128"><nobr>のために触れた。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:23140;left:128"><nobr>学習</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:23172;left:155"><nobr>HTM リージョンはセンサから得られるデータのパターンとパターンのシーケンス</nobr></div>
<div style="position:absolute;top:23201;left:128"><nobr>を見つけることで、その世界を学習する。リージョンはその入力が何を表しているのか</nobr></div>
<div style="position:absolute;top:23228;left:128"><nobr>を「知って」はいない。それは純粋に統計的な世界でのみ機能する。それは入力ビット</nobr></div>
<div style="position:absolute;top:23255;left:128"><nobr>の組み合わせのうち、頻繁に同時に起こる組み合わせを見ている。我々はこれを空間的</nobr></div>
<div style="position:absolute;top:23282;left:128"><nobr>パターンと呼んでいる。そしてこれらの空間的パターンが時間と共にどのような順で現</nobr></div>
<div style="position:absolute;top:23309;left:128"><nobr>れるかを見ている。我々はこれを時間的パターンないしシーケンスと呼んでいる。</nobr></div>
<div style="position:absolute;top:23336;left:155"><nobr>もしリージョンへの入力が建物の環境に関するセンサであるなら、リージョンは建</nobr></div>
<div style="position:absolute;top:23363;left:128"><nobr>物の北側や南側において、ある温度と湿度の組み合わせがしばしば起こることを見つけ</nobr></div>
<div style="position:absolute;top:23390;left:128"><nobr>るだろう。そしてこれらの組み合わせが毎日移り変わる様子を学習するだろう。</nobr></div>
<div style="position:absolute;top:23417;left:155"><nobr>もしリージョンへの入力があるお店の購入に関する情報であれば、週末にある種の</nobr></div>
<div style="position:absolute;top:23444;left:128"><nobr>雑誌が購入されることや、天候が寒いときはある種の価格帯のものが夕方頃に好まれる</nobr></div>
<div style="position:absolute;top:23471;left:128"><nobr>ことを見つけるだろう。そして異なる人の購入パターンが類似の時系列のパターンに従</nobr></div>
<div style="position:absolute;top:23498;left:128"><nobr>うことを学習するだろう。</nobr></div>
<div style="position:absolute;top:23525;left:155"><nobr>一つの HTM リージョンは学習の能力が限定されている。リージョンはそれがどれ</nobr></div>
<div style="position:absolute;top:23552;left:128"><nobr>だけのメモリを利用可能で、それが受け取った入力がどのくらい複雑であるかに応じて</nobr></div>
<div style="position:absolute;top:23579;left:128"><nobr>何を学習するかを自動的に調整する。リージョンに割り当てられたメモリが削減された</nobr></div>
<div style="position:absolute;top:23606;left:128"><nobr>ら、リージョンが学習する空間的パターンはより単純なものとなる。割り当てられたメ</nobr></div>
<div style="position:absolute;top:23633;left:128"><nobr>モリが増加すると、学習する空間的パターンは複雑になりうる。学習した空間的パター</nobr></div>
<div style="position:absolute;top:23660;left:128"><nobr>ンが単純であれば、複雑な画像を理解するにはリージョンの階層構造が必要となりうる。</nobr></div>
<div style="position:absolute;top:23687;left:128"><nobr>我々はこの特徴を、人の視覚システムに見ることができる。網膜から情報を受け取る新</nobr></div>
<div style="position:absolute;top:23714;left:128"><nobr>皮質のリージョンは、視覚的な小さな領域についてだけ、空間的なパターンを学習する。</nobr></div>
<div style="position:absolute;top:23741;left:128"><nobr>階層構造のいくつかのレベルを経由した後にだけ、視覚の全体像を認識する。</nobr></div>
<div style="position:absolute;top:23768;left:155"><nobr>生物的システムと同様に、HTM リージョンの学習アルゴリズムは「オンライン学</nobr></div>
<div style="position:absolute;top:23795;left:128"><nobr>習」ができる。即ち、新しい入力を受け取るごとに継続的に学習する。学習した後の方</nobr></div>
<div style="position:absolute;top:23822;left:128"><nobr>が推論が改善されるが、学習フェーズと推論フェーズとを分ける必要はない。入力のパ</nobr></div>
<div style="position:absolute;top:23849;left:128"><nobr>ターンが変化するに従い、HTM リージョンもまた段階的に変化する。</nobr></div>
<div style="position:absolute;top:23876;left:155"><nobr>初期の訓練の後、HTM は学習し続けることもできるし、訓練フェーズの後に学習</nobr></div>
<div style="position:absolute;top:23903;left:128"><nobr>を無効化することもできる。他の方法としては、階層構造の下位レベルでは学習を無効</nobr></div>
<div style="position:absolute;top:23930;left:128"><nobr>化し、上位レベルでは学習を続けることもできる。HTM がその周囲の世界の統計的構</nobr></div>
<div style="position:absolute;top:23957;left:128"><nobr>造を学習したら、多くの学習は階層構造のより上位のレベルで起こる。もし HTM が下</nobr></div>
<div style="position:absolute;top:23984;left:128"><nobr>位レベルではかつて見られなかった新しいパターンに触れたら、これらの新しいパター</nobr></div>
</span></font>

<div style="position:absolute;top:24153;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=20><b>Page 20</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:25335;left:437"><nobr><b>20</b></nobr></div>
<div style="position:absolute;top:24307;left:128"><nobr>ンを学習するのにより長時間必要となる。この特徴は人間にも見られる。既に知ってい</nobr></div>
<div style="position:absolute;top:24334;left:128"><nobr>る言語の新しい単語を学習するのは比較的容易である。しかし慣れない発音の外国語の</nobr></div>
<div style="position:absolute;top:24361;left:128"><nobr>新しい単語を覚えようと思えば、まだ下位レベルの発音を知らないのでずっと難しいと</nobr></div>
<div style="position:absolute;top:24388;left:128"><nobr>思うだろう。</nobr></div>
<div style="position:absolute;top:24415;left:155"><nobr>単にパターンを見つけることは、価値の高い可能性を秘めている。マーケットの変</nobr></div>
<div style="position:absolute;top:24442;left:128"><nobr>動、病状の変化、天候、工場の生産、送電系統のような複雑なシステムの障害などの、</nobr></div>
<div style="position:absolute;top:24469;left:128"><nobr>高レベルなパターンを理解することはそれ自体に価値がある。それでも空間的・時間的</nobr></div>
<div style="position:absolute;top:24496;left:128"><nobr>パターンを学習することは推論と予測に先立って必要となる。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:24564;left:128"><nobr>推論</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:24596;left:155"><nobr>HTM が周囲の世界のパターンを学習すると、新しい入力について推論ができるよ</nobr></div>
<div style="position:absolute;top:24625;left:128"><nobr>うになる。HTM が入力を受け取ると、以前に学習した空間的ないし時間的パターンと</nobr></div>
<div style="position:absolute;top:24652;left:128"><nobr>照合する。新しい入力が以前に格納したシーケンスとうまく適合することが、推論とパ</nobr></div>
<div style="position:absolute;top:24679;left:128"><nobr>ターンマッチングの本質である。</nobr></div>
<div style="position:absolute;top:24706;left:155"><nobr>メロディをどうやって理解するかを考えてみよう。メロディの最初の音を聞いただ</nobr></div>
<div style="position:absolute;top:24733;left:128"><nobr>けでは良く分からない。次の音を聞けば可能性がかなり狭まるが、まだ十分ではないだ</nobr></div>
<div style="position:absolute;top:24760;left:128"><nobr>ろう。メロディを理解するためには普通は３，４，ないしそれ以上の音を聞く必要があ</nobr></div>
<div style="position:absolute;top:24787;left:128"><nobr>る。HTM リージョンの推論も似ている。それは継続的に入力列を見て、以前学習した</nobr></div>
<div style="position:absolute;top:24814;left:128"><nobr>シーケンと照合を試みる。HTM リージョンはシーケンスの最初からの照合を見つける</nobr></div>
<div style="position:absolute;top:24841;left:128"><nobr>こともできるが普通はもっと流動的で、それはちょうどメロディがどこから始まっても</nobr></div>
<div style="position:absolute;top:24868;left:128"><nobr>貴方が理解できることと似ている。HTM リージョンは分散表現を用いるので、リージ</nobr></div>
<div style="position:absolute;top:24895;left:128"><nobr>ョンがシーケンスを記憶ないし推論することは上記のメロディの例よりも複雑である。</nobr></div>
<div style="position:absolute;top:24922;left:128"><nobr>しかしこの例は、HTM が働く様子を示すものである。</nobr></div>
<div style="position:absolute;top:24949;left:155"><nobr>貴方がセンサから新しい入力を受け取ったら、それがすぐに明確になるとまでは言</nobr></div>
<div style="position:absolute;top:24976;left:128"><nobr>えないものの、慣れ親しんだパターンをその新しい入力から容易に見つけることができ</nobr></div>
<div style="position:absolute;top:25003;left:128"><nobr>る。例えば貴方は、例え老人であっても若い人であっても、男でも女でも、早く話され</nobr></div>
<div style="position:absolute;top:25030;left:128"><nobr>てもゆっくりでも、なまりが強くても、ほとんどの人が話す「朝食」という言葉を理解</nobr></div>
<div style="position:absolute;top:25057;left:128"><nobr>できる。同じ人が同じ「朝食」という単語を百回発音しても、その音は二度と、貴方の</nobr></div>
<div style="position:absolute;top:25084;left:128"><nobr>蝸牛殻<font style="font-size:8px">17</font>（音の受容体）を正確に同じように刺激することはないにも関わらずである。</nobr></div>
<div style="position:absolute;top:25109;left:155"><nobr>HTM リージョンも脳と同じ問題に直面する：入力は決して正確に繰り返されない。</nobr></div>
<div style="position:absolute;top:25138;left:128"><nobr>さらに、ちょうど脳と同じように、HTM リージョンは推論や訓練の最中にも新しい入</nobr></div>
<div style="position:absolute;top:25165;left:128"><nobr>力を取り扱わなければならない。HTM リージョンが新しい入力に対処する一つの方法</nobr></div>
<div style="position:absolute;top:25192;left:128"><nobr>は、疎分散表現を利用することによる。疎分散表現の鍵となる特徴は、パターンの一部</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:25270;left:128"><nobr>17 <font style="font-size:12px">cochleae。かぎゅうかく。耳の奥にある渦巻き状の感覚器官。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:25415;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=21><b>Page 21</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:26597;left:437"><nobr><b>21</b></nobr></div>
<div style="position:absolute;top:25569;left:128"><nobr>分だけをマッチングするだけでほぼ確実にマッチさせることができるということであ</nobr></div>
<div style="position:absolute;top:25596;left:128"><nobr>る。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:25664;left:128"><nobr>予測</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:25696;left:155"><nobr>HTM の各リージョンはパターンのシーケンスを格納する。格納されたシーケンス</nobr></div>
<div style="position:absolute;top:25725;left:128"><nobr>を現在の入力とマッチングすることで、次に到着すると思われる入力の予測をする。</nobr></div>
<div style="position:absolute;top:25750;left:128"><nobr>HTM リージョンは実際には疎分散表現の間の変遷を記録する。あるときはその変遷は</nobr></div>
<div style="position:absolute;top:25779;left:128"><nobr>メロディの中の音に見られるように線形のシーケンスであるが、一般的な場合は将来入</nobr></div>
<div style="position:absolute;top:25806;left:128"><nobr>力される可能性があるものが同時に多数予測される。HTM リージョンはときには長期</nobr></div>
<div style="position:absolute;top:25833;left:128"><nobr>間に及ぶ過去の文脈に基づいて異なる予測をする。HTM の記憶の多くはシーケンスの</nobr></div>
<div style="position:absolute;top:25860;left:128"><nobr>記憶と空間的パターンの変遷を記憶することに使われる。</nobr></div>
<div style="position:absolute;top:25885;left:155"><nobr>HTM の予測の鍵となる特徴のいくつかを以下に示す。</nobr></div>
<div style="position:absolute;top:25944;left:128"><nobr><b>1) </b>予測は継続的である</nobr></div>
<div style="position:absolute;top:25968;left:155"><nobr>貴方は特に意識していなくても継続的に予測している。HTM も同じことをする。</nobr></div>
<div style="position:absolute;top:25995;left:128"><nobr>歌を聞いているとき、貴方は次の音を予測している。階段を降りるとき、貴方の足がい</nobr></div>
<div style="position:absolute;top:26022;left:128"><nobr>つ次の段に触れるかを予測している。野球のピッチャーの投球を見ている時、ボールが</nobr></div>
<div style="position:absolute;top:26049;left:128"><nobr>バッターの方に近づいていくことを予測している。HTM リージョンでは、予測と推論</nobr></div>
<div style="position:absolute;top:26076;left:128"><nobr>はほとんど同じことである。予測は分離された処理ではなく、HTM リージョンが働く</nobr></div>
<div style="position:absolute;top:26103;left:128"><nobr>仕組みに統合されている。</nobr></div>
<div style="position:absolute;top:26160;left:128"><nobr><b>2) </b>予測は階層構造のすべてのレベルのすべてのリージョンで起こる</nobr></div>
<div style="position:absolute;top:26182;left:155"><nobr>HTM リージョンが階層構造を持つとき、予測はすべてのレベルで起こる。リージ</nobr></div>
<div style="position:absolute;top:26211;left:128"><nobr>ョンはそれが既に学習したパターンについて予測をする。言語の例では、低レベルのリ</nobr></div>
<div style="position:absolute;top:26238;left:128"><nobr>ージョンでは次の音素を予測し、高レベルのリージョンでは単語や句を予測するだろう。</nobr></div>
<div style="position:absolute;top:26295;left:128"><nobr><b>3) </b>予測は文脈依存である</nobr></div>
<div style="position:absolute;top:26319;left:155"><nobr>予測は過去に何が起こったか、そして現在何が起こっているかに基づいて行われる。</nobr></div>
<div style="position:absolute;top:26346;left:128"><nobr>従って直前の文脈に基づいて、ある入力から異なった予測が行われることがある。HTM</nobr></div>
<div style="position:absolute;top:26373;left:128"><nobr>リージョンは必要なだけのより多くの直前の文脈を用いて学習し、短時間ないし長時間</nobr></div>
<div style="position:absolute;top:26400;left:128"><nobr>の両方の文脈を保持することができる。この特徴は可変長記憶<font style="font-size:8px">18</font>として知られている。</nobr></div>
<div style="position:absolute;top:26427;left:128"><nobr>例えば、暗唱している演説、ゲティスバーグ演説<font style="font-size:8px">19</font>などを考えてみよう。次の単語を予</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:26476;left:128"><nobr>18 <font style="font-size:12px">variable order memory</font></nobr></div>
<div style="position:absolute;top:26495;left:128"><nobr>19 <font style="font-size:12px">Gettysburg Address。「人民の人民による人民のための政治」のフレーズが有名。”Four score and</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:26517;left:141"><nobr>seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty,</nobr></div>
<div style="position:absolute;top:26535;left:141"><nobr>and dedicated to the proposition that all men are created equal...” (以下略) </nobr></div>
</span></font>

<div style="position:absolute;top:26677;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=22><b>Page 22</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:27859;left:437"><nobr><b>22</b></nobr></div>
<div style="position:absolute;top:26831;left:128"><nobr>測するには、現在の単語だけでは全く不十分である。最初の文章だけでも ”and” の次</nobr></div>
<div style="position:absolute;top:26858;left:128"><nobr>に “seven” が来ることもあれば、“dedicated” が来ることもある。ときにはほんの少し</nobr></div>
<div style="position:absolute;top:26885;left:128"><nobr>の文脈で予測できることもある。“four score and” と分かれば次の “seven”を予測でき</nobr></div>
<div style="position:absolute;top:26912;left:128"><nobr>る。他の場合はフレーズが繰り返される場合があり、演説のうちのどの部分であるかを</nobr></div>
<div style="position:absolute;top:26939;left:128"><nobr>知るためには、そして次に何が来るかを予測するには、より長い文脈を使う必要がある。</nobr></div>
<div style="position:absolute;top:26995;left:128"><nobr><b>4) </b>予測は安定化につながる</nobr></div>
<div style="position:absolute;top:27020;left:155"><nobr>あるリージョンの出力はその予測である。HTM の特徴の一つは、リージョンから</nobr></div>
<div style="position:absolute;top:27047;left:128"><nobr>の出力はより安定しているということである。安定とはつまり、階層構造の上位に行く</nobr></div>
<div style="position:absolute;top:27074;left:128"><nobr>ほどよりゆっくりと変化し、長く継続するということ。この特徴はリージョンが予測を</nobr></div>
<div style="position:absolute;top:27101;left:128"><nobr>する方法からもたらされる。リージョンは単にすぐ次に何が起こるかを予測するだけで</nobr></div>
<div style="position:absolute;top:27128;left:128"><nobr>はない。可能なときは時間軸の複数ステップ先を予測する。あるリージョンが 5 ステッ</nobr></div>
<div style="position:absolute;top:27155;left:128"><nobr>プ先を予測できるとしよう。新しい入力が到着したとき、新たに予測されたステップは</nobr></div>
<div style="position:absolute;top:27182;left:128"><nobr>変化するが、しかしそのうちの 4 つの既に予測されたステップは変化しない。従って、</nobr></div>
<div style="position:absolute;top:27209;left:128"><nobr>個々の新しい入力は全く違っていても、出力の一部だけが変化するので、出力は入力よ</nobr></div>
<div style="position:absolute;top:27236;left:128"><nobr>りも安定化している。この特徴は我々が実世界で経験することを反映している。歌の名</nobr></div>
<div style="position:absolute;top:27263;left:128"><nobr>前のような高レベルの概念は、歌の中の実際の音のような低レベルの概念よりもゆっく</nobr></div>
<div style="position:absolute;top:27290;left:128"><nobr>りと変化する。</nobr></div>
<div style="position:absolute;top:27347;left:128"><nobr><b>5) </b>予測により、新しい入力が予期されたものか予期しないものかが分かる</nobr></div>
<div style="position:absolute;top:27371;left:155"><nobr>各 HTM リージョンは新しい事柄の検出器である。各リージョンは次に何が起こる</nobr></div>
<div style="position:absolute;top:27398;left:128"><nobr>かを予測するので、予期せぬ事が起こったということを知ることができる。HTM は次</nobr></div>
<div style="position:absolute;top:27425;left:128"><nobr>の入力として起こりうるものを、一つだけではなく一度に多数予測することができる。</nobr></div>
<div style="position:absolute;top:27452;left:128"><nobr>そのため次に何が起こるかを正確に予測できるわけではないが、もし次の入力がどの予</nobr></div>
<div style="position:absolute;top:27479;left:128"><nobr>測にも一致しないとき、何か普通でないことが起こったことが分かる。</nobr></div>
<div style="position:absolute;top:27536;left:128"><nobr><b>6) </b>予測はシステムをノイズにより強くすることができる</nobr></div>
<div style="position:absolute;top:27558;left:155"><nobr>HTM が次に何が起こるかを予測したとき、推論をその予測に従う方向へ向かわせ</nobr></div>
<div style="position:absolute;top:27587;left:128"><nobr>る。例えば HTM が話し言葉を処理しているとき、次にどんな音が、単語が、考えが聞</nobr></div>
<div style="position:absolute;top:27614;left:128"><nobr>こえてくるかを予測する。その予測により、欠落したデータを埋め合わせられる。もし</nobr></div>
<div style="position:absolute;top:27641;left:128"><nobr>あいまいな音が届いたら、HTM は予測していることに基づいてその音を解釈すること</nobr></div>
<div style="position:absolute;top:27668;left:128"><nobr>で、ノイズが含まれているときの推論を助けることができる。</nobr></div>
<div style="position:absolute;top:27693;left:155"><nobr>HTM リージョンの、シーケンス記憶、推論、予測は緊密に統合されている。これ</nobr></div>
<div style="position:absolute;top:27722;left:128"><nobr>らはリージョンの中核機能である。 </nobr></div>
</span></font>

<div style="position:absolute;top:27939;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=23><b>Page 23</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:29121;left:437"><nobr><b>23</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:28092;left:128"><nobr>行動<b><font style="font-size:10px">20</font></b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:28126;left:155"><nobr>我々の行動は我々が感じることに影響を及ぼす。目を動かすに従って、網膜は変化</nobr></div>
<div style="position:absolute;top:28153;left:128"><nobr>する入力を受け取る。手や指を動かせば、触った感触が変化する様子が脳に届く。我々</nobr></div>
<div style="position:absolute;top:28180;left:128"><nobr>のほとんど全ての動作は、我々が感じることを変化させる。センサ入力と筋肉運動は緊</nobr></div>
<div style="position:absolute;top:28207;left:128"><nobr>密に絡み合っている。</nobr></div>
<div style="position:absolute;top:28234;left:155"><nobr>数十年来の主要な見方では、新皮質の単一のリージョンである第 1 運動野が、新皮</nobr></div>
<div style="position:absolute;top:28261;left:128"><nobr>質内で運動を指令する場所と考えられてきた。その後、新皮質内のほとんどないしすべ</nobr></div>
<div style="position:absolute;top:28288;left:128"><nobr>てのリージョンは、低レベルの感覚野でさえ、運動に関する出力を出していることが分</nobr></div>
<div style="position:absolute;top:28315;left:128"><nobr>かった。すべての皮質性リージョンは感覚と運動機能とを統合していると考えられる。</nobr></div>
<div style="position:absolute;top:28342;left:155"><nobr>運動指令を生成することは予測することと似ているので、我々は現存のフレームワ</nobr></div>
<div style="position:absolute;top:28369;left:128"><nobr>ーク中の各 HTM リージョンに運動出力を加えることができると予期している。しかし</nobr></div>
<div style="position:absolute;top:28396;left:128"><nobr>ながら、これまでのすべての HTM 実装は純粋にセンサ入力に対処するものであって、</nobr></div>
<div style="position:absolute;top:28423;left:128"><nobr>運動に関する構成要素は含まれていない。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:28506;left:128"><nobr><b>HTM </b>の実装に向けての進捗状況</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:28552;left:155"><nobr>我々は HTM の理論的なフレームワークを実用的な技術へと大きく進化させた。</nobr></div>
<div style="position:absolute;top:28579;left:128"><nobr>我々は HTM 大脳皮質性学習アルゴリズムのいくつかのバージョンを実装・テストし、</nobr></div>
<div style="position:absolute;top:28606;left:128"><nobr>基本的なアーキテクチャは健全であると分かった。新しいデータでアルゴリズムをテス</nobr></div>
<div style="position:absolute;top:28633;left:128"><nobr>トするに従い、我々はアルゴリズムをより改善し、不足している部分を補ってゆくだろ</nobr></div>
<div style="position:absolute;top:28660;left:128"><nobr>う。これに伴い、この文書も更新する。これに続く３つの章は現在のアルゴリズムの状</nobr></div>
<div style="position:absolute;top:28687;left:128"><nobr>況を述べる。</nobr></div>
<div style="position:absolute;top:28714;left:155"><nobr>この理論の多くの構成要素はまだ実装されていない。注意<font style="font-size:8px">21</font>、リージョン間のフィ</nobr></div>
<div style="position:absolute;top:28741;left:128"><nobr>ードバック、特定のタイミング、センサ入力と行動の統合などがある。これらの欠落し</nobr></div>
<div style="position:absolute;top:28768;left:128"><nobr>た構成要素は既に作成されたフレームワークの中にうまく統合されなければならない。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:29039;left:128"><nobr>20 <font style="font-size:12px">behavior</font></nobr></div>
<div style="position:absolute;top:29056;left:128"><nobr>21 <font style="font-size:12px">attention </font></nobr></div>
</span></font>

<div style="position:absolute;top:29201;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=24><b>Page 24</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:30383;left:437"><nobr><b>24</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:29412;left:128"><nobr>第２章： <b>HTM </b>大脳皮質性学習アルゴリズム</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:29464;left:155"><nobr>本章では HTM リージョンの現状の学習アルゴリズムを説明する。第３章と第４章</nobr></div>
<div style="position:absolute;top:29491;left:128"><nobr>は疑似コードを用いて学習アルゴリズムの実装方法を説明し、本章では概念的に説明す</nobr></div>
<div style="position:absolute;top:29518;left:128"><nobr>る。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:29598;left:128"><nobr>用語説明</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:29647;left:155"><nobr>始める前に、用語を説明すると理解の助けとなるだろう。HTM 学習アルゴリズム</nobr></div>
<div style="position:absolute;top:29674;left:128"><nobr>を説明するとき、我々はニューロサイエンスの用語を使用する。セル<font style="font-size:8px">22</font>、シナプス<font style="font-size:8px">23</font>、</nobr></div>
<div style="position:absolute;top:29701;left:128"><nobr>シナプス候補<font style="font-size:8px">24</font>、樹状突起セグメント<font style="font-size:8px">25</font>、カラム<font style="font-size:8px">26</font>などの用語を使用する。学習アルゴリ</nobr></div>
<div style="position:absolute;top:29728;left:128"><nobr>ズムは理論上の必要に応じてニューロサイエンスの細部に照らして導かれたので、これ</nobr></div>
<div style="position:absolute;top:29755;left:128"><nobr>らの用語を使うことは理にかなっている。しかしながらアルゴリズムを実装する課程で、</nobr></div>
<div style="position:absolute;top:29782;left:128"><nobr>我々は性能の問題に直面し、その働きを理解したと感じたときには処理速度を向上させ</nobr></div>
<div style="position:absolute;top:29809;left:128"><nobr>る別の方法を探し求めた。これはときには、生物学的な詳細に厳格にこだわるのではな</nobr></div>
<div style="position:absolute;top:29836;left:128"><nobr>く、同じ結果が得られさえすれば、これを逸脱することとなった。もし読者がニューロ</nobr></div>
<div style="position:absolute;top:29863;left:128"><nobr>サイエンスの初学者であればこのことは問題とならないであろう。しかしニューロサイ</nobr></div>
<div style="position:absolute;top:29890;left:128"><nobr>エンスの用語に慣れ親しんだ読者であれば、我々が使用する用語が読者の予期するもの</nobr></div>
<div style="position:absolute;top:29917;left:128"><nobr>としばしば違うために混乱することもあるだろう。付録の生物学に関する議論では、</nobr></div>
<div style="position:absolute;top:29942;left:128"><nobr>HTM 学習アルゴリズムとニューロ生物学的に等価なものについて、相違点・類似点を</nobr></div>
<div style="position:absolute;top:29971;left:128"><nobr>詳細に述べる。ここでは混乱の元となりうる用語の違いのうち、主なものについて説明</nobr></div>
<div style="position:absolute;top:29998;left:128"><nobr>する。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:30066;left:128"><nobr>セル状態</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:30098;left:155"><nobr>HTM セルは３つの出力状態を持つ。フィード・フォワード入力によりアクティブ</nobr></div>
<div style="position:absolute;top:30127;left:128"><nobr>な状態、横方向の入力によりアクティブな状態（これは予測を表す）、アクティブでな</nobr></div>
<div style="position:absolute;top:30154;left:128"><nobr>い状態である。最初の出力状態はニューロンのアクション状態による短時間のはげしい</nobr></div>
<div style="position:absolute;top:30181;left:128"><nobr>出力<font style="font-size:8px">27</font>に相当する。２つ目の出力状態はもっとゆっくりとした、安定した出力<font style="font-size:8px">28</font>に相当</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:30230;left:128"><nobr>22 <font style="font-size:12px">cell</font></nobr></div>
<div style="position:absolute;top:30248;left:128"><nobr>23 <font style="font-size:12px">synapse</font></nobr></div>
<div style="position:absolute;top:30266;left:128"><nobr>24 <font style="font-size:12px">potential synapse</font></nobr></div>
<div style="position:absolute;top:30284;left:128"><nobr>25 <font style="font-size:12px">dendrite segment</font></nobr></div>
<div style="position:absolute;top:30302;left:128"><nobr>26 <font style="font-size:12px">column</font></nobr></div>
<div style="position:absolute;top:30320;left:128"><nobr>27 <font style="font-size:12px">a short burst of action potentials in a neuron </font></nobr></div>
</span></font>

<div style="position:absolute;top:30463;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=25><b>Page 25</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:31645;left:437"><nobr><b>25</b></nobr></div>
<div style="position:absolute;top:30617;left:128"><nobr>する。我々はこれら２つのアクティブ状態以上の詳細なモデル化の必要性はないと考え</nobr></div>
<div style="position:absolute;top:30644;left:128"><nobr>た。即ち、個々のアクション状態の強さの程度、アクティビティの発生頻度を表すスカ</nobr></div>
<div style="position:absolute;top:30671;left:128"><nobr>ラー量などはモデル化する必要性を見いだせない。分散表現の利用は、セルのアクティ</nobr></div>
<div style="position:absolute;top:30698;left:128"><nobr>ビティの程度を表すスカラー量をモデル化することを凌駕するように感じられる。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:30766;left:128"><nobr>樹状突起セグメント</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:30798;left:155"><nobr>HTM セルは比較的リアルな（従ってまた複雑な）樹状突起モデルを持つ。各 HTM</nobr></div>
<div style="position:absolute;top:30827;left:128"><nobr>セルは理論的に一つの主要樹状突起セグメント<font style="font-size:8px">29</font>と 10~20 個の末梢樹状突起セグメン</nobr></div>
<div style="position:absolute;top:30854;left:128"><nobr>ト<font style="font-size:8px">30</font>を持つ。主要樹状突起セグメントはフィード・フォワード入力を受け取り、末梢樹</nobr></div>
<div style="position:absolute;top:30881;left:128"><nobr>状突起セグメントは周辺のセルからの横方向の入力を受け取る。抑制セルは同じカラム</nobr></div>
<div style="position:absolute;top:30908;left:128"><nobr>中の全てのセルが類似のフィード・フォワード入力に対して応答するように強制する。</nobr></div>
<div style="position:absolute;top:30935;left:128"><nobr>単純化のため、各セルごとの主要樹状突起セグメントを取り除き、同じカラム中のすべ</nobr></div>
<div style="position:absolute;top:30962;left:128"><nobr>てのセルで共有する一つの主要樹状突起セグメントで置き換えた。空間プーリング関数</nobr></div>
<div style="position:absolute;top:30989;left:128"><nobr>（後述）はカラム単位で、共有の樹状突起セグメントに対して作用する。時間プーリン</nobr></div>
<div style="position:absolute;top:31016;left:128"><nobr>グ関数はカラム中の個々のセル単位で、末梢樹状突起セグメントに対して作用する。生</nobr></div>
<div style="position:absolute;top:31043;left:128"><nobr>物学的にはカラムに接続するような樹状突起セグメントは存在しないものの、この単純</nobr></div>
<div style="position:absolute;top:31070;left:128"><nobr>化は同等の機能をもたらす。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:31138;left:128"><nobr>シナプス</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:31170;left:155"><nobr>HTM のシナプスは二値のウェイトを持つ。生物学上のシナプスは可変値のウェイ</nobr></div>
<div style="position:absolute;top:31199;left:128"><nobr>トを持つが、確率的・不安定であり、生体ニューロンはシナプスのウェイト値の正確な</nobr></div>
<div style="position:absolute;top:31226;left:128"><nobr>値に依存しているはずがないということを暗示している。HTM の分散表現及び我々の</nobr></div>
<div style="position:absolute;top:31253;left:128"><nobr>樹状突起の計算モデルを利用すれば、HTM シナプスに二値のウェイトを割り当てても</nobr></div>
<div style="position:absolute;top:31280;left:128"><nobr>何ら悪影響はないはずである。シナプスの形成及び切断をモデル化するため、読者には</nobr></div>
<div style="position:absolute;top:31307;left:128"><nobr>馴染みがないと思われる２つの追加の概念をニューロサイエンスから援用した。一つ目</nobr></div>
<div style="position:absolute;top:31334;left:128"><nobr>は、シナプス候補の概念である。これは樹状突起セグメントに十分近い位置を通るすべ</nobr></div>
<div style="position:absolute;top:31361;left:128"><nobr>ての軸索を表し、シナプスを形成する可能性があるものである。二つ目は、永続値であ</nobr></div>
<div style="position:absolute;top:31388;left:128"><nobr>る。これは各シナプス候補に割り当てられたスカラー値である。シナプスの永続値は軸</nobr></div>
<div style="position:absolute;top:31415;left:128"><nobr>索と樹状突起の間の接続の度合いを表す。その度合は生物学的には、完全に分離した状</nobr></div>
<div style="position:absolute;top:31442;left:128"><nobr>態から、接続はしていないがシナプスを形成し始めた状態、最小限にシナプスが接続し</nobr></div>
<div style="position:absolute;top:31469;left:128"><nobr>た状態、大きく完全にシナプスが接続された状態に至るまでの範囲を取る。シナプスの</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:31523;left:128"><nobr>28 <font style="font-size:12px">a slower, steady rate of action potentials in a neuron</font></nobr></div>
<div style="position:absolute;top:31542;left:128"><nobr>29 <font style="font-size:12px">proximal dendrite segment。樹状突起のうち、ニューロンの中心部に近い部分。</font></nobr></div>
<div style="position:absolute;top:31561;left:128"><nobr>30 <font style="font-size:12px">distal dendrite segment。樹状突起のうち、末端に近い部分。distalは末梢（まっしょう）・末端の意味。</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:31581;left:141"><nobr>ちなみに末梢神経は <a href="http://ejje.weblio.jp/content/peripheral">peripheral </a>nerve という。 </nobr></div>
</span></font>

<div style="position:absolute;top:31725;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=26><b>Page 26</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:32907;left:437"><nobr><b>26</b></nobr></div>
<div style="position:absolute;top:31879;left:128"><nobr>永続値は 0.0 から 1.0 までの範囲のスカラー値である。学習にはシナプスの永続値の増</nobr></div>
<div style="position:absolute;top:31906;left:128"><nobr>加や減少が含まれる。シナプスの永続値がしきい値を超えたら、ウェイト値 1 で接続さ</nobr></div>
<div style="position:absolute;top:31933;left:128"><nobr>れたことを表す。しきい値より下回っていたら、ウェイト値 0 で切断されたことを表す。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:32013;left:128"><nobr>概要</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:32062;left:155"><nobr>仮に読者が HTM リージョンだったと想像してみよう。貴方の入力は数千ないし数</nobr></div>
<div style="position:absolute;top:32089;left:128"><nobr>万のビットからなる。これらの入力ビットはセンサ入力データや、階層構造の下位の他</nobr></div>
<div style="position:absolute;top:32116;left:128"><nobr>のリージョンから来たデータである。それらは複雑にオン・オフしている。これらの入</nobr></div>
<div style="position:absolute;top:32143;left:128"><nobr>力に対して貴方は何が出来るか？</nobr></div>
<div style="position:absolute;top:32170;left:155"><nobr>我々はその答えを単純な形態で既に説明した。各 HTM リージョンはその入力の共</nobr></div>
<div style="position:absolute;top:32197;left:128"><nobr>通のパターンを探し、それらのパターンのシーケンスを学習する。シーケンスの記憶か</nobr></div>
<div style="position:absolute;top:32224;left:128"><nobr>ら、各リージョンは予測をする。この高レベルの説明は容易に分かるが、実現にはもう</nobr></div>
<div style="position:absolute;top:32251;left:128"><nobr>少し説明が必要である。以下の３ステップにもう少し詳細化してみよう。</nobr></div>
<div style="position:absolute;top:32308;left:128"><nobr><b>1) </b>入力の疎分散表現を作成する</nobr></div>
<div style="position:absolute;top:32335;left:128"><nobr><b>2) </b>以前の入力の文脈に基づいて、入力の表現を作成する</nobr></div>
<div style="position:absolute;top:32362;left:128"><nobr><b>3) </b>以前の入力の文脈に基づいて、現在の入力からの予測をする</nobr></div>
<div style="position:absolute;top:32413;left:155"><nobr>これらのステップについてより詳細に見ていこう。</nobr></div>
<div style="position:absolute;top:32470;left:128"><nobr><b>1) </b>入力の疎分散表現を作成する</nobr></div>
<div style="position:absolute;top:32494;left:155"><nobr>リージョンへの入力を想像するには、それを巨大なビット列と考えるとよい。脳内</nobr></div>
<div style="position:absolute;top:32521;left:128"><nobr>ではこれらはニューロンからの軸索にあたる。任意の時点で、これらの入力のある部分</nobr></div>
<div style="position:absolute;top:32548;left:128"><nobr>はアクティブ（値１）、他の部分は非アクティブ（値０）である。アクティブな入力ビ</nobr></div>
<div style="position:absolute;top:32575;left:128"><nobr>ットの比率は変化する。例えば0%から60%としよう。HTMリージョンで行う最初の事</nobr></div>
<div style="position:absolute;top:32602;left:128"><nobr>は、この入力を疎な新しい表現に変換することである。例えば、入力のうち40%がオン</nobr></div>
<div style="position:absolute;top:32629;left:128"><nobr>かも知れないが、新しい表現では2%だけがオンになる。HTMリージョンは論理的には</nobr></div>
<div style="position:absolute;top:32656;left:128"><nobr>カラムの集合からなる。各カラムは1又はそれ以上のセルから成る。カラムは論理的に</nobr></div>
<div style="position:absolute;top:32683;left:128"><nobr>は2Dの配列状に配置できるが、これは要件ではない。リージョンの各カラムは入力ビ</nobr></div>
<div style="position:absolute;top:32710;left:128"><nobr>ットのユニークな部分集合（普通は他のカラムと重なるが、完全に同じ部分集合になる</nobr></div>
<div style="position:absolute;top:32737;left:128"><nobr>ことはない）に接続される。結果として、異なる入力パターンからは、レベル全体では</nobr></div>
<div style="position:absolute;top:32764;left:128"><nobr>異なるカラムのアクティベーションを得る。最も強いアクティベーションを得たカラム</nobr></div>
<div style="position:absolute;top:32791;left:128"><nobr>は、弱いアクティベーションを得たカラムを抑制、ないし非アクティブ化する。（抑制</nobr></div>
<div style="position:absolute;top:32818;left:128"><nobr>は非常に局所的範囲からリージョン全体までの範囲で変化する円の円内で起こる）入力</nobr></div>
</span></font>

<div style="position:absolute;top:32987;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=27><b>Page 27</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:34169;left:437"><nobr><b>27</b></nobr></div>
<div style="position:absolute;top:33141;left:128"><nobr>の疎表現は、抑制の後でどのカラムがアクティブでどれが非アクティブであるかによっ</nobr></div>
<div style="position:absolute;top:33168;left:128"><nobr>て表される。例え入力ビットのうちアクティブなビットの数が大幅に変化した場合であ</nobr></div>
<div style="position:absolute;top:33195;left:128"><nobr>っても、相対的に一定の割合のカラムがアクティブになるように抑制関数が定義される。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:11px;font-family:Times">
<div style="position:absolute;top:33575;left:213"><nobr>図 ２−１ カラムとセルからなる HTM リージョンの例。リージョンの一部分</nobr></div>
<div style="position:absolute;top:33602;left:213"><nobr>のみ表示している。各カラムは入力のユニークな部分集合によるアクティベー</nobr></div>
<div style="position:absolute;top:33629;left:213"><nobr>ションを受け取る。最も強いアクティベーションを受けたカラムが他の弱いア</nobr></div>
<div style="position:absolute;top:33656;left:213"><nobr>クティベーションを抑制する。結果は入力の疎分散表現である。（アクティブ</nobr></div>
<div style="position:absolute;top:33683;left:213"><nobr>なカラムは灰色で示した）</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:33735;left:155"><nobr>いま、入力パターンが変化したと想像してみよう。もしほんの少しの入力ビットが</nobr></div>
<div style="position:absolute;top:33762;left:128"><nobr>変化したなら、いくつかのカラムでは少し多く又は少し少ない入力ビットがオン状態に</nobr></div>
<div style="position:absolute;top:33789;left:128"><nobr>なるが、アクティブなカラムの集合はあまり大幅に変化しないだろう。よって似た入力</nobr></div>
<div style="position:absolute;top:33816;left:128"><nobr>パターン（アクティブなビットの共通部分が非常に多いもの）からはアクティブなカラ</nobr></div>
<div style="position:absolute;top:33843;left:128"><nobr>ムの比較的安定した集合に対応付けられる。コード化がどのくらい安定しているかは、</nobr></div>
<div style="position:absolute;top:33870;left:128"><nobr>各カラムがどの入力に接続しているかに大きく依存する。この接続関係は、後述する方</nobr></div>
<div style="position:absolute;top:33897;left:128"><nobr>法で学習する。これらのすべてのステップ（入力の部分集合から各カラムへの接続関係</nobr></div>
<div style="position:absolute;top:33924;left:128"><nobr>を学習し、各カラムへの入力レベルを決定し、アクティブなカラムの疎な集合をえらぶ</nobr></div>
<div style="position:absolute;top:33951;left:128"><nobr>ために抑制すること）を空間プーリングと呼ぶ。この用語は空間的に類似（アクティブ</nobr></div>
<div style="position:absolute;top:33978;left:128"><nobr>なビットの共通部分が多い）のパターンがプールされる（それらが共通の表現に互いに</nobr></div>
<div style="position:absolute;top:34005;left:128"><nobr>グループ化される）ことを意味する。 </nobr></div>
</span></font>

<div style="position:absolute;top:34249;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=28><b>Page 28</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:35431;left:437"><nobr><b>28</b></nobr></div>
<div style="position:absolute;top:34405;left:128"><nobr><b>2) </b>以前の入力の文脈に基づいて、入力の表現を作成する</nobr></div>
<div style="position:absolute;top:34430;left:155"><nobr>リージョンで行われる次の機能は、入力をカラムで表現したものを、過去からの状</nobr></div>
<div style="position:absolute;top:34457;left:128"><nobr>態ないし文脈を含む新しい表現に変換することである。新しい表現は各カラムの一部の</nobr></div>
<div style="position:absolute;top:34484;left:128"><nobr>セル、普通は１カラムにつき１つのセルをアクティブにすることで得られる（<a href="#29">図 ２−</a></nobr></div>
<div style="position:absolute;top:34511;left:128"><nobr><a href="#29">２</a>）。</nobr></div>
<div style="position:absolute;top:34538;left:155"><nobr>「I ate a pear」と「I have eight pears」<font style="font-size:8px">31</font>の二つの話し言葉を聞く場合を考えてみ</nobr></div>
<div style="position:absolute;top:34565;left:128"><nobr>よう。「ate」と「eight」は同音異義語であり、発音が同じである。声に出したときの</nobr></div>
<div style="position:absolute;top:34592;left:128"><nobr>「ate」と「eight」に対して同じ反応をするニューロンが脳内のどこかにあると考えら</nobr></div>
<div style="position:absolute;top:34619;left:128"><nobr>れる。これら全体で同じ音が耳に入る。また一方、これらの入力が異なり、異なる文脈</nobr></div>
<div style="position:absolute;top:34646;left:128"><nobr>にあると反応するニューロンが脳内の他のどこかにあると考えられる。「ate」という</nobr></div>
<div style="position:absolute;top:34673;left:128"><nobr>音に対する表現は「I ate」を聞いたときと「I have eight」を聞いた時とでは異なるだろ</nobr></div>
<div style="position:absolute;top:34700;left:128"><nobr>う。「I ate a pear」と「I have eight pears」の二つの文を記憶したと想像してみよう。</nobr></div>
<div style="position:absolute;top:34727;left:128"><nobr>「I ate…」と聞いたときと「I have eight…」と聞いたときとでは、異なる予測をするだ</nobr></div>
<div style="position:absolute;top:34754;left:128"><nobr>ろう。よって「I ate…」と聞いたときと「I have eight…」と聞いたときとでは異なる内</nobr></div>
<div style="position:absolute;top:34781;left:128"><nobr>部表現が存在するはずである。</nobr></div>
<div style="position:absolute;top:34808;left:155"><nobr>ある入力を異なる文脈では異なるコード変換をするというこの原理は、認知とふる</nobr></div>
<div style="position:absolute;top:34835;left:128"><nobr>まいの普遍的な特徴であり、HTM リージョンの最も重要な機能の一つである。この能</nobr></div>
<div style="position:absolute;top:34862;left:128"><nobr>力の重要性はどんなに強調しても、強調し過ぎることはない。</nobr></div>
<div style="position:absolute;top:34891;left:155"><nobr>HTM リージョンの各カラムは複数のセルからなっている。同じカラムのすべてのセ</nobr></div>
<div style="position:absolute;top:34916;left:128"><nobr>ルは同じフィード・フォワード入力を受け取る。カラム内の各セルはアクティブ又は非</nobr></div>
<div style="position:absolute;top:34943;left:128"><nobr>アクティブである。アクティブな各カラムごとに、どのセルをアクティブなセルとして</nobr></div>
<div style="position:absolute;top:34970;left:128"><nobr>選択するかによって、完全に同じ入力に対して異なる文脈では異なる表現をすることが</nobr></div>
<div style="position:absolute;top:34997;left:128"><nobr>できる。例で説明すると分かりやすいだろう。各カラムは 4 つのセルからなり、各入力</nobr></div>
<div style="position:absolute;top:35024;left:128"><nobr>は 100 個のアクティブなカラムで表現されるとしよう。カラムの中で一つのセルだけ</nobr></div>
<div style="position:absolute;top:35051;left:128"><nobr>が一度にアクティブであるとすると、完全に同じ入力に対して 4<font style="font-size:8px">100 </font>通りの表現が可能で</nobr></div>
<div style="position:absolute;top:35078;left:128"><nobr>ある。同じ入力は常に同じ組み合わせの 100 個のカラムがアクティブになるが、文脈</nobr></div>
<div style="position:absolute;top:35105;left:128"><nobr>が異なればカラム中の異なるセルがアクティブになる。これで同じ入力に対して非常に</nobr></div>
<div style="position:absolute;top:35132;left:128"><nobr>大きな数の文脈を表現可能となったが、これらの異なる表現はどのくらいユニークであ</nobr></div>
<div style="position:absolute;top:35159;left:128"><nobr>ろうか？ 4<font style="font-size:8px">100 </font>個の可能なパターンのうちからランダムに選択した 2 個は、ほとんどの</nobr></div>
<div style="position:absolute;top:35186;left:128"><nobr>場合、約 25 個のセルが重複している。よって同じ入力を異なる文脈で表した 2 つの表</nobr></div>
<div style="position:absolute;top:35213;left:128"><nobr>現は、約 25 個のセルが共通で 75 個のセルが異なっており、容易に区別することがで</nobr></div>
<div style="position:absolute;top:35240;left:128"><nobr>きる。</nobr></div>
<div style="position:absolute;top:35270;left:155"><nobr>HTM リージョンの一般的な規則は次のようになる。もしあるカラムがアクティブに</nobr></div>
<div style="position:absolute;top:35294;left:128"><nobr>なると、そのカラム中のすべてのセルを見る。もしそのカラム中の一つ又はそれ以上の</nobr></div>
<div style="position:absolute;top:35321;left:128"><nobr>セルが既に予測状態であれば、それらのセルだけがアクティブになる。もしそのカラム</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:35367;left:128"><nobr>31 <font style="font-size:12px">「私は梨を食べる」と「私は 8 個の梨を持っている」 </font></nobr></div>
</span></font>

<div style="position:absolute;top:35511;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=29><b>Page 29</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:36693;left:437"><nobr><b>29</b></nobr></div>
<div style="position:absolute;top:35665;left:128"><nobr>中のすべてのセルが予測状態でないならば、すべてのセルがアクティブになる。このよ</nobr></div>
<div style="position:absolute;top:35692;left:128"><nobr>うに考えることができる：ある入力パターンが期待されるなら、システムは予測状態の</nobr></div>
<div style="position:absolute;top:35719;left:128"><nobr>セルだけをアクティブにすることで期待通りであることを確認する。その入力パターン</nobr></div>
<div style="position:absolute;top:35746;left:128"><nobr>が期待と違うなら、システムはカラム中のすべてのセルをアクティブにすることで、「予</nobr></div>
<div style="position:absolute;top:35773;left:128"><nobr>期しない入力が発生したのであらゆる解釈が有りうる」ということを表す。</nobr></div>
<div style="position:absolute;top:35800;left:155"><nobr>もし以前の状態が何もないなら、従って文脈も予測もないなら、カラムがアクティ</nobr></div>
<div style="position:absolute;top:35827;left:128"><nobr>ブになるときは各カラム内のすべてのセルがアクティブになる。この筋書きは歌の最初</nobr></div>
<div style="position:absolute;top:35854;left:128"><nobr>の音を聞いたときと似ている。文脈がなければ、普通は次に何が起こるかを予測できな</nobr></div>
<div style="position:absolute;top:35881;left:128"><nobr>い：すべての選択肢が有効である。以前の状態があるが入力が予期したものと合致しな</nobr></div>
<div style="position:absolute;top:35908;left:128"><nobr>いときは、アクティブなカラムのすべてのセルがアクティブになる。この決定はカラム</nobr></div>
<div style="position:absolute;top:35935;left:128"><nobr>ごとに行われるので、予測が適合するかしないかは「オール・オア・ナッシング」<font style="font-size:8px">32</font>で</nobr></div>
<div style="position:absolute;top:35962;left:128"><nobr>はない。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:11px;font-family:Times">
<div style="position:absolute;top:36369;left:223"><nobr>図 ２−２ カラムの一部のセルをアクティブにすることで、HTM リージョンは</nobr></div>
<div style="position:absolute;top:36396;left:223"><nobr>同じ入力の多くの異なる文脈を表現することができる。カラムは予測状態のセ</nobr></div>
<div style="position:absolute;top:36423;left:223"><nobr>ルだけをアクティブにする。予測状態のセルがないカラムでは、カラム中のす</nobr></div>
<div style="position:absolute;top:36450;left:223"><nobr>べてのセルをアクティブにする。図は、あるカラムでは一つのセルだけがアク</nobr></div>
<div style="position:absolute;top:36477;left:223"><nobr>ティブであり、あるカラムではすべてのセルがアクティブである様子を示して</nobr></div>
<div style="position:absolute;top:36504;left:223"><nobr>いる。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:36556;left:155"><nobr>前述の用語の説明で述べたように、HTM セルは３つの状態を取る。セルがフィー</nobr></div>
<div style="position:absolute;top:36583;left:128"><nobr>ド・フォワード入力によってアクティブになったときは単に「アクティブ」の用語で呼</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:36630;left:128"><nobr>32 <font style="font-size:12px">all-or-nothing </font></nobr></div>
</span></font>

<div style="position:absolute;top:36773;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=30><b>Page 30</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:37955;left:437"><nobr><b>30</b></nobr></div>
<div style="position:absolute;top:36927;left:128"><nobr>ぶ。セルが他の周囲のセルとの横方向の接続によってアクティブになったときは「予測</nobr></div>
<div style="position:absolute;top:36954;left:128"><nobr>状態」と呼ぶ（<a href="#31">図 ２−３</a>）。</nobr></div>
<div style="position:absolute;top:37010;left:128"><nobr><b>3) </b>以前の入力の文脈に基づいて、現在の入力からの予測をする</nobr></div>
<div style="position:absolute;top:37035;left:155"><nobr>リージョンの最後のステップは次に起こると考えられることを予測することである。</nobr></div>
<div style="position:absolute;top:37062;left:128"><nobr>予測はステップ 2)で作成した、すべての以前の入力からの文脈を含む表現に基づいて行</nobr></div>
<div style="position:absolute;top:37089;left:128"><nobr>われる。</nobr></div>
<div style="position:absolute;top:37116;left:155"><nobr>リージョンが予測をするときは、将来のフィード・フォワード入力によってアクテ</nobr></div>
<div style="position:absolute;top:37143;left:128"><nobr>ィブになると考えられるすべてのセルをアクティブ（予測状態）にする。リージョンの</nobr></div>
<div style="position:absolute;top:37170;left:128"><nobr>表現は疎であるので、同時に複数の予測がなされ得る。例えばカラムのうちの 2%が入</nobr></div>
<div style="position:absolute;top:37197;left:128"><nobr>力によってアクティブになるとすると、カラムの 20%が予測状態のセルとなることで</nobr></div>
<div style="position:absolute;top:37222;left:128"><nobr>10 個の異なる予測がなされ得る。あるいはカラムの 40%が予測状態のセルとなること</nobr></div>
<div style="position:absolute;top:37251;left:128"><nobr>で、20 個の異なる予測がなされ得る。各カラムが 4 個のセルからなり、一度に一つだ</nobr></div>
<div style="position:absolute;top:37278;left:128"><nobr>けがアクティブになるとすれば、セル全体の 10%が予測状態になることになる。</nobr></div>
<div style="position:absolute;top:37305;left:155"><nobr>今後、疎分散表現の章が追加されれば、異なる予測が混じり合っても、リージョン</nobr></div>
<div style="position:absolute;top:37332;left:128"><nobr>は特定の入力が予測されたのかそうでないのかを高い確信さでもって知ることができ</nobr></div>
<div style="position:absolute;top:37359;left:128"><nobr>ることが示されるだろう。</nobr></div>
<div style="position:absolute;top:37386;left:155"><nobr>リージョンはどうやって予測をするのか？ 入力パターンが時間と共に変化すると</nobr></div>
<div style="position:absolute;top:37413;left:128"><nobr>き、カラムとセルの異なる組み合わせが順次アクティブになる。あるセルがアクティブ</nobr></div>
<div style="position:absolute;top:37440;left:128"><nobr>になると、周囲のセルのうちすぐ直前にアクティブだったセルの部分集合への接続を形</nobr></div>
<div style="position:absolute;top:37467;left:128"><nobr>成する。これらの接続は、そのアプリケーションで必要とされる学習速度に応じて早く</nobr></div>
<div style="position:absolute;top:37494;left:128"><nobr>形成されたりゆっくりと形成されたりするように調整できる。その後、すべてのセルは</nobr></div>
<div style="position:absolute;top:37521;left:128"><nobr>これらの接続を見て、どのセルが同時にアクティブになるかを探さなくてはならない。</nobr></div>
<div style="position:absolute;top:37548;left:128"><nobr>もし接続がアクティブになったら、セルはそれ自身が間もなくアクティブになることを</nobr></div>
<div style="position:absolute;top:37575;left:128"><nobr>予測することができ、予測状態に入る。よってある組み合わせのセルがフィード・フォ</nobr></div>
<div style="position:absolute;top:37602;left:128"><nobr>ワード入力によってアクティブになると、ひき続いて起こると考えられる他の組み合わ</nobr></div>
<div style="position:absolute;top:37629;left:128"><nobr>せのセルが予測状態になる。このことは、貴方が歌を聞いていて次の音を予測しようと</nobr></div>
<div style="position:absolute;top:37656;left:128"><nobr>している瞬間と同様と考えられる。 </nobr></div>
</span></font>

<div style="position:absolute;top:38035;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=31><b>Page 31</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:39217;left:437"><nobr><b>31</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:11px;font-family:Times">
<div style="position:absolute;top:38515;left:223"><nobr>図 ２−３ 任意の時点で、HTM リージョンのいくつかのセルがフィード・フ</nobr></div>
<div style="position:absolute;top:38542;left:223"><nobr>ォワード入力によってアクティブになる（薄い灰色で示した）。他のあるセル</nobr></div>
<div style="position:absolute;top:38569;left:223"><nobr>は、アクティブなセルからの横方向の入力を受け取って予測状態になる（濃い</nobr></div>
<div style="position:absolute;top:38596;left:223"><nobr>灰色で示した）。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:38648;left:155"><nobr>まとめると、新しい入力が到着すると、アクティブなカラムの疎な部分集合が選択</nobr></div>
<div style="position:absolute;top:38675;left:128"><nobr>される。各カラムの一つ又はそれ以上のセルがアクティブになり、これはまた同じリー</nobr></div>
<div style="position:absolute;top:38702;left:128"><nobr>ジョン内のセル間の接続の学習内容に応じて他のセルを予測状態にする。リージョン内</nobr></div>
<div style="position:absolute;top:38729;left:128"><nobr>の接続によってアクティブになったセルは、次に何が起こると考えられるかについての</nobr></div>
<div style="position:absolute;top:38756;left:128"><nobr>予測を表す。次のフィード・フォワード入力が到着すると、他のアクティブなカラムの</nobr></div>
<div style="position:absolute;top:38783;left:128"><nobr>疎な組み合わせが選択される。新たにアクティブになったカラムが予期したものでない</nobr></div>
<div style="position:absolute;top:38810;left:128"><nobr>とき、つまりどのセルもそれがアクティブになることを予測しなかったとき、カラム中</nobr></div>
<div style="position:absolute;top:38837;left:128"><nobr>のすべてのセルをアクティブにする。新たにアクティブになったカラムが一つ又はそれ</nobr></div>
<div style="position:absolute;top:38864;left:128"><nobr>以上の予測状態のセルを持つなら、それらのセルだけがアクティブになる。リージョン</nobr></div>
<div style="position:absolute;top:38891;left:128"><nobr>の出力はリージョン内のすべてのセルのアクティブ状態であり、フィード・フォワード</nobr></div>
<div style="position:absolute;top:38918;left:128"><nobr>入力によってアクティブになったセルと、予測状態のためアクティブになったセルとか</nobr></div>
<div style="position:absolute;top:38945;left:128"><nobr>らなる。</nobr></div>
<div style="position:absolute;top:38972;left:155"><nobr>既に述べたように、予測は次の時刻ステップだけではない。HTM リージョンの予</nobr></div>
<div style="position:absolute;top:38999;left:128"><nobr>測は将来のいくつかのステップに及ぶこともありうる。メロディに例えると、HTM リ</nobr></div>
<div style="position:absolute;top:39026;left:128"><nobr>ージョンはメロディの次の音を予測するだけではなく、例えば次の 4 つの音を予測する</nobr></div>
<div style="position:absolute;top:39053;left:128"><nobr>かも知れない。これは望ましい特徴と言える。リージョンの出力（リージョン内のアク</nobr></div>
<div style="position:absolute;top:39080;left:128"><nobr>ティブ状態のセルと予測状態のセルの和集合）は入力よりもゆっくりと変化する。リー</nobr></div>
<div style="position:absolute;top:39107;left:128"><nobr>ジョンがメロディの次の 4 つの音を予測しているときを想像してみよう。メロディを文</nobr></div>
<div style="position:absolute;top:39134;left:128"><nobr>字 A, B, C, D, E, F, G のシーケンスで表現する。最初の 2 音を聞いた後、リージョン</nobr></div>
</span></font>

<div style="position:absolute;top:39297;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=32><b>Page 32</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:40479;left:437"><nobr><b>32</b></nobr></div>
<div style="position:absolute;top:39451;left:128"><nobr>はシーケンスを理解し、予測をし始める。それは C, D, E, F を予測する。B のセル<font style="font-size:8px">33</font>は</nobr></div>
<div style="position:absolute;top:39478;left:128"><nobr>既にアクティブであるから B, C, D, E, F がそれぞれ 2 つのアクティブな状態のどちら</nobr></div>
<div style="position:absolute;top:39505;left:128"><nobr>かになる。さらにリージョンが次の音 C を聞く。アクティブ状態のセルと予測状態の</nobr></div>
<div style="position:absolute;top:39532;left:128"><nobr>セルの集合は C, D, E, F, G を表す。入力パターンは B から C へとまったく違うものに</nobr></div>
<div style="position:absolute;top:39559;left:128"><nobr>変化したが、20%のセルだけが変化している。</nobr></div>
<div style="position:absolute;top:39584;left:155"><nobr>HTM リージョンの出力はリージョン内のすべてのセルのアクティブ状態を示すベ</nobr></div>
<div style="position:absolute;top:39613;left:128"><nobr>クトルで表されるので、この例の出力では入力に比べて 5 倍安定している。階層構造に</nobr></div>
<div style="position:absolute;top:39640;left:128"><nobr>配置されたリージョンでは、階層構造を上に登るに従って時間的な安定性が増加する様</nobr></div>
<div style="position:absolute;top:39667;left:128"><nobr>子が見られるはずである。</nobr></div>
<div style="position:absolute;top:39694;left:155"><nobr>表現に文脈を追加して予測を行う 2 つのステップを「時間プーリング」という用語</nobr></div>
<div style="position:absolute;top:39721;left:128"><nobr>で表す。パターンのシーケンスに対してゆっくりと変化する出力を生成することで、時</nobr></div>
<div style="position:absolute;top:39748;left:128"><nobr>間と共に順に現れる異なるパターンを「プールする」<font style="font-size:8px">34</font>。</nobr></div>
<div style="position:absolute;top:39775;left:155"><nobr>では、さらに別のレベルで詳細化を進めよう。先ずは空間プーリングと時間プーリ</nobr></div>
<div style="position:absolute;top:39802;left:128"><nobr>ングで共通の概念から始める。そして空間プーリングに固有の概念と詳細、時間プーリ</nobr></div>
<div style="position:absolute;top:39829;left:128"><nobr>ングに固有の概念と詳細の順に説明する。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:39910;left:128"><nobr>共通概念</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:39958;left:155"><nobr>空間プーリングの学習と時間プーリングの学習は似ている。どちらの場合の学習も、</nobr></div>
<div style="position:absolute;top:39985;left:128"><nobr>セル間の接続関係、あるいはシナプスの形成を含む。時間プーリングは同じリージョン</nobr></div>
<div style="position:absolute;top:40012;left:128"><nobr>内のセル間の接続を学習する。空間プーリングは入力ビットとカラムとのフィード・フ</nobr></div>
<div style="position:absolute;top:40039;left:128"><nobr>ォワード接続を学習する。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:40107;left:128"><nobr>二値ウェイト</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:40139;left:155"><nobr>HTM のシナプスは 0 又は 1 の効果だけを持つ。多くの他のニューラルネットワー</nobr></div>
<div style="position:absolute;top:40168;left:128"><nobr>クモデルでは 0 から 1 の範囲で変化するスカラー値のウェイトを用いるのと異なり、ウ</nobr></div>
<div style="position:absolute;top:40195;left:128"><nobr>ェイトは二値である。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:40356;left:128"><nobr>33 <font style="font-size:12px">英文では cells と複数形なので、B を表すセルは一つではないことが分かる。A, B, C,...のそれぞれ</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:40376;left:141"><nobr>に対応する疎分散表現は、リージョン全体の 2%のセルの組み合わせで表される。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:40395;left:128"><nobr>34 <font style="font-size:12px">何かを貯めこんで蓄積するというニュアンスから、時間に関する情報を蓄積するものという意味と思わ</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:40415;left:141"><nobr>れる。 </nobr></div>
</span></font>

<div style="position:absolute;top:40559;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=33><b>Page 33</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:41741;left:437"><nobr><b>33</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:40712;left:128"><nobr>永続値</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:40746;left:155"><nobr>シナプスは学習を通じて継続的に形成されあるいは切断される。既に述べたように、</nobr></div>
<div style="position:absolute;top:40773;left:128"><nobr>各シナプスに（0.0 から 1.0 の）スカラー値を割り当て、接続がどのくらい永続的であ</nobr></div>
<div style="position:absolute;top:40800;left:128"><nobr>るかを表す。接続が強化されれば、永続値は増加する。他の状況では、永続値は減少す</nobr></div>
<div style="position:absolute;top:40827;left:128"><nobr>る。永続値がしきい値（例えば 0.2）を上回れば、シナプスは形成されたと考えられる。</nobr></div>
<div style="position:absolute;top:40854;left:128"><nobr>永続値がしきい値を下回れば、シナプスは無効である。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:40922;left:128"><nobr>樹状突起セグメント</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:40956;left:155"><nobr>シナプスは樹状突起セグメントに接続される。樹状突起には主要と末梢の 2 種類が</nobr></div>
<div style="position:absolute;top:40983;left:128"><nobr>ある。</nobr></div>
<div style="position:absolute;top:41009;left:128"><nobr>- 主要樹状突起セグメントはフィード・フォワード入力との間のシナプスを形成する。</nobr></div>
<div style="position:absolute;top:41037;left:155"><nobr>このタイプのセグメントのアクティブなシナプスは線形に加算され、これによりカ</nobr></div>
<div style="position:absolute;top:41064;left:155"><nobr>ラムがフィード・フォワード入力によるアクティブ状態になるか否かが決定される。</nobr></div>
<div style="position:absolute;top:41090;left:128"><nobr>- 末梢樹状突起セグメントは同じリージョン内のセル間のシナプスを形成する。各セ</nobr></div>
<div style="position:absolute;top:41118;left:155"><nobr>ルはいくつかの末梢樹状突起セグメントを持つ。ある末梢樹状突起セグメント上の</nobr></div>
<div style="position:absolute;top:41145;left:155"><nobr>アクティブなシナプスの合計がしきい値を超えたら、接続されたセルは予測状態に</nobr></div>
<div style="position:absolute;top:41172;left:155"><nobr>よりアクティブになる。一つのセルに複数の末梢樹状突起セグメントがあるので、</nobr></div>
<div style="position:absolute;top:41199;left:155"><nobr>セルの予測状態はそれぞれをしきい値で判定した結果の論理和で求められる。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:41267;left:128"><nobr>シナプス候補</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:41301;left:155"><nobr>既に述べたように、樹状突起セグメントはシナプス候補のリストを持つ。すべての</nobr></div>
<div style="position:absolute;top:41328;left:128"><nobr>シナプス候補は永続値を持ち、永続値がしきい値を超えたら有効に機能するシナプスと</nobr></div>
<div style="position:absolute;top:41355;left:128"><nobr>なる。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:41423;left:128"><nobr>学習</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:41457;left:155"><nobr>学習では樹状突起セグメント上のシナプス候補の永続値を増加・減少させる。シナ</nobr></div>
<div style="position:absolute;top:41484;left:128"><nobr>プスの永続性を増加・減少させるために用いられる規則は「ヘブの学習規則」<font style="font-size:8px">35</font>に似て</nobr></div>
<div style="position:absolute;top:41511;left:128"><nobr>いる。例えば、ある樹状突起セグメントがしきい値以上の入力を受け取ったためにセル</nobr></div>
<div style="position:absolute;top:41538;left:128"><nobr>がアクティブになったときは、そのセグメント上のシナプスの永続値を修正する。シナ</nobr></div>
<div style="position:absolute;top:41565;left:128"><nobr>プスがアクティブであり、従ってセルがアクティブになることに貢献した場合、その永</nobr></div>
<div style="position:absolute;top:41592;left:128"><nobr>続値を増加させる。シナプスがアクティブではなく、従って貢献しなかった場合、その</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:41638;left:128"><nobr>35 <font style="font-size:12px">Hebbian learning rules。「細胞 A の軸索が細胞 B を発火させるのに十分近くにあり、繰り返しあるい</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:41658;left:141"><nobr>は絶え間なくその発火に参加するとき、いくつかの成長過程あるいは代謝変化が一方あるいは両方</nobr></div>
<div style="position:absolute;top:41677;left:141"><nobr>の細胞に起こり、細胞 B を発火させる細胞の 1 つとして細胞 A の効率が増加する。」 </nobr></div>
</span></font>

<div style="position:absolute;top:41821;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=34><b>Page 34</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:43003;left:437"><nobr><b>34</b></nobr></div>
<div style="position:absolute;top:41975;left:128"><nobr>永続値を減少させる。シナプスの永続値を更新する正確な条件は、空間プーリングと時</nobr></div>
<div style="position:absolute;top:42002;left:128"><nobr>間プーリングとでは異なる。詳細は以下に述べる。</nobr></div>
<div style="position:absolute;top:42029;left:155"><nobr>では空間プーリング関数と時間プーリング関数に固有の概念について述べる。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:42109;left:128"><nobr>空間プーリングの概念</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:42158;left:155"><nobr>空間プーリングの最も基本的な機能はリージョンへの入力を疎なパターンに変換す</nobr></div>
<div style="position:absolute;top:42185;left:128"><nobr>ることである。シーケンスを学習して予測をするときに用いられる仕組では疎分散パタ</nobr></div>
<div style="position:absolute;top:42212;left:128"><nobr>ーンから始めることが必要となるため、この機能は重要である。空間プーリングがどれ</nobr></div>
<div style="position:absolute;top:42239;left:128"><nobr>ほどうまく計算及び学習をするのかを決定するいくつかの到達目標がある。</nobr></div>
<div style="position:absolute;top:42296;left:128"><nobr><b>1) </b>すべてのカラムを使用する</nobr></div>
<div style="position:absolute;top:42318;left:155"><nobr>HTM リージョンは入力の共通したパターンに対する表現を学習するための固定数</nobr></div>
<div style="position:absolute;top:42347;left:128"><nobr>のカラムがある。一つの目的は、全体のカラムの数がいくつあったとしても、すべての</nobr></div>
<div style="position:absolute;top:42374;left:128"><nobr>カラムが確かに、何か有用なことの表現を学習するということにある。決してアクティ</nobr></div>
<div style="position:absolute;top:42401;left:128"><nobr>ブにならないようなカラムは必要でない。そうならないために、各カラムがその周囲の</nobr></div>
<div style="position:absolute;top:42428;left:128"><nobr>カラムと相対的にどのくらい頻繁にアクティブになるかを常に監視する。カラムがアク</nobr></div>
<div style="position:absolute;top:42455;left:128"><nobr>ティブになる相対的な頻度が低すぎるときは、そのカラムが勝者となるカラムの集合に</nobr></div>
<div style="position:absolute;top:42482;left:128"><nobr>含まれ始めるようになるまで、その入力がアクティブになる基準をブースト<font style="font-size:8px">36</font>する。本</nobr></div>
<div style="position:absolute;top:42509;left:128"><nobr>質的に、すべてのカラムは周囲のカラムと互いに競合しており、入力パターンに対する</nobr></div>
<div style="position:absolute;top:42536;left:128"><nobr>表現に加わろうとしている。あるカラムがほとんどアクティブにならないときは、その</nobr></div>
<div style="position:absolute;top:42563;left:128"><nobr>カラムはもっと積極的になる。そうなると、他のカラムはその入力を変更させられて少</nobr></div>
<div style="position:absolute;top:42590;left:128"><nobr>しだけ異なる入力パターンを表現し始める。</nobr></div>
<div style="position:absolute;top:42647;left:128"><nobr><b>2) </b>望ましい密度を維持する</nobr></div>
<div style="position:absolute;top:42671;left:155"><nobr>リージョンは入力に対する疎な表現を形成する必要がある。最大の入力を受け取っ</nobr></div>
<div style="position:absolute;top:42698;left:128"><nobr>たカラムは周囲のカラムを抑制する。抑制範囲を決める半径は、そのカラムの受容野<font style="font-size:8px">37</font></nobr></div>
<div style="position:absolute;top:42725;left:128"><nobr>のサイズに比例する（従ってまた、小さなサイズからリージョン全体に至る範囲を取る）。</nobr></div>
<div style="position:absolute;top:42752;left:128"><nobr>抑制半径の範囲内では、多くのアクティブな入力を受け取ったわずかなパーセンテージ</nobr></div>
<div style="position:absolute;top:42779;left:128"><nobr>のカラムだけを「勝者」とする。その他のカラムは無効化される。（抑制「半径」の語</nobr></div>
<div style="position:absolute;top:42806;left:128"><nobr>感は二次元状に配置されたカラムを暗示しているが、この概念は他のトポロジにも適用</nobr></div>
<div style="position:absolute;top:42833;left:128"><nobr>できる）</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:42901;left:128"><nobr>36 <font style="font-size:12px">boost。後押しする、増強するなどの意。後述のアルゴリズムでブースト値という変数が出現するため、</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:42921;left:141"><nobr>そのままブーストと訳した。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:42940;left:128"><nobr>37 <font style="font-size:12px">receptive field </font></nobr></div>
</span></font>

<div style="position:absolute;top:43083;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=35><b>Page 35</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:44265;left:437"><nobr><b>35</b></nobr></div>
<div style="position:absolute;top:43239;left:128"><nobr><b>3) </b>些細なパターンを避ける</nobr></div>
<div style="position:absolute;top:43264;left:155"><nobr>すべてのカラムが些細ではない入力パターンを表すことが望まれる。この到達目標</nobr></div>
<div style="position:absolute;top:43291;left:128"><nobr>は、カラムがアクティブになるために必要な最小のしきい値を設定することで達成でき</nobr></div>
<div style="position:absolute;top:43318;left:128"><nobr>る。例えば、しきい値を 50 とすると、カラムがアクティブになるにはその樹状突起セ</nobr></div>
<div style="position:absolute;top:43345;left:128"><nobr>グメント上のアクティブなシナプスが 50 個以上必要であり、これによりあるレベル以</nobr></div>
<div style="position:absolute;top:43372;left:128"><nobr>上に複雑なパターンだけが表現されることが保証される。</nobr></div>
<div style="position:absolute;top:43428;left:128"><nobr><b>4) </b>余分な接続関係を避ける</nobr></div>
<div style="position:absolute;top:43453;left:155"><nobr>よく注意しないと、あるカラムが巨大な数の有効なシナプスを保持することが起こ</nobr></div>
<div style="position:absolute;top:43480;left:128"><nobr>りうる。すると、あまり関連性のない多くの異なる入力パターンに強く反応するように</nobr></div>
<div style="position:absolute;top:43507;left:128"><nobr>なる。シナプスの異なる部分集合は異なるパターンに反応するだろう。この問題を避け</nobr></div>
<div style="position:absolute;top:43534;left:128"><nobr>るため、勝者カラムに現在貢献していないシナプスすべてについて、その永続値を減少</nobr></div>
<div style="position:absolute;top:43561;left:128"><nobr>させる。貢献していないシナプスに確実に十分なペナルティを与えることで、一つのカ</nobr></div>
<div style="position:absolute;top:43588;left:128"><nobr>ラムが表現する入力パターンが限定されることを保証し、それはときには一つだけのこ</nobr></div>
<div style="position:absolute;top:43615;left:128"><nobr>ともある。</nobr></div>
<div style="position:absolute;top:43671;left:128"><nobr><b>5) </b>自己調整的な受容野</nobr></div>
<div style="position:absolute;top:43696;left:155"><nobr>実物の脳は高い可塑性<font style="font-size:8px">38</font>を示す。新皮質のリージョンは、様々な変化に反応してま</nobr></div>
<div style="position:absolute;top:43723;left:128"><nobr>ったく異なる事柄の表現を学習できる。もし新皮質の一部が損傷したら、損傷した部分</nobr></div>
<div style="position:absolute;top:43750;left:128"><nobr>が表現していたものを他の部分によって表現するように調整される。もし感覚器官が損</nobr></div>
<div style="position:absolute;top:43777;left:128"><nobr>傷したり変化したりすると、それに関連付けられていた部分の新皮質は何か他のことを</nobr></div>
<div style="position:absolute;top:43804;left:128"><nobr>表現するように調整される。システムは自己調整的である。我々の HTM リージョンに</nobr></div>
<div style="position:absolute;top:43831;left:128"><nobr>も同様の柔軟性を求めたい。あるリージョンに 10,000 個のカラムを割り当てたら、入</nobr></div>
<div style="position:absolute;top:43858;left:128"><nobr>力を 10,000 個のカラムで最適に表現する方法を学習するべきである。あるリージョン</nobr></div>
<div style="position:absolute;top:43885;left:128"><nobr>に 20,000 個のカラムを割り当てたら、その数を使う最適な方法を学習するべきである。</nobr></div>
<div style="position:absolute;top:43912;left:128"><nobr>入力の統計的性質が変化したら、カラムはその新たな事実を最適に表現するように変化</nobr></div>
<div style="position:absolute;top:43939;left:128"><nobr>するべきである。まとめると、HTM の設計者はリージョンに任意のリソースを割り当</nobr></div>
<div style="position:absolute;top:43966;left:128"><nobr>てることができて、そのリージョンは利用可能なカラムと入力の統計的性質に基づいて</nobr></div>
<div style="position:absolute;top:43993;left:128"><nobr>入力を最適に表現するという仕事ができるべきである。一般的な規則は、リージョンの</nobr></div>
<div style="position:absolute;top:44020;left:128"><nobr>カラムがより多くあれば、各カラムは入力のより大きくより詳細なパターンを表現する</nobr></div>
<div style="position:absolute;top:44047;left:128"><nobr>ということである。なお一定の粗さを保つが<font style="font-size:8px">39</font>、カラムは普通、より稀にアクティブに</nobr></div>
<div style="position:absolute;top:44074;left:128"><nobr>なる。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:44141;left:128"><nobr>38 <font style="font-size:12px">plastic。かそせい。物理的な可塑性とは固体に外力を加えて変形させ、力を取り去ってももとに戻ら</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:44162;left:141"><nobr>ない性質のこと。脳の可塑性とは経験に応じて神経回路の組み換えや再構成を行う能力のこと。柔軟</nobr></div>
<div style="position:absolute;top:44182;left:141"><nobr>性、適応性。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:44201;left:128"><nobr>39 <font style="font-size:12px">粗さ(sparsity)はアクティブになるカラムの割合。カラムの数が増えても粗さは一定ということ。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:44345;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=36><b>Page 36</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:45527;left:437"><nobr><b>36</b></nobr></div>
<div style="position:absolute;top:44499;left:155"><nobr>これらの非常に望ましい到達目標を達成するために、新しい学習規則は必要ない。</nobr></div>
<div style="position:absolute;top:44526;left:128"><nobr>アクティブでないカラムをブーストし、粗さを一定に保つために周囲のカラムを抑制し、</nobr></div>
<div style="position:absolute;top:44553;left:128"><nobr>入力に対するしきい値の最小値を設け、多くのシナプス候補を蓄積・維持し、その貢献</nobr></div>
<div style="position:absolute;top:44580;left:128"><nobr>度に応じてシナプスを追加・削除することで、全体効果としてカラムは望ましい効果を</nobr></div>
<div style="position:absolute;top:44607;left:128"><nobr>達成するように動的に設定される。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:44687;left:128"><nobr>空間プーリングの詳細</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:44736;left:155"><nobr>空間プーリングが行うすべてについて述べる。</nobr></div>
<div style="position:absolute;top:44793;left:128"><nobr>1) 固定の数のビットからなる入力から始める。これらのビットはセンサからのデータ</nobr></div>
<div style="position:absolute;top:44817;left:155"><nobr>であったり、階層構造の下位の他のリージョンからであったりする。</nobr></div>
<div style="position:absolute;top:44847;left:128"><nobr>2) この入力を受取る固定の数のカラムをリージョンに割り当てる。各カラムはそれに</nobr></div>
<div style="position:absolute;top:44871;left:155"><nobr>連結された樹状突起セグメントを持つ。各樹状突起セグメントは入力ビットの部分</nobr></div>
<div style="position:absolute;top:44898;left:155"><nobr>集合を表すシナプス候補の集合を持つ。各シナプス候補は永続値を持つ。その永続</nobr></div>
<div style="position:absolute;top:44925;left:155"><nobr>値に基づいて、いくつかのシナプス候補が有効になる。</nobr></div>
<div style="position:absolute;top:44955;left:128"><nobr>3) 与えられた任意の入力について、アクティブな入力ビットと接続している有効なシ</nobr></div>
<div style="position:absolute;top:44979;left:155"><nobr>ナプスの数を各カラムごとに求める。</nobr></div>
<div style="position:absolute;top:45009;left:128"><nobr>4) アクティブなシナプスの数にブースト値<font style="font-size:8px">40</font>を乗じる。ブースト値は、そのカラムが</nobr></div>
<div style="position:absolute;top:45033;left:155"><nobr>周囲のものに比べてどのくらい頻繁にアクティブになったかに基づいて動的に決め</nobr></div>
<div style="position:absolute;top:45060;left:155"><nobr>られる。</nobr></div>
<div style="position:absolute;top:45090;left:128"><nobr>5) ブースト後に最大のアクティベーションを得たカラムは、抑制半径内の固定のパー</nobr></div>
<div style="position:absolute;top:45114;left:155"><nobr>センテージのカラム以外のものを無効化する。抑制半径はそれ自体、入力ビットの</nobr></div>
<div style="position:absolute;top:45141;left:155"><nobr>広がり具合（又はファン・アウト）から動的に決定される。これでアクティブなカ</nobr></div>
<div style="position:absolute;top:45168;left:155"><nobr>ラムの疎な集合が得られた。</nobr></div>
<div style="position:absolute;top:45198;left:128"><nobr>6) アクティブなカラムのそれぞれについて、すべてのシナプス候補の永続値を調節す</nobr></div>
<div style="position:absolute;top:45222;left:155"><nobr>る。アクティブな入力に割り当てられたシナプスの永続値は増加させる。非アクテ</nobr></div>
<div style="position:absolute;top:45249;left:155"><nobr>ィブな入力に割り当てられたシナプスの永続値は減少させる。永続値の変更により、</nobr></div>
<div style="position:absolute;top:45276;left:155"><nobr>いくつかのシナプスが有効になったり無効になったりする。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:45357;left:128"><nobr>時間プーリングの概念</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:45464;left:128"><nobr>40 <font style="font-size:12px">boosting factor </font></nobr></div>
</span></font>

<div style="position:absolute;top:45607;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=37><b>Page 37</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:46789;left:437"><nobr><b>37</b></nobr></div>
<div style="position:absolute;top:45761;left:155"><nobr>時間プーリングがシーケンスを学習し、予測をすることを思い出して欲しい。基本</nobr></div>
<div style="position:absolute;top:45788;left:128"><nobr>的な方法は、あるセルがアクティブになったら直前にアクティブであった他のセルとの</nobr></div>
<div style="position:absolute;top:45815;left:128"><nobr>接続を形成することである。これによりセルは、そのセルの接続を調べることでいつそ</nobr></div>
<div style="position:absolute;top:45842;left:128"><nobr>れがアクティブになるかを予測できるようになる。すべてのセルがこれを行えば、全体</nobr></div>
<div style="position:absolute;top:45869;left:128"><nobr>としてそれらはシーケンスを記憶してそれを思い出し、次に何が起こると考えられるか</nobr></div>
<div style="position:absolute;top:45896;left:128"><nobr>を予測できる。パターンのシーケンスを記憶するための集中記憶装置はなく、その代わ</nobr></div>
<div style="position:absolute;top:45923;left:128"><nobr>りに記憶は各セルに分散配置される。記憶が分散しているため、システムはノイズや誤</nobr></div>
<div style="position:absolute;top:45950;left:128"><nobr>りに強くなる。個々のセルが失敗しても、通常それによる影響はわずかないし全くない。</nobr></div>
<div style="position:absolute;top:45977;left:128"><nobr>なお、時間プーリングが利用している、疎分散表現の重要な特徴を 2, 3 述べておくこ</nobr></div>
<div style="position:absolute;top:46004;left:128"><nobr>とは価値がある。</nobr></div>
<div style="position:absolute;top:46031;left:155"><nobr>仮想的に、あるリージョンが全部で 10,000 個あるセルのうち、常に 200 個のセル</nobr></div>
<div style="position:absolute;top:46058;left:128"><nobr>がアクティブになることで表現を形成しているとしよう（任意の時点で 2%のセルがア</nobr></div>
<div style="position:absolute;top:46085;left:128"><nobr>クティブ）。200 個のアクティブなセルで表される特定のパターンを記憶・理解するに</nobr></div>
<div style="position:absolute;top:46112;left:128"><nobr>はどうすればよいだろうか。これを行う単純な方法は、関心がある 200 個のアクティ</nobr></div>
<div style="position:absolute;top:46139;left:128"><nobr>ブなセルのリストを作成することである。ちょうど同じ 200 個のセルが再びアクティ</nobr></div>
<div style="position:absolute;top:46166;left:128"><nobr>ブになったことが分かれば、そのパターンを理解したことになる。しかしながら、200</nobr></div>
<div style="position:absolute;top:46193;left:128"><nobr>個のアクティブなセルのうち 20 個だけのリストを作成して、残りの 180 個を無視した</nobr></div>
<div style="position:absolute;top:46220;left:128"><nobr>としたらどうだろうか？ 何が起こるだろうか？ 20 個のセルだけを記憶したら、200</nobr></div>
<div style="position:absolute;top:46247;left:128"><nobr>個のセルの異なるパターンにおいてそれら 20 個の部分がちょうどアクティブになるよ</nobr></div>
<div style="position:absolute;top:46274;left:128"><nobr>うなパターンが数多く存在して、間違いだらけになると読者は考えるかも知れない。し</nobr></div>
<div style="position:absolute;top:46301;left:128"><nobr>かしそうはならない。パターンは大きくかつ疎であるため（この例では 10,000 個のう</nobr></div>
<div style="position:absolute;top:46328;left:128"><nobr>ち 200 個のセルがアクティブ）、20 個のアクティブなセルを記憶することで 200 個す</nobr></div>
<div style="position:absolute;top:46355;left:128"><nobr>べてを記憶することとほとんど同じくらいうまく記憶できる。実際のシステムで間違い</nobr></div>
<div style="position:absolute;top:46382;left:128"><nobr>が起こる可能性は極めて稀で、必要なメモリ量を非常に節約できる。</nobr></div>
<div style="position:absolute;top:46407;left:155"><nobr>HTM リージョンのセルはこの特徴を利用している。各セルの樹状突起セグメント</nobr></div>
<div style="position:absolute;top:46436;left:128"><nobr>は同じセル内の他のセルへの接続関係の集合を持つ。樹状突起セグメントはある時点で</nobr></div>
<div style="position:absolute;top:46463;left:128"><nobr>のネットワークの状態を理解する手段とするため、これらの接続を形成している。周囲</nobr></div>
<div style="position:absolute;top:46490;left:128"><nobr>のアクティブなセルは数百から数千あるかも知れないが、樹状突起セグメントが接続し</nobr></div>
<div style="position:absolute;top:46517;left:128"><nobr>なければならないのはこのうちの 15 から 20 程度に過ぎない。樹状突起セグメントに</nobr></div>
<div style="position:absolute;top:46544;left:128"><nobr>接続する 15 個のセルがアクティブと分かれば、その大きなパターンが発生していると</nobr></div>
<div style="position:absolute;top:46571;left:128"><nobr>ほぼ確信できる。このテクニックを「サブサンプリング」と呼び、HTM アルゴリズム</nobr></div>
<div style="position:absolute;top:46598;left:128"><nobr>全体を通じて利用している。</nobr></div>
<div style="position:absolute;top:46625;left:155"><nobr>各セルは多くの異なる分散パターンに関与し、また多くの異なるシーケンスに関与</nobr></div>
<div style="position:absolute;top:46652;left:128"><nobr>している。ある特定のセルは数十から数百の時間的遷移に関与しているかも知れない。</nobr></div>
<div style="position:absolute;top:46679;left:128"><nobr>従って各セルは一つではなく、いくつかの樹状突起セグメントを持つ。理想的にはセル</nobr></div>
<div style="position:absolute;top:46706;left:128"><nobr>が理解したいアクティビティの各パターンごとに一つの樹状突起セグメントを持つこ</nobr></div>
</span></font>

<div style="position:absolute;top:46869;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=38><b>Page 38</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:48051;left:437"><nobr><b>38</b></nobr></div>
<div style="position:absolute;top:47023;left:128"><nobr>とが望ましい。しかしながら実際には、樹状突起セグメントはいくつかの完全に異なる</nobr></div>
<div style="position:absolute;top:47050;left:128"><nobr>パターンに関して接続を学習することができ、それでもうまく行く。例えば、一つのセ</nobr></div>
<div style="position:absolute;top:47077;left:128"><nobr>グメントが 4 つの異なるパターンのそれぞれについて 20 個の接続を持ち、都合 80 個</nobr></div>
<div style="position:absolute;top:47104;left:128"><nobr>の接続を持つとする。そして、これらの接続のうち任意の 15 個がアクティブなときに</nobr></div>
<div style="position:absolute;top:47131;left:128"><nobr>樹状突起セグメントがアクティブとなるようにしきい値を設定する。これにより誤りが</nobr></div>
<div style="position:absolute;top:47158;left:128"><nobr>発生する可能性が生じる。異なるパターンが混在することで、樹状突起セグメントのア</nobr></div>
<div style="position:absolute;top:47185;left:128"><nobr>クティブな接続に関する 15 個のしきい値に到達する可能性がある。しかしながら、表</nobr></div>
<div style="position:absolute;top:47212;left:128"><nobr>現の疎な性質により、このような誤りは非常に起こりにくい。</nobr></div>
<div style="position:absolute;top:47239;left:155"><nobr>では、10 個から 20 個の樹状突起セグメントを持つセルと数千個のシナプスがどの</nobr></div>
<div style="position:absolute;top:47266;left:128"><nobr>ようにして数百種類のセルのアクティブ状態を理解するのかを見ていこう。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:47347;left:128"><nobr>時間プーリングの詳細</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:47395;left:155"><nobr>時間プーリングで行われるステップを数え上げていく。空間プーリングを終えてフ</nobr></div>
<div style="position:absolute;top:47422;left:128"><nobr>ィード・フォワード入力を表現するアクティブなカラムの集合が得られたところから始</nobr></div>
<div style="position:absolute;top:47449;left:128"><nobr>める。</nobr></div>
<div style="position:absolute;top:47506;left:128"><nobr>1) それぞれのアクティブなカラムについて、カラムの中のセルで予測状態のものを調</nobr></div>
<div style="position:absolute;top:47530;left:155"><nobr>べ、アクティブにする。すべてのセルが予測状態でないなら、カラム中のすべての</nobr></div>
<div style="position:absolute;top:47557;left:155"><nobr>セルをアクティブにする。結果として得られたアクティブなセルの集合は、以前の</nobr></div>
<div style="position:absolute;top:47584;left:155"><nobr>入力の文脈の下での入力表現である。</nobr></div>
<div style="position:absolute;top:47614;left:128"><nobr>2) リージョンのすべてのセルの各樹状突起セグメントについて、アクティブなセルに</nobr></div>
<div style="position:absolute;top:47638;left:155"><nobr>接続されている接続状態のシナプスの数を数える。もしその数がしきい値を超えて</nobr></div>
<div style="position:absolute;top:47665;left:155"><nobr>いれば、その樹状突起セグメントをアクティブとして印を付ける。アクティブな樹</nobr></div>
<div style="position:absolute;top:47692;left:155"><nobr>状突起セグメントを持つセルを、それがフィード・フォワード入力によって既にア</nobr></div>
<div style="position:absolute;top:47719;left:155"><nobr>クティブでない限り、予測状態にする。アクティブな樹状突起を持たず、フィード・</nobr></div>
<div style="position:absolute;top:47746;left:155"><nobr>フォワード入力によりアクティブになっていないセルは、非アクティブにする。以</nobr></div>
<div style="position:absolute;top:47773;left:155"><nobr>上により、予測状態のセル全体がそのリージョンの予測となる。</nobr></div>
<div style="position:absolute;top:47803;left:128"><nobr>3) 樹状突起セグメントがアクティブになったとき、そのセグメント上のすべてのシナ</nobr></div>
<div style="position:absolute;top:47827;left:155"><nobr>プスの永続値を更新する。そのアクティブな樹状突起セグメントのすべてのシナプ</nobr></div>
<div style="position:absolute;top:47854;left:155"><nobr>ス候補について、アクティブなセルに接続しているシナプスの永続値を増加させ、</nobr></div>
<div style="position:absolute;top:47881;left:155"><nobr>非アクティブなセルに接続しているシナプスの永続値を減少させる。シナプスの永</nobr></div>
<div style="position:absolute;top:47908;left:155"><nobr>続値に対するこれらの変更に一時的と印を付ける。</nobr></div>
<div style="position:absolute;top:47935;left:155"><nobr>これはセグメントをアクティブにし、従ってまた予測をするほど既に十分に訓練さ</nobr></div>
<div style="position:absolute;top:47962;left:155"><nobr>れたシナプスを更新する。しかしながら、可能であればさらに時間をさかのぼって</nobr></div>
</span></font>

<div style="position:absolute;top:48131;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=39><b>Page 39</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:49313;left:437"><nobr><b>39</b></nobr></div>
<div style="position:absolute;top:48285;left:155"><nobr>予測ができるように常に拡張したい。このため、同じセルの二番目の樹状突起セグ</nobr></div>
<div style="position:absolute;top:48312;left:155"><nobr>メントを取り上げ、訓練する。二番目のセグメントとして、以前の時刻ステップの</nobr></div>
<div style="position:absolute;top:48339;left:155"><nobr>シナプスの状態に最もマッチするものを一つ選択する。このセグメントに対して、</nobr></div>
<div style="position:absolute;top:48366;left:155"><nobr>以前の時刻ステップのシステムの状態を用いて、アクティブなセルに接続している</nobr></div>
<div style="position:absolute;top:48393;left:155"><nobr>シナプスの永続値を増加させ、非アクティブなセルに接続しているシナプスの永続</nobr></div>
<div style="position:absolute;top:48420;left:155"><nobr>値を減少させる。シナプスの永続値に対するこれらの変更に一時的と印を付ける。</nobr></div>
<div style="position:absolute;top:48449;left:128"><nobr>4) あるセルがフィード・フォワード入力によって予測状態からアクティブ状態<font style="font-size:8px">41</font>に変</nobr></div>
<div style="position:absolute;top:48474;left:155"><nobr>化したときはいつも、そのセルに関連付けられているすべてのシナプス候補の「一</nobr></div>
<div style="position:absolute;top:48501;left:155"><nobr>時的」の印を削除する。従ってフィード・フォワードによってセルがアクティブ化</nobr></div>
<div style="position:absolute;top:48528;left:155"><nobr>したことを正しく予測したときだけ、シナプスの永続値を更新する。</nobr></div>
<div style="position:absolute;top:48557;left:128"><nobr>5) セルがアクティブ状態から非アクティブ状態に変化したとき、このセルのすべての</nobr></div>
<div style="position:absolute;top:48582;left:155"><nobr>シナプス候補について一時的な永続値の変更を元に戻す。フィード・フォワードに</nobr></div>
<div style="position:absolute;top:48609;left:155"><nobr>よってセルがアクティブ化したことを間違って予測したときはシナプスの永続値を</nobr></div>
<div style="position:absolute;top:48636;left:155"><nobr>強化したくないため。</nobr></div>
<div style="position:absolute;top:48690;left:155"><nobr>フィード・フォワードによってアクティブになったセルだけを処理するのはリージ</nobr></div>
<div style="position:absolute;top:48717;left:128"><nobr>ョンの <font style="font-size:15px">内部だけ　</font>であって、それ以外では予測はさらなる予測を引き起こすことに注意。</nobr></div>
<div style="position:absolute;top:48744;left:128"><nobr>しかし（フィード・フォワードと予測の）すべてのアクティブなセルはリージョンの出</nobr></div>
<div style="position:absolute;top:48771;left:128"><nobr>力となり、階層構造の <font style="font-size:15px">次の　</font>リージョンへと引き継がれる。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:48852;left:128"><nobr>一次と可変長<b><font style="font-size:11px">42</font></b>のシーケンスと予測</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:48900;left:155"><nobr>空間プーリングと時間プーリングの議論を終える前に、もう一つ大きな論点がある。</nobr></div>
<div style="position:absolute;top:48927;left:128"><nobr>すべての読者の興味を引かないかも知れないし、また第３章と第４章を理解する上では</nobr></div>
<div style="position:absolute;top:48954;left:128"><nobr>必要ないけれども。</nobr></div>
<div style="position:absolute;top:48981;left:155"><nobr>一つのカラムに対するセルの数を増やしたときないし減らしたときの効果はどうな</nobr></div>
<div style="position:absolute;top:49008;left:128"><nobr>るだろうか？ 特に、１カラムに１つのセルしかないときは何が起こるだろうか？</nobr></div>
<div style="position:absolute;top:49035;left:155"><nobr>以前用いた例では、カラム当たり４セルのアクティブなカラムが 100 個の場合、入</nobr></div>
<div style="position:absolute;top:49062;left:128"><nobr>力の表現は 4<font style="font-size:8px">100 </font>通りの異なるコード化が可能であることを示した。従って、同じ入力が</nobr></div>
<div style="position:absolute;top:49089;left:128"><nobr>様々な文脈の中で出現しても混乱しないようにできる。例えば、もし入力パターンが単</nobr></div>
<div style="position:absolute;top:49116;left:128"><nobr>語を表すなら、リージョンは同じ単語が何度も使われる多くの文章を混乱することなく</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:49173;left:128"><nobr>41 <font style="font-size:12px">原文は“inactive to active”となっているが、web 上の forum で“predictive state to active state”の間</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:49193;left:141"><nobr>違いだったとの訂正があった。(2010/12/14 Sabutai: title “Cortical Algorithms document: praise</nobr></div>
<div style="position:absolute;top:49211;left:141"><nobr>and suggestions”)</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:49229;left:128"><nobr>42 <font style="font-size:12px">“first order” と “variable order”。前者は一つだけの長さのシーケンスと予測、後者は任意の長さの</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:49249;left:141"><nobr>シーケンスと予測。 </nobr></div>
</span></font>

<div style="position:absolute;top:49393;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=40><b>Page 40</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:50575;left:437"><nobr><b>40</b></nobr></div>
<div style="position:absolute;top:49547;left:128"><nobr>記憶できる。「犬」のような単語が異なる文脈の中でユニークな表現を持つことができ</nobr></div>
<div style="position:absolute;top:49574;left:128"><nobr>る。この能力により HTM リージョンは可変長の予測が可能となる。</nobr></div>
<div style="position:absolute;top:49601;left:155"><nobr>可変長予測は現在起きていることだけではなく、可変の長さの過去の文脈に基づい</nobr></div>
<div style="position:absolute;top:49628;left:128"><nobr>て予測する。HTM リージョンは可変長の記憶である。</nobr></div>
<div style="position:absolute;top:49655;left:155"><nobr>カラム当たり 5 セルに増やすと、任意の特定の入力に対して可能なコード化の数は</nobr></div>
<div style="position:absolute;top:49680;left:128"><nobr>5<font style="font-size:8px">100 </font>に増加し、4<font style="font-size:8px">100 </font>よりずっと大きくなる。しかしこれらの数は両方とも非常に大きく、</nobr></div>
<div style="position:absolute;top:49709;left:128"><nobr>多くの現実的な問題においてこの容量の増加はあまり役に立たないだろう。</nobr></div>
<div style="position:absolute;top:49736;left:155"><nobr>しかしながら、カラム当たりのセルの数をこれより少なくすると、大きな違いが生</nobr></div>
<div style="position:absolute;top:49763;left:128"><nobr>まれる。</nobr></div>
<div style="position:absolute;top:49790;left:155"><nobr>もしカラム当たり１セルまでになると、文脈の中で表現する能力を失ってしまう。</nobr></div>
<div style="position:absolute;top:49817;left:128"><nobr>リージョンへの入力は、以前の活動に関係なく常に同じ予測を引き起こす結果となる。</nobr></div>
<div style="position:absolute;top:49844;left:128"><nobr>カラム当たり１セルの場合、HTM リージョンの記憶は一次記憶となり、予測は現在の</nobr></div>
<div style="position:absolute;top:49871;left:128"><nobr>入力だけに基づいて行われる。</nobr></div>
<div style="position:absolute;top:49898;left:155"><nobr>一次予測は脳が解くことのできるある種の問題 ―静的空間推論― に理想的であ</nobr></div>
<div style="position:absolute;top:49925;left:128"><nobr>る。既に述べたように、人は短時間だけ画像を見せられたとき、目が後を追うには短か</nobr></div>
<div style="position:absolute;top:49952;left:128"><nobr>すぎる時間であってもその物体を理解できる。ものを聞くとき、それが何であれ理解す</nobr></div>
<div style="position:absolute;top:49979;left:128"><nobr>るには常にパターンのシーケンスを聞く必要がある。視覚も普通はそれに似ていて、視</nobr></div>
<div style="position:absolute;top:50006;left:128"><nobr>覚的イメージの流れを処理する必要がある。しかしある条件下では、一瞬のイメージだ</nobr></div>
<div style="position:absolute;top:50033;left:128"><nobr>けでも理解できることがある。</nobr></div>
<div style="position:absolute;top:50060;left:155"><nobr>時間的理解と静的理解とでは、異なる推論メカニズムが必要とされているように思</nobr></div>
<div style="position:absolute;top:50087;left:128"><nobr>われる。一方は可変長の文脈に基づいてパターンのシーケンスを理解し、予測をする必</nobr></div>
<div style="position:absolute;top:50114;left:128"><nobr>要がある。他方は時間的文脈を使わずに静的な空間的パターンを理解する必要がある。</nobr></div>
<div style="position:absolute;top:50141;left:128"><nobr>カラム当たり複数のセルを持つ HTM リージョンは時間に基づくシーケンスを理解す</nobr></div>
<div style="position:absolute;top:50168;left:128"><nobr>るのに理想的であり、カラム当たり１セルの HTM リージョンは空間的パターンを理解</nobr></div>
<div style="position:absolute;top:50195;left:128"><nobr>するのに理想的である。Numenta では、カラム当たり１セルのリージョンを視覚問題</nobr></div>
<div style="position:absolute;top:50222;left:128"><nobr>に適用した実験を数多く実施した。これらの実験の詳細はこの章の範囲を超えるが、重</nobr></div>
<div style="position:absolute;top:50249;left:128"><nobr>要な概念だけ述べる。</nobr></div>
<div style="position:absolute;top:50274;left:155"><nobr>HTM リージョンにイメージを入力すると、リージョン内のカラムは画素の共通の</nobr></div>
<div style="position:absolute;top:50303;left:128"><nobr>空間的配列の表現を学習する。学習するパターンの種類は新皮質の V1 野（生物学で広</nobr></div>
<div style="position:absolute;top:50330;left:128"><nobr>く研究されている新皮質のリージョン）で観察されるものと似ていて、概ね、異なる角</nobr></div>
<div style="position:absolute;top:50357;left:128"><nobr>度の線と角である。動画像で訓練すると、HTM リージョンはこれらの基本的な形の遷</nobr></div>
<div style="position:absolute;top:50384;left:128"><nobr>移を学習する。例えばある箇所に垂直な線があって、左又は右に移動した垂直な線がそ</nobr></div>
<div style="position:absolute;top:50411;left:128"><nobr>れに続くということがよくある。よく観察されるパターンの遷移は HTM リージョンで</nobr></div>
<div style="position:absolute;top:50438;left:128"><nobr>記憶される。 </nobr></div>
</span></font>

<div style="position:absolute;top:50655;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=41><b>Page 41</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:51837;left:437"><nobr><b>41</b></nobr></div>
<div style="position:absolute;top:50809;left:155"><nobr>もしリージョンへの入力画像が、垂直な線が右に移動するものだったら何が起こる</nobr></div>
<div style="position:absolute;top:50836;left:128"><nobr>だろうか？ カラム当たり１セルしかなかったら、線が次に左又は右に現れること<font style="font-size:8px">43</font>を</nobr></div>
<div style="position:absolute;top:50863;left:128"><nobr>予測できるだろう。線が過去にどこにあったか知っているという文脈を使うことができ</nobr></div>
<div style="position:absolute;top:50890;left:128"><nobr>ないため、それが左ないし右に移動していることを知ることはできない。このようなカ</nobr></div>
<div style="position:absolute;top:50917;left:128"><nobr>ラム当たり１セルのものは、新皮質の「複雑型細胞」<font style="font-size:8px">44</font>のように振舞うと分かるだろう。</nobr></div>
<div style="position:absolute;top:50944;left:128"><nobr>そのようなセルの予測出力は、その線が左や右に動いていようがいまいが異なる位置に</nobr></div>
<div style="position:absolute;top:50971;left:128"><nobr>ある視覚的な線に対してアクティブになるだろう。このようなリージョンは異なるイメ</nobr></div>
<div style="position:absolute;top:50998;left:128"><nobr>ージを区別する能力を保持する一方で、平行移動や大きさの変化に対して安定性を示す</nobr></div>
<div style="position:absolute;top:51025;left:128"><nobr>ことが我々の観察から分かった。このような振る舞いは、空間的不変性（同じパターン</nobr></div>
<div style="position:absolute;top:51052;left:128"><nobr>の異なる見方を理解すること）のために必要である。</nobr></div>
<div style="position:absolute;top:51079;left:155"><nobr>もし同じ実験をカラム当たり複数のセルを持つ HTM リージョンに対して行えば、</nobr></div>
<div style="position:absolute;top:51106;left:128"><nobr>そのセルが新皮質の「方位選択性複雑型細胞」<font style="font-size:8px">45</font>のように振舞うと分かるだろう。セル</nobr></div>
<div style="position:absolute;top:51133;left:128"><nobr>の予測出力は左に移動する線や右に移動する線に対してアクティブになるが、両方に対</nobr></div>
<div style="position:absolute;top:51160;left:128"><nobr>してはアクティブにならないだろう。</nobr></div>
<div style="position:absolute;top:51187;left:155"><nobr>これらをまとめて、我々は次のような仮説を立てた。新皮質は一次と可変長の両方</nobr></div>
<div style="position:absolute;top:51214;left:128"><nobr>の推論及び予測をしなければならない。新皮質の各リージョンには 4 又は 5 層のセルが</nobr></div>
<div style="position:absolute;top:51241;left:128"><nobr>ある。層は様々な形に異なっているが、それらはすべてカラム単位で応答する性質を共</nobr></div>
<div style="position:absolute;top:51268;left:128"><nobr>有しており、その層内で水平方向に大きな接続性を持っている。新皮質のセルの層はそ</nobr></div>
<div style="position:absolute;top:51295;left:128"><nobr>れぞれ、この章で述べたような HTM の推論と学習に似たことを実行しているのではな</nobr></div>
<div style="position:absolute;top:51322;left:128"><nobr>いか、と我々は推測した。異なる層のセルは異なる役割を演じている。例えば解剖学に</nobr></div>
<div style="position:absolute;top:51349;left:128"><nobr>よれば第 6 層は階層構造のフィードバックを形成し、第 5 層は運動の動作に関わってい</nobr></div>
<div style="position:absolute;top:51376;left:128"><nobr>る。セルの 2 つの主要なフィード・フォワード層は第 4 層と第 3 層である。第 4 層と</nobr></div>
<div style="position:absolute;top:51403;left:128"><nobr>第 3 層の一つの違いは、第 4 層のセルが独立に、即ちカラムの中で１セルだけが動作す</nobr></div>
<div style="position:absolute;top:51430;left:128"><nobr>るのに対して、第 3 層のセルはカラムの中で複数のセルが動作することだろうと我々は</nobr></div>
<div style="position:absolute;top:51457;left:128"><nobr>推測した。よってセンサ入力に近い新皮質のリージョンは一次記憶と可変長記憶の両方</nobr></div>
<div style="position:absolute;top:51484;left:128"><nobr>を持つ。一次シーケンス記憶（だいたい第４層のニューロンに対応する）は空間的に不</nobr></div>
<div style="position:absolute;top:51511;left:128"><nobr>変の表現を形成するのに役立つ。可変長シーケンス記憶（だいだい第 3 層のニューロン</nobr></div>
<div style="position:absolute;top:51538;left:128"><nobr>に対応する）は動画像の推論と予測に役立つ。</nobr></div>
<div style="position:absolute;top:51565;left:155"><nobr>まとめると我々は、この章で述べたようなアルゴリズムは新皮質のニューロンのす</nobr></div>
<div style="position:absolute;top:51592;left:128"><nobr>べての層で働いているという仮説を立てた。新皮質の層の詳細は大きく違っていて、フ</nobr></div>
<div style="position:absolute;top:51619;left:128"><nobr>ィード・フォワードとフィードバック、注意<font style="font-size:8px">46</font>、運動動作<font style="font-size:8px">47</font>に関する異なる役割を演じ</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:51703;left:128"><nobr>43 <font style="font-size:12px">「移動する」ことは予測できないが、隣の位置に「出現する」ことは予測できるということ。</font></nobr></div>
<div style="position:absolute;top:51721;left:128"><nobr>44 <font style="font-size:12px">complex cell</font></nobr></div>
<div style="position:absolute;top:51738;left:128"><nobr>45 <font style="font-size:12px">directionally-tuned complex cell</font></nobr></div>
<div style="position:absolute;top:51755;left:128"><nobr>46 <font style="font-size:12px">attention</font></nobr></div>
<div style="position:absolute;top:51772;left:128"><nobr>47 <font style="font-size:12px">motor behavior </font></nobr></div>
</span></font>

<div style="position:absolute;top:51917;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=42><b>Page 42</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:53099;left:437"><nobr><b>42</b></nobr></div>
<div style="position:absolute;top:52071;left:128"><nobr>ている。センサ入力に近いリージョンでは、一次記憶を実行するニューロンの層が空間</nobr></div>
<div style="position:absolute;top:52098;left:128"><nobr>的不変性に有利であるため役に立つ。</nobr></div>
<div style="position:absolute;top:52127;left:155"><nobr>Numenta では、一次（カラム当たり１セル）の HTM リージョンを画像認識問題に</nobr></div>
<div style="position:absolute;top:52152;left:128"><nobr>適用する実験をした。我々はまた、可変長（カラム当たり複数セル）の HTM リージョ</nobr></div>
<div style="position:absolute;top:52179;left:128"><nobr>ンに可変長のシーケンスを理解・予測させる実験をした。将来的には、これらを一つの</nobr></div>
<div style="position:absolute;top:52206;left:128"><nobr>リージョンに混在させ、他の目的にもアルゴリズムを拡張することを試みることは理に</nobr></div>
<div style="position:absolute;top:52233;left:128"><nobr>かなっている。しかしながら、一つの層と等価なカラム当たり複数セルの構造が、単体</nobr></div>
<div style="position:absolute;top:52260;left:128"><nobr>であれ複数階層であれ、多くの興味深い問題を取り扱いうると我々は信じている。 </nobr></div>
</span></font>

<div style="position:absolute;top:53179;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=43><b>Page 43</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:54361;left:437"><nobr><b>43</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:53390;left:128"><nobr>第３章：　空間プーリングの実装と疑似コード</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:53442;left:155"><nobr>本章では空間プーリング関数<font style="font-size:8px">48</font>の最初の実装の疑似コードを詳細に示す。このコー</nobr></div>
<div style="position:absolute;top:53469;left:128"><nobr>ドの入力は、センサー・データ又は前のレベルからのバイナリ配列である。このコード</nobr></div>
<div style="position:absolute;top:53496;left:128"><nobr>は activeColumns(t) を計算する。activeColumns(t) は時刻 t において、フィード・</nobr></div>
<div style="position:absolute;top:53523;left:128"><nobr>フォワード入力に対して選択されたカラムのリストである。このリストは、次章で述べ</nobr></div>
<div style="position:absolute;top:53550;left:128"><nobr>る時間プーリング関数の入力として送られる。即ち、activeColumns(t) は空間プーリ</nobr></div>
<div style="position:absolute;top:53577;left:128"><nobr>ング関数の出力である。</nobr></div>
<div style="position:absolute;top:53604;left:155"><nobr>疑似コードは３つのフェーズに明確に分かれる。これらは順に実行される。</nobr></div>
<div style="position:absolute;top:53658;left:149"><nobr>フェーズ 1: 各カラムについて、現在の入力のオーバラップを計算する。</nobr></div>
<div style="position:absolute;top:53685;left:149"><nobr>フェーズ 2: 抑制の後に勝者となったカラムを計算する。</nobr></div>
<div style="position:absolute;top:53712;left:149"><nobr>フェーズ 3: シナプスの永続値と内部変数を更新する。</nobr></div>
<div style="position:absolute;top:53766;left:155"><nobr>空間プーリングの学習はオンライン<font style="font-size:8px">49</font>で行われるが、フェーズ 3 を単にスキップす</nobr></div>
<div style="position:absolute;top:53793;left:128"><nobr>ることで学習をしないようにすることもできる。</nobr></div>
<div style="position:absolute;top:53820;left:155"><nobr>以下、３つのフェーズのそれぞれについて疑似コードを示す。疑似コードの中で使</nobr></div>
<div style="position:absolute;top:53847;left:128"><nobr>用されている様々なデータ構造や補助関数は本章の最後に示す。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:53915;left:128"><nobr>初期化</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:53949;left:155"><nobr>最初の入力を受け取る前に、各カラムの最初のシナプス候補のリストを計算してリ</nobr></div>
<div style="position:absolute;top:53976;left:128"><nobr>ージョンを初期化する。これは入力配列の中からランダムに選択された入力位置のリス</nobr></div>
<div style="position:absolute;top:54003;left:128"><nobr>トで構成される。各入力はシナプスで表現され、ランダムな永続値が割り当てられる。</nobr></div>
<div style="position:absolute;top:54030;left:128"><nobr>ランダムな永続値は二つの条件を満たすように選ばれる。第一に、その値は</nobr></div>
<div style="position:absolute;top:54059;left:128"><nobr>connectedPerm（シナプスが「接続している」と判定される最小の永続値）の前後の狭</nobr></div>
<div style="position:absolute;top:54084;left:128"><nobr>い範囲から選ばれる。これにより、訓練を少ない回数繰り返しただけで、シナプス候補</nobr></div>
<div style="position:absolute;top:54111;left:128"><nobr>が接続（ないし切断）することを可能とする。第二に、各カラムは入力リージョン上で</nobr></div>
<div style="position:absolute;top:54138;left:128"><nobr>自然な中心位置があり、永続値はこの中心に向かってバイアスを加えられる。（中心付</nobr></div>
<div style="position:absolute;top:54165;left:128"><nobr>近ではより高い値を与えられる）</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:54278;left:128"><nobr>48 <font style="font-size:12px">spatial pooler function</font></nobr></div>
<div style="position:absolute;top:54297;left:128"><nobr>49 <font style="font-size:12px">online。推論の計算と学習の計算を分離せずに、同時に行うということ。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:54441;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=44><b>Page 44</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:55623;left:437"><nobr><b>44</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:54594;left:128"><nobr>フェーズ <b>1: </b>オーバラップ</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:54628;left:155"><nobr>最初のフェーズでは、与えられた入力ベクトルについて、そのベクトルと各カラム</nobr></div>
<div style="position:absolute;top:54655;left:128"><nobr>のオーバラップを計算する。各カラムのオーバラップは、アクティブな入力と接続され</nobr></div>
<div style="position:absolute;top:54682;left:128"><nobr>たシナプスの数を数え、それにブースト値を掛けたものである。もしこの値が</nobr></div>
<div style="position:absolute;top:54711;left:128"><nobr>minOverlap を下回っている場合、オーバラップは 0 とする。</nobr></div>
<div style="position:absolute;top:54766;left:157"><nobr>1.  <b>for </b>c <b>in </b>columns </nobr></div>
<div style="position:absolute;top:54793;left:157"><nobr>2. </nobr></div>
<div style="position:absolute;top:54820;left:157"><nobr>3.  </nobr></div>
<div style="position:absolute;top:54820;left:255"><nobr>overlap(c) = 0 </nobr></div>
<div style="position:absolute;top:54848;left:157"><nobr>4.  </nobr></div>
<div style="position:absolute;top:54848;left:255"><nobr><b>for </b>s <b>in </b>connectedSynapses(c) </nobr></div>
<div style="position:absolute;top:54874;left:157"><nobr>5.  </nobr></div>
<div style="position:absolute;top:54874;left:323"><nobr>overlap(c) = overlap(c) + input(t, s.sourceInput) </nobr></div>
<div style="position:absolute;top:54901;left:157"><nobr>6. </nobr></div>
<div style="position:absolute;top:54929;left:157"><nobr>7.  </nobr></div>
<div style="position:absolute;top:54929;left:255"><nobr><b>if </b>overlap(c) &lt; minOverlap <b>then</b></nobr></div>
<div style="position:absolute;top:54955;left:157"><nobr>8.  </nobr></div>
<div style="position:absolute;top:54955;left:323"><nobr>overlap(c) = 0 </nobr></div>
<div style="position:absolute;top:54983;left:157"><nobr>9.  </nobr></div>
<div style="position:absolute;top:54983;left:255"><nobr><b>else</b></nobr></div>
<div style="position:absolute;top:55009;left:157"><nobr>10.  </nobr></div>
<div style="position:absolute;top:55009;left:323"><nobr>overlap(c) = overlap(c) * boost(c) </nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:55076;left:128"><nobr>フェーズ <b>2: </b>抑制</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:55110;left:155"><nobr>第 2 のフェーズでは、抑制の後に勝者となったカラムを計算する。</nobr></div>
<div style="position:absolute;top:55139;left:128"><nobr>desiredLocalActivity は勝者となるカラムの数を制御するパラメータである。例えば、</nobr></div>
<div style="position:absolute;top:55166;left:128"><nobr>desiredLocalActivity を 10 とすると、抑制半径の範囲内においてカラムのオーバラップ</nobr></div>
<div style="position:absolute;top:55191;left:128"><nobr>値が高い順に 10 位以内のカラムが勝者となる。</nobr></div>
<div style="position:absolute;top:55248;left:157"><nobr>11.  <b>for </b>c <b>in </b>columns </nobr></div>
<div style="position:absolute;top:55275;left:157"><nobr>12. </nobr></div>
<div style="position:absolute;top:55302;left:157"><nobr>13.  </nobr></div>
<div style="position:absolute;top:55302;left:258"><nobr>minLocalActivity = kthScore(neighbors(c), desiredLocalActivity) </nobr></div>
<div style="position:absolute;top:55329;left:157"><nobr>14. </nobr></div>
<div style="position:absolute;top:55356;left:157"><nobr>15.  </nobr></div>
<div style="position:absolute;top:55356;left:258"><nobr><b>if </b>overlap(c) &gt; 0 <b>and </b>overlap(c) ? minLocalActivity <b>then</b></nobr></div>
<div style="position:absolute;top:55383;left:157"><nobr>16.  </nobr></div>
<div style="position:absolute;top:55383;left:322"><nobr>activeColumns(t).append(c) </nobr></div>
<div style="position:absolute;top:55410;left:157"><nobr>17. </nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:55477;left:128"><nobr>フェーズ <b>3: </b>学習</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:55510;left:155"><nobr>第 3 のフェーズは学習を実行する。これによりすべてのシナプスの永続値は必要に</nobr></div>
<div style="position:absolute;top:55537;left:128"><nobr>応じて更新され、ブースト値と抑制半径を更新する。 </nobr></div>
</span></font>

<div style="position:absolute;top:55703;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=45><b>Page 45</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:56885;left:437"><nobr><b>45</b></nobr></div>
<div style="position:absolute;top:55857;left:155"><nobr>主要な学習規則は 20-26 行目で実装されている。勝者となったカラムのそれぞれに</nobr></div>
<div style="position:absolute;top:55884;left:128"><nobr>ついて、もしあるシナプスがアクティブであればその永続値をインクリンメントし、そ</nobr></div>
<div style="position:absolute;top:55911;left:128"><nobr>の他の場合はデクリメントする。永続値は 0 から 1 の範囲内に束縛される。</nobr></div>
<div style="position:absolute;top:55936;left:155"><nobr>28-36 行目ではブーストを実装している。カラムが接続を学習するための二つの独</nobr></div>
<div style="position:absolute;top:55965;left:128"><nobr>立したブースト機構がある。あるカラムがあまり勝者となっていない（activeDutyCycle</nobr></div>
<div style="position:absolute;top:55992;left:128"><nobr>で観測される）とき、そのブースト値をインクリメントする（30-32 行目）。一方、あ</nobr></div>
<div style="position:absolute;top:56019;left:128"><nobr>るカラムのシナプスがどの入力ともあまりオーバラップしない<font style="font-size:8px">50</font>（overlapDutyCycle で</nobr></div>
<div style="position:absolute;top:56046;left:128"><nobr>観測される）とき、その永続値がブーストされる（34-36 行目）。ノート：学習モード</nobr></div>
<div style="position:absolute;top:56073;left:128"><nobr>がオフになると、ブースト値は固定される。</nobr></div>
<div style="position:absolute;top:56100;left:155"><nobr>フェーズ 3 の最後に、抑制半径を再計算する（38 行目）。</nobr></div>
<div style="position:absolute;top:56157;left:157"><nobr>18.  <b>for </b>c <b>in </b>activeColumns(t) </nobr></div>
<div style="position:absolute;top:56184;left:157"><nobr>19. </nobr></div>
<div style="position:absolute;top:56211;left:157"><nobr>20.  </nobr></div>
<div style="position:absolute;top:56211;left:257"><nobr><b>for </b>s <b>in </b>potentialSynapses(c) </nobr></div>
<div style="position:absolute;top:56238;left:157"><nobr>21.  </nobr></div>
<div style="position:absolute;top:56238;left:326"><nobr><b>if </b>active(s) <b>then</b></nobr></div>
<div style="position:absolute;top:56265;left:157"><nobr>22.  </nobr></div>
<div style="position:absolute;top:56265;left:391"><nobr>s.permanence += permanenceInc </nobr></div>
<div style="position:absolute;top:56292;left:157"><nobr>23.  </nobr></div>
<div style="position:absolute;top:56292;left:391"><nobr>s.permanence = min(1.0, s.permanence) </nobr></div>
<div style="position:absolute;top:56319;left:157"><nobr>24.  </nobr></div>
<div style="position:absolute;top:56319;left:326"><nobr><b>else</b></nobr></div>
<div style="position:absolute;top:56346;left:157"><nobr>25.  </nobr></div>
<div style="position:absolute;top:56346;left:391"><nobr>s.permanence -= permanenceDec </nobr></div>
<div style="position:absolute;top:56373;left:157"><nobr>26.  </nobr></div>
<div style="position:absolute;top:56373;left:391"><nobr>s.permanence = max(0.0, s.permanence) </nobr></div>
<div style="position:absolute;top:56400;left:157"><nobr>27. </nobr></div>
<div style="position:absolute;top:56427;left:157"><nobr>28.  <b>for </b>c <b>in </b>columns: </nobr></div>
<div style="position:absolute;top:56454;left:157"><nobr>29. </nobr></div>
<div style="position:absolute;top:56481;left:157"><nobr>30.  </nobr></div>
<div style="position:absolute;top:56481;left:257"><nobr>minDutyCycle(c) = 0.01 * maxDutyCycle(neighbors(c)) </nobr></div>
<div style="position:absolute;top:56508;left:157"><nobr>31.  </nobr></div>
<div style="position:absolute;top:56508;left:257"><nobr>activeDutyCycle(c) = updateActiveDutyCycle(c) </nobr></div>
<div style="position:absolute;top:56535;left:157"><nobr>32.  </nobr></div>
<div style="position:absolute;top:56535;left:257"><nobr>boost(c) = boostFunction(activeDutyCycle(c), minDutyCycle(c)) </nobr></div>
<div style="position:absolute;top:56562;left:157"><nobr>33. </nobr></div>
<div style="position:absolute;top:56589;left:157"><nobr>34.  </nobr></div>
<div style="position:absolute;top:56589;left:257"><nobr>overlapDutyCycle(c) = updateOverlapDutyCycle(c) </nobr></div>
<div style="position:absolute;top:56616;left:157"><nobr>35.  </nobr></div>
<div style="position:absolute;top:56616;left:257"><nobr><b>if </b>overlapDutyCycle(c) &lt; minDutyCycle(c) <b>then</b></nobr></div>
<div style="position:absolute;top:56643;left:157"><nobr>36.  </nobr></div>
<div style="position:absolute;top:56643;left:326"><nobr>increasePermanences(c, 0.1*connectedPerm) </nobr></div>
<div style="position:absolute;top:56670;left:157"><nobr>37. </nobr></div>
<div style="position:absolute;top:56697;left:157"><nobr>38.  inhibitionRadius = averageReceptiveFieldSize() </nobr></div>
<div style="position:absolute;top:56724;left:157"><nobr>39. </nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:56821;left:128"><nobr>50 <font style="font-size:12px">オーバラップ値が小さい </font></nobr></div>
</span></font>

<div style="position:absolute;top:56965;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=46><b>Page 46</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:58147;left:437"><nobr><b>46</b></nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:57145;left:128"><nobr>データ構造と補助関数</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:57194;left:155"><nobr>以下の変数とデータ構造が疑似コードで使用されている。</nobr></div>
<div style="position:absolute;top:57251;left:136"><nobr>columns</nobr></div>
<div style="position:absolute;top:57249;left:306"><nobr>すべてのカラムのリスト</nobr></div>
<div style="position:absolute;top:57283;left:136"><nobr>input(t,j)</nobr></div>
<div style="position:absolute;top:57280;left:306"><nobr>時刻t におけるこのレベルへの入力。j 番目の入力がオンのと</nobr></div>
<div style="position:absolute;top:57307;left:306"><nobr>き、input(t, j) は1である。</nobr></div>
<div style="position:absolute;top:57338;left:136"><nobr>overlap(<i>c</i>)</nobr></div>
<div style="position:absolute;top:57335;left:306"><nobr>ある入力パターンに対する、カラムc の空間プーリング・オ</nobr></div>
<div style="position:absolute;top:57362;left:306"><nobr>ーバラップ</nobr></div>
<div style="position:absolute;top:57392;left:136"><nobr>activeColumns(<i>t</i>)</nobr></div>
<div style="position:absolute;top:57390;left:306"><nobr>フィード・フォワード入力により勝者となったカラムの添え</nobr></div>
<div style="position:absolute;top:57417;left:306"><nobr>字のリスト</nobr></div>
<div style="position:absolute;top:57447;left:136"><nobr>desiredLocalActivity 抑制ステップの後に勝者となるカラムの数を制御するパラメ</nobr></div>
<div style="position:absolute;top:57472;left:306"><nobr>ータ</nobr></div>
<div style="position:absolute;top:57502;left:136"><nobr>inhibitionRadius</nobr></div>
<div style="position:absolute;top:57499;left:306"><nobr>カラムに接続された受容野<font style="font-size:8px">51</font>のサイズの平均値</nobr></div>
<div style="position:absolute;top:57533;left:136"><nobr>neighbors(c)</nobr></div>
<div style="position:absolute;top:57531;left:306"><nobr>カラムc から inhibitionRadius の範囲内にあるすべてのカラ</nobr></div>
<div style="position:absolute;top:57558;left:306"><nobr>ムのリスト</nobr></div>
<div style="position:absolute;top:57588;left:136"><nobr>minOverlap</nobr></div>
<div style="position:absolute;top:57586;left:306"><nobr>抑制ステップで処理対象となるべきカラムのアクティブな入</nobr></div>
<div style="position:absolute;top:57613;left:306"><nobr>力の最小の数<font style="font-size:8px">52</font></nobr></div>
<div style="position:absolute;top:57643;left:136"><nobr>boost(c)</nobr></div>
<div style="position:absolute;top:57641;left:306"><nobr>学習のときに計算される、カラムc のブースト値。この値は</nobr></div>
<div style="position:absolute;top:57668;left:306"><nobr>アクティブでないカラムのオーバラップ値を増加させるため</nobr></div>
<div style="position:absolute;top:57695;left:306"><nobr>に使われる。</nobr></div>
<div style="position:absolute;top:57725;left:136"><nobr>synapse</nobr></div>
<div style="position:absolute;top:57722;left:306"><nobr>シナプスを表すデータ構造。永続値と接続元の入力の添え字</nobr></div>
<div style="position:absolute;top:57749;left:306"><nobr>からなる。</nobr></div>
<div style="position:absolute;top:57779;left:136"><nobr>connectedPerm</nobr></div>
<div style="position:absolute;top:57777;left:306"><nobr>もしあるシナプスの永続値がこの値よりも大きければ、接続</nobr></div>
<div style="position:absolute;top:57804;left:306"><nobr>していると判定される</nobr></div>
<div style="position:absolute;top:57834;left:136"><nobr>potentialSynapses</nobr></div>
<div style="position:absolute;top:57861;left:136"><nobr>(c)</nobr></div>
<div style="position:absolute;top:57832;left:306"><nobr>シナプス候補とその永続値のリスト</nobr></div>
<div style="position:absolute;top:57889;left:136"><nobr>connectedSynapses</nobr></div>
<div style="position:absolute;top:57916;left:136"><nobr>(c)</nobr></div>
<div style="position:absolute;top:57889;left:306"><nobr>potentialSynapses(c) の部分集合で、永続値がconnectedPerm</nobr></div>
<div style="position:absolute;top:57914;left:306"><nobr>以上のものからなる。これらは現在カラムc に接続されてい</nobr></div>
<div style="position:absolute;top:57941;left:306"><nobr>るフィード・フォワード入力である。</nobr></div>
<div style="position:absolute;top:57971;left:136"><nobr>permanenceInc</nobr></div>
<div style="position:absolute;top:57968;left:306"><nobr>学習時にシナプスの永続値を増加させる増分値</nobr></div>
<div style="position:absolute;top:58002;left:136"><nobr>permanenceDec</nobr></div>
<div style="position:absolute;top:58000;left:306"><nobr>学習時にシナプスの永続値を減少させる減少値</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:58063;left:128"><nobr>51 <font style="font-size:12px">巻末の用語の説明参照</font></nobr></div>
<div style="position:absolute;top:58083;left:128"><nobr>52 <font style="font-size:12px">あるカラムへのアクティブな入力がこの数以上であれば、抑制ステップで処理対象となる。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:58227;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=47><b>Page 47</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:59409;left:437"><nobr><b>47</b></nobr></div>
<div style="position:absolute;top:58384;left:136"><nobr>activeDutyCycle(c)</nobr></div>
<div style="position:absolute;top:58382;left:306"><nobr>抑制の後にカラムc がアクティブになった頻度を表す移動平</nobr></div>
<div style="position:absolute;top:58409;left:306"><nobr>均値（例えば直近1000回繰り返した間にアクティブになった</nobr></div>
<div style="position:absolute;top:58436;left:306"><nobr>回数）</nobr></div>
<div style="position:absolute;top:58466;left:136"><nobr>overlapDutyCycle(c) カラムc がその入力に対して有意なオーバラップ値（即ち、</nobr></div>
<div style="position:absolute;top:58493;left:306"><nobr>minOverlapより大きな値）になった頻度を表す移動平均値（例</nobr></div>
<div style="position:absolute;top:58518;left:306"><nobr>えば直近1000回繰り返した間に有意なオーバラップ値になっ</nobr></div>
<div style="position:absolute;top:58545;left:306"><nobr>た回数）</nobr></div>
<div style="position:absolute;top:58575;left:136"><nobr>minDutyCycle(c)</nobr></div>
<div style="position:absolute;top:58572;left:306"><nobr>最小限望まれるセルの発火頻度を表す変数。あるセルの発火</nobr></div>
<div style="position:absolute;top:58599;left:306"><nobr>頻度がこの値を下回れば、それはブーストされる。この値は</nobr></div>
<div style="position:absolute;top:58626;left:306"><nobr>その付近のカラムの最大の発火頻度の1%として計算する。</nobr></div>
<div style="position:absolute;top:58681;left:155"><nobr>以下の補助関数が疑似コードで使用されている。</nobr></div>
<div style="position:absolute;top:58738;left:136"><nobr>kthScore(cols, k) </nobr></div>
<div style="position:absolute;top:58736;left:306"><nobr>与えられたカラムのリストに対して、k番目のオーバラップ値</nobr></div>
<div style="position:absolute;top:58763;left:306"><nobr>を返す</nobr></div>
<div style="position:absolute;top:58793;left:136"><nobr>updateActiveDutyCy</nobr></div>
<div style="position:absolute;top:58820;left:136"><nobr>cle(c) </nobr></div>
<div style="position:absolute;top:58791;left:306"><nobr>抑制の後にカラムc がアクティブになった頻度の移動平均を</nobr></div>
<div style="position:absolute;top:58818;left:306"><nobr>計算する</nobr></div>
<div style="position:absolute;top:58848;left:136"><nobr>updateOverlapDuty</nobr></div>
<div style="position:absolute;top:58875;left:136"><nobr>Cycle(c) </nobr></div>
<div style="position:absolute;top:58845;left:306"><nobr>カラムc のオーバラップ値がminOverlap より大きくなった</nobr></div>
<div style="position:absolute;top:58872;left:306"><nobr>頻度の移動平均を計算する</nobr></div>
<div style="position:absolute;top:58902;left:136"><nobr>averageReceptiveFi</nobr></div>
<div style="position:absolute;top:58929;left:136"><nobr>eldSize()</nobr></div>
<div style="position:absolute;top:58900;left:306"><nobr>カラムに接続された受容野の半径についての、すべてのカラ</nobr></div>
<div style="position:absolute;top:58927;left:306"><nobr>ムの平均値。カラムに接続された受容野は接続されたシナプ</nobr></div>
<div style="position:absolute;top:58954;left:306"><nobr>ス（永続値≧connectedPermのもの）だけが含まれる。これは</nobr></div>
<div style="position:absolute;top:58981;left:306"><nobr>カラム間の横方向の抑制範囲を決めるために用いられる。</nobr></div>
<div style="position:absolute;top:59011;left:136"><nobr>maxDutyCycle(cols)  与えられたカラムのリストのうち、activeDutyCycle が最大の</nobr></div>
<div style="position:absolute;top:59036;left:306"><nobr>ものを返す</nobr></div>
<div style="position:absolute;top:59066;left:136"><nobr>increasePermanenc</nobr></div>
<div style="position:absolute;top:59093;left:136"><nobr>es(c, s) </nobr></div>
<div style="position:absolute;top:59064;left:306"><nobr>カラムc のすべてのシナプスの永続値をスケール因子s に従</nobr></div>
<div style="position:absolute;top:59091;left:306"><nobr>って増加させる</nobr></div>
<div style="position:absolute;top:59121;left:136"><nobr>boostFunction(c) </nobr></div>
<div style="position:absolute;top:59118;left:306"><nobr>カラムc のブースト値を返す。ブースト値は1以上のスカラ値</nobr></div>
<div style="position:absolute;top:59146;left:306"><nobr>である。activeDutyCycle(c) が minDutyCycle(c) より大きけ</nobr></div>
<div style="position:absolute;top:59173;left:306"><nobr>ればブースト値は1。activeDutyCycle が minDutyCycle より</nobr></div>
<div style="position:absolute;top:59200;left:306"><nobr>下回り始めて以降は、ブースト値はリニアに増加する。 </nobr></div>
</span></font>

<div style="position:absolute;top:59489;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=48><b>Page 48</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:60671;left:437"><nobr><b>48</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:59700;left:128"><nobr>第４章：　時間プーリングの実装と疑似コード</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:59752;left:155"><nobr>本章では時間プーリング関数<font style="font-size:8px">53</font>の最初の実装の疑似コードを詳細に示す。このコー</nobr></div>
<div style="position:absolute;top:59779;left:128"><nobr>ドの入力は空間プーリング関数で計算した activeColumns(t) である。このコードは時</nobr></div>
<div style="position:absolute;top:59806;left:128"><nobr>刻 t における各セルのアクティブ状態及び予測状態を計算する。アクティブ状態と予測</nobr></div>
<div style="position:absolute;top:59833;left:128"><nobr>状態の論理和が時間プーリング関数の出力であり、次のレベルの入力である。</nobr></div>
<div style="position:absolute;top:59860;left:155"><nobr>疑似コードは３つのフェーズに明確に分かれる。これらは順に実行される。</nobr></div>
<div style="position:absolute;top:59914;left:149"><nobr>フェーズ 1: 各セルについてアクティブ状態 activeState(t) を計算する。</nobr></div>
<div style="position:absolute;top:59941;left:149"><nobr>フェーズ 2: 各セルについて予測状態 predictiveState(t) を計算する。</nobr></div>
<div style="position:absolute;top:59968;left:149"><nobr>フェーズ 3: シナプスを更新する。</nobr></div>
<div style="position:absolute;top:60022;left:155"><nobr>フェーズ 3 は学習するときにだけ必要となる。しかしながら、空間プーリングのと</nobr></div>
<div style="position:absolute;top:60049;left:128"><nobr>きとは異なり、学習が有効のときはフェーズ 1 と 2 も学習特有の操作をいくつか含んで</nobr></div>
<div style="position:absolute;top:60076;left:128"><nobr>いる。時間プーリングは空間プーリングよりかなり複雑であるため、先ずは時間プーリ</nobr></div>
<div style="position:absolute;top:60103;left:128"><nobr>ングの推論だけのバージョンを示し、次に推論と学習を含むバージョンを示す。補助関</nobr></div>
<div style="position:absolute;top:60130;left:128"><nobr>数は疑似コードの後に、本章の最後に示す。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:60210;left:128"><nobr>時間プーリング疑似コード：　推論だけのバージョン</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:60267;left:128"><nobr>フェーズ <b>1</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:60301;left:155"><nobr>第 1 のフェーズでは、各セルのアクティブ状態を計算する。勝者となった各カラム</nobr></div>
<div style="position:absolute;top:60328;left:128"><nobr>について、どのセルをアクティブにするのかを決定する。フィード・フォワード入力が</nobr></div>
<div style="position:absolute;top:60355;left:128"><nobr>いずれかのセルによって予測された（即ち、前回の時刻ステップで順序セグメントによ</nobr></div>
<div style="position:absolute;top:60382;left:128"><nobr>って predictiveState が 1 になった）とき、それらのセルをアクティブにする（4-9 行目）。</nobr></div>
<div style="position:absolute;top:60409;left:128"><nobr>フィード・フォワード入力が予測されなかった（どのセルも predictiveState がオンにな</nobr></div>
<div style="position:absolute;top:60436;left:128"><nobr>らなかった）とき、そのカラムのすべてのセルをアクティブにする（11-13 行目）。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:60608;left:128"><nobr>53 <font style="font-size:12px">temporal pooler function </font></nobr></div>
</span></font>

<div style="position:absolute;top:60751;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=49><b>Page 49</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:61933;left:437"><nobr><b>49</b></nobr></div>
<div style="position:absolute;top:60908;left:157"><nobr>1.  <b>for </b>c <b>in </b>activeColumns(t) </nobr></div>
<div style="position:absolute;top:60935;left:157"><nobr>2. </nobr></div>
<div style="position:absolute;top:60962;left:157"><nobr>3.  </nobr></div>
<div style="position:absolute;top:60962;left:260"><nobr>buPredicted = <b>false</b></nobr></div>
<div style="position:absolute;top:60989;left:157"><nobr>4.  </nobr></div>
<div style="position:absolute;top:60989;left:260"><nobr><b>for </b>i = 0 <b>to </b>cellsPerColumn - 1 </nobr></div>
<div style="position:absolute;top:61016;left:157"><nobr>5.  </nobr></div>
<div style="position:absolute;top:61016;left:323"><nobr><b>if </b>predictiveState(c, i, t-1) == <b>true then</b></nobr></div>
<div style="position:absolute;top:61043;left:157"><nobr>6.  </nobr></div>
<div style="position:absolute;top:61043;left:389"><nobr>s = getActiveSegment(c, i, t-1, activeState) </nobr></div>
<div style="position:absolute;top:61070;left:157"><nobr>7.  </nobr></div>
<div style="position:absolute;top:61070;left:389"><nobr><b>if </b>s.sequenceSegment == <b>true then</b></nobr></div>
<div style="position:absolute;top:61097;left:157"><nobr>8.  </nobr></div>
<div style="position:absolute;top:61097;left:455"><nobr>buPredicted = <b>true</b></nobr></div>
<div style="position:absolute;top:61124;left:157"><nobr>9.  </nobr></div>
<div style="position:absolute;top:61124;left:455"><nobr>activeState(c, i, t) = 1 </nobr></div>
<div style="position:absolute;top:61151;left:157"><nobr>10. </nobr></div>
<div style="position:absolute;top:61178;left:157"><nobr>11.  </nobr></div>
<div style="position:absolute;top:61178;left:260"><nobr><b>if </b>buPredicted == <b>false then</b></nobr></div>
<div style="position:absolute;top:61205;left:157"><nobr>12.  </nobr></div>
<div style="position:absolute;top:61205;left:323"><nobr><b>for </b>i = 0 <b>to </b>cellsPerColumn - 1 </nobr></div>
<div style="position:absolute;top:61232;left:157"><nobr>13.  </nobr></div>
<div style="position:absolute;top:61232;left:389"><nobr>activeState(c, i, t) = 1</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:61299;left:128"><nobr>フェーズ <b>2</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:61333;left:155"><nobr>第 2 のフェーズでは、各セルの予測状態を計算する。セルのどれかのセグメントが</nobr></div>
<div style="position:absolute;top:61360;left:128"><nobr>アクティブになると、そのセルの predictiveState がオンになる。即ち、十分な数の横</nobr></div>
<div style="position:absolute;top:61387;left:128"><nobr>方向の接続先が、フィード・フォワード入力によって現在発火していればオンになる。</nobr></div>
<div style="position:absolute;top:61444;left:157"><nobr>14.  <b>for </b>c, i <b>in </b>cells </nobr></div>
<div style="position:absolute;top:61471;left:157"><nobr>15.  </nobr></div>
<div style="position:absolute;top:61471;left:257"><nobr><b>for </b>s <b>in </b>segments(c, i) </nobr></div>
<div style="position:absolute;top:61498;left:157"><nobr>16.  </nobr></div>
<div style="position:absolute;top:61498;left:327"><nobr><b>if </b>segmentActive(c, i, s, t) <b>then</b></nobr></div>
<div style="position:absolute;top:61525;left:157"><nobr>17.  </nobr></div>
<div style="position:absolute;top:61525;left:389"><nobr>predictiveState(c, i, t) = 1 </nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:61603;left:128"><nobr>時間プーリング疑似コード：　推論と学習を含むバージョン</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:61661;left:128"><nobr>フェーズ <b>1</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:61694;left:155"><nobr>第 1 のフェーズでは、勝者となったカラム中の各セルの activeState を計算する。そ</nobr></div>
<div style="position:absolute;top:61721;left:128"><nobr>れらのカラムについて、コードはさらにカラムごとに一つのセルを学習セル</nobr></div>
<div style="position:absolute;top:61750;left:128"><nobr>(learnState)として選択する<font style="font-size:8px">54</font>。そのロジックは以下の通り。フィード・フォワード入力</nobr></div>
<div style="position:absolute;top:61775;left:128"><nobr>がいずれかのセルによって予測された（即ち、順序セグメントによって predictiveState</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:61830;left:128"><nobr>54 <font style="font-size:12px">lcChosen は学習セルが選択されたこと（learn cell chosen）を表し、(c, i) が選択された学習セル、</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:61850;left:141"><nobr>そして learnState(c, i, t) =1 に設定されることでこのセルが学習セルとして選択されたことを記憶す</nobr></div>
<div style="position:absolute;top:61869;left:141"><nobr>る。 </nobr></div>
</span></font>

<div style="position:absolute;top:62013;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=50><b>Page 50</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:63195;left:437"><nobr><b>50</b></nobr></div>
<div style="position:absolute;top:62167;left:128"><nobr>が 1 になった）とき<font style="font-size:8px">55</font>、それらのセルをアクティブにする（23-27 行目）。そのセグメ</nobr></div>
<div style="position:absolute;top:62194;left:128"><nobr>ントが、learnState がオンのセルによってアクティブになった場合、そのセルは学習セ</nobr></div>
<div style="position:absolute;top:62221;left:128"><nobr>ルとして選択される（28-30 行目）。フィード・フォワード入力が予測されなかったと</nobr></div>
<div style="position:absolute;top:62248;left:128"><nobr>き、そのカラムのすべてのセルをアクティブにする（32-34 行目）。さらに、ベストマ</nobr></div>
<div style="position:absolute;top:62275;left:128"><nobr>ッチセルが学習セルとして選択され（36-41 行目）、新しいセグメントがそのセルに追</nobr></div>
<div style="position:absolute;top:62302;left:128"><nobr>加される。</nobr></div>
<div style="position:absolute;top:62359;left:157"><nobr>18.  <b>for </b>c <b>in </b>activeColumns(t) </nobr></div>
<div style="position:absolute;top:62386;left:157"><nobr>19. </nobr></div>
<div style="position:absolute;top:62413;left:157"><nobr>20.  </nobr></div>
<div style="position:absolute;top:62413;left:245"><nobr>buPredicted = <b>false</b></nobr></div>
<div style="position:absolute;top:62440;left:157"><nobr>21.  </nobr></div>
<div style="position:absolute;top:62440;left:245"><nobr>lcChosen = <b>false</b></nobr></div>
<div style="position:absolute;top:62467;left:157"><nobr>22.  </nobr></div>
<div style="position:absolute;top:62467;left:245"><nobr><b>for </b>i = 0 <b>to </b>cellsPerColumn - 1 </nobr></div>
<div style="position:absolute;top:62494;left:157"><nobr>23.  </nobr></div>
<div style="position:absolute;top:62494;left:298"><nobr><b>if </b>predictiveState(c, i, t-1) == <b>true then</b></nobr></div>
<div style="position:absolute;top:62521;left:157"><nobr>24.  </nobr></div>
<div style="position:absolute;top:62521;left:351"><nobr>s = getActiveSegment(c, i, t-1, activeState) </nobr></div>
<div style="position:absolute;top:62548;left:157"><nobr>25.  </nobr></div>
<div style="position:absolute;top:62548;left:351"><nobr><b>if </b>s.sequenceSegment == <b>true then</b></nobr></div>
<div style="position:absolute;top:62575;left:157"><nobr>26.  </nobr></div>
<div style="position:absolute;top:62575;left:404"><nobr>buPredicted = <b>true</b></nobr></div>
<div style="position:absolute;top:62602;left:157"><nobr>27.  </nobr></div>
<div style="position:absolute;top:62602;left:404"><nobr>activeState(c, i, t) = 1 </nobr></div>
<div style="position:absolute;top:62629;left:157"><nobr>28.  </nobr></div>
<div style="position:absolute;top:62629;left:404"><nobr><b>if </b>segmentActive(s, t-1, learnState) <b>then</b></nobr></div>
<div style="position:absolute;top:62656;left:157"><nobr>29.  </nobr></div>
<div style="position:absolute;top:62656;left:457"><nobr>lcChosen = true </nobr></div>
<div style="position:absolute;top:62683;left:157"><nobr>30.  </nobr></div>
<div style="position:absolute;top:62683;left:457"><nobr>learnState(c, i, t) = 1 </nobr></div>
<div style="position:absolute;top:62710;left:157"><nobr>31. </nobr></div>
<div style="position:absolute;top:62737;left:157"><nobr>32.  </nobr></div>
<div style="position:absolute;top:62737;left:245"><nobr><b>if </b>buPredicted == <b>false then</b></nobr></div>
<div style="position:absolute;top:62764;left:157"><nobr>33.  </nobr></div>
<div style="position:absolute;top:62764;left:298"><nobr><b>for </b>i = 0 <b>to </b>cellsPerColumn - 1 </nobr></div>
<div style="position:absolute;top:62791;left:157"><nobr>34.  </nobr></div>
<div style="position:absolute;top:62791;left:351"><nobr>activeState(c, i, t) = 1 </nobr></div>
<div style="position:absolute;top:62818;left:157"><nobr>35. </nobr></div>
<div style="position:absolute;top:62845;left:157"><nobr>36.  </nobr></div>
<div style="position:absolute;top:62845;left:245"><nobr><b>if </b>lcChosen == false <b>then</b></nobr></div>
<div style="position:absolute;top:62872;left:157"><nobr>37.  </nobr></div>
<div style="position:absolute;top:62872;left:298"><nobr>I,s = getBestMatchingCell(c, t-1) </nobr></div>
<div style="position:absolute;top:62899;left:157"><nobr>38.  </nobr></div>
<div style="position:absolute;top:62899;left:298"><nobr>learnState(c, i, t) = 1 </nobr></div>
<div style="position:absolute;top:62926;left:157"><nobr>39.  </nobr></div>
<div style="position:absolute;top:62926;left:298"><nobr>sUpdate = getSegmentActiveSynapses (c, i, s, t-1, <b>true</b>) </nobr></div>
<div style="position:absolute;top:62953;left:157"><nobr>40.  </nobr></div>
<div style="position:absolute;top:62953;left:298"><nobr>sUpdate.sequenceSegment = <b>true</b></nobr></div>
<div style="position:absolute;top:62980;left:157"><nobr>41.  </nobr></div>
<div style="position:absolute;top:62980;left:298"><nobr>segmentUpdateList.add(sUpdate)</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:63111;left:128"><nobr>55 <font style="font-size:12px">buPredicted はフィード・フォワード入力が予測されたこと（ bottom-up predicted）を表す。</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:63131;left:141"><nobr>（bottom-up は feed-forward と同義で、「フィード・フォワード」と訳している） </nobr></div>
</span></font>

<div style="position:absolute;top:63275;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=51><b>Page 51</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:64457;left:437"><nobr><b>51</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:63428;left:128"><nobr>フェーズ <b>2</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:63462;left:155"><nobr>第 2 のフェーズでは、各セルの予測状態を計算する。セルのどれかのセグメントが</nobr></div>
<div style="position:absolute;top:63489;left:128"><nobr>アクティブになると、そのセルの predictiveState がオンになる。即ち、十分な数の横</nobr></div>
<div style="position:absolute;top:63516;left:128"><nobr>方向の接続先が、フィード・フォワード入力によって現在アクティブであればオンにな</nobr></div>
<div style="position:absolute;top:63543;left:128"><nobr>る。この場合、そのセルは以下の変更を待ち行列に加える： a) 現在アクティブなセグ</nobr></div>
<div style="position:absolute;top:63570;left:128"><nobr>メントを強化<font style="font-size:8px">56</font>する（47-48 行目）、b) このアクティベーション<font style="font-size:8px">57</font>を予測し得たセグメ</nobr></div>
<div style="position:absolute;top:63597;left:128"><nobr>ント（即ち、前回の時刻ステップでアクティビティに（弱いかもしれないが）マッチし</nobr></div>
<div style="position:absolute;top:63624;left:128"><nobr>たセグメント）を強化する（50-53 行目）。</nobr></div>
<div style="position:absolute;top:63682;left:157"><nobr>42.  <b>for </b>c, i <b>in </b>cells </nobr></div>
<div style="position:absolute;top:63709;left:157"><nobr>43.  </nobr></div>
<div style="position:absolute;top:63709;left:234"><nobr><b>for </b>s <b>in </b>segments(c, i) </nobr></div>
<div style="position:absolute;top:63736;left:157"><nobr>44.  </nobr></div>
<div style="position:absolute;top:63736;left:277"><nobr><b>if </b>segmentActive(s, t, activeState) <b>then</b></nobr></div>
<div style="position:absolute;top:63762;left:157"><nobr>45.  </nobr></div>
<div style="position:absolute;top:63762;left:319"><nobr>predictiveState(c, i, t) = 1 </nobr></div>
<div style="position:absolute;top:63789;left:157"><nobr>46. </nobr></div>
<div style="position:absolute;top:63817;left:157"><nobr>47.  </nobr></div>
<div style="position:absolute;top:63817;left:319"><nobr>activeUpdate = getSegmentActiveSynapses(c, i, s, t, <b>false</b>)</nobr></div>
<div style="position:absolute;top:63843;left:157"><nobr>48.  </nobr></div>
<div style="position:absolute;top:63843;left:319"><nobr>segmentUpdateList.add(activeUpdate) </nobr></div>
<div style="position:absolute;top:63870;left:157"><nobr>49. </nobr></div>
<div style="position:absolute;top:63897;left:157"><nobr>50.  </nobr></div>
<div style="position:absolute;top:63897;left:319"><nobr>predSegment = getBestMatchingSegment(c, i, t-1) </nobr></div>
<div style="position:absolute;top:63924;left:157"><nobr>51.  </nobr></div>
<div style="position:absolute;top:63924;left:319"><nobr>predUpdate = getSegmentActiveSynapses( </nobr></div>
<div style="position:absolute;top:63952;left:157"><nobr>52.  </nobr></div>
<div style="position:absolute;top:63952;left:372"><nobr>c, i, predSegment, t-1, <b>true</b>) </nobr></div>
<div style="position:absolute;top:63978;left:157"><nobr>53.  </nobr></div>
<div style="position:absolute;top:63978;left:319"><nobr>segmentUpdateList.add(predUpdate) </nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:64045;left:128"><nobr>フェーズ <b>3</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:64079;left:155"><nobr>第 3 の、そして最後のフェーズでは、実際に学習を実施する。待ち行列に追加され</nobr></div>
<div style="position:absolute;top:64106;left:128"><nobr>たセグメントの更新は、フィード・フォワード入力を得てセルが学習セルとして選択さ</nobr></div>
<div style="position:absolute;top:64133;left:128"><nobr>れたときに実施される（55-57 行目）。そうではなく、もしセルが何らかの理由で予測</nobr></div>
<div style="position:absolute;top:64160;left:128"><nobr>を停止した場合、そのセグメントをネガティブ<font style="font-size:8px">58</font>に強化する（58-60 行目）。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:64354;left:128"><nobr>56 <font style="font-size:12px">reinforcement。フェーズ 3 で強化学習をする処理対象を segmentUpdateList に記憶する。</font></nobr></div>
<div style="position:absolute;top:64373;left:128"><nobr>57 <font style="font-size:12px">44 行目の if 文の条件が成立したこと</font></nobr></div>
<div style="position:absolute;top:64393;left:128"><nobr>58 <font style="font-size:12px">逆に弱める方向に学習する </font></nobr></div>
</span></font>

<div style="position:absolute;top:64537;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=52><b>Page 52</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:65719;left:437"><nobr><b>52</b></nobr></div>
<div style="position:absolute;top:64694;left:157"><nobr>54.  <b>for </b>c, i <b>in </b>cells </nobr></div>
<div style="position:absolute;top:64721;left:157"><nobr>55.  </nobr></div>
<div style="position:absolute;top:64721;left:234"><nobr><b>if </b>learnState(s, i, t) == 1 <b>then</b></nobr></div>
<div style="position:absolute;top:64748;left:157"><nobr>56.  </nobr></div>
<div style="position:absolute;top:64748;left:287"><nobr>adaptSegments (segmentUpdateList(c, i), <b>true</b>) </nobr></div>
<div style="position:absolute;top:64775;left:157"><nobr>57.  </nobr></div>
<div style="position:absolute;top:64775;left:287"><nobr>segmentUpdateList(c, i).delete() </nobr></div>
<div style="position:absolute;top:64802;left:157"><nobr>58.  </nobr></div>
<div style="position:absolute;top:64802;left:234"><nobr><b>else if </b>predictiveState(c, i, t) == 0 <b>and </b>predictiveState(c, i, t-1)==1 <b>then</b></nobr></div>
<div style="position:absolute;top:64829;left:157"><nobr>59.  </nobr></div>
<div style="position:absolute;top:64829;left:287"><nobr>adaptSegments (segmentUpdateList(c, i), <b>false</b>) </nobr></div>
<div style="position:absolute;top:64856;left:157"><nobr>60.  </nobr></div>
<div style="position:absolute;top:64856;left:287"><nobr>segmentUpdateList(c, i).delete() </nobr></div>
<div style="position:absolute;top:64883;left:157"><nobr>61. </nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:64962;left:128"><nobr>実装の詳細と用語説明</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:65011;left:155"><nobr>この節では時間プーリングの実装と用語の詳細を述べる。各セルは二つの数値でア</nobr></div>
<div style="position:absolute;top:65038;left:128"><nobr>クセスする。カラムの添字 c と、セルの添字 i である。セルは樹状突起セグメントのリ</nobr></div>
<div style="position:absolute;top:65065;left:128"><nobr>ストを保持する。各セグメントはシナプスのリストと、各シナプスごとに永続値を保持</nobr></div>
<div style="position:absolute;top:65092;left:128"><nobr>する。セルのシナプスに対する変更は、セルがフィード・フォワード入力によってアク</nobr></div>
<div style="position:absolute;top:65119;left:128"><nobr>ティブになるまでは一時的とマークされる。これらの一時的な変更は</nobr></div>
<div style="position:absolute;top:65148;left:128"><nobr>segmentUpdateList によって保持される。各セグメントはまた、論理値のフラグ</nobr></div>
<div style="position:absolute;top:65175;left:128"><nobr>sequenceSegment を保持する。これはそのセグメントが次の時刻ステップにおけるフ</nobr></div>
<div style="position:absolute;top:65200;left:128"><nobr>ィード・フォワード入力を予測するかどうかを示している。</nobr></div>
<div style="position:absolute;top:65227;left:155"><nobr>シナプス候補の実装は空間プーリングの実装とは異なっている。空間プーリングで</nobr></div>
<div style="position:absolute;top:65254;left:128"><nobr>は、シナプス候補の完全なリストが明示的に示される。時間プーリングでは各セグメン</nobr></div>
<div style="position:absolute;top:65281;left:128"><nobr>トが固有のシナプス候補の（ときには大きな）リストを保持することができる。実際に</nobr></div>
<div style="position:absolute;top:65308;left:128"><nobr>は各セグメントごとに大きなリストを管理することは、計算量が大きくメモリ消費が集</nobr></div>
<div style="position:absolute;top:65335;left:128"><nobr>中する。そこで我々は、時間プーリングでは学習の際に各セグメントごとにアクティブ</nobr></div>
<div style="position:absolute;top:65362;left:128"><nobr>なシナプスをランダムに追加する（newSynapseCount パラメータで制御する）。この</nobr></div>
<div style="position:absolute;top:65389;left:128"><nobr>最適化はすべてのシナプス候補のリストを維持管理するのと同様の効果があり、しかも</nobr></div>
<div style="position:absolute;top:65416;left:128"><nobr>新たな時間的パターンを学習できる可能性を維持しながらもセグメント毎のリストは</nobr></div>
<div style="position:absolute;top:65443;left:128"><nobr>ずっと小さくなる。</nobr></div>
<div style="position:absolute;top:65470;left:155"><nobr>疑似コードはまた、異なる時刻ステップのセル状態の推移を追うために小さな状態</nobr></div>
<div style="position:absolute;top:65497;left:128"><nobr>遷移マシンを使用する。各セルごとに三つの異なる状態を維持管理する。配列</nobr></div>
<div style="position:absolute;top:65526;left:128"><nobr>activeState と predictiveState は各セルの各時刻ステップごとのアクティブ状態及び</nobr></div>
<div style="position:absolute;top:65551;left:128"><nobr>予測状態の推移を追う。配列 learnState はどのセルの出力が学習のときに使用される</nobr></div>
<div style="position:absolute;top:65578;left:128"><nobr>かを決定する。入力が予測されなかったときは、その特定のカラムのすべてのセルが同</nobr></div>
<div style="position:absolute;top:65605;left:128"><nobr>じ時刻ステップ内に同時にアクティブになる。これらのセルのうちの一つだけ（入力に</nobr></div>
<div style="position:absolute;top:65632;left:128"><nobr>最もマッチするセル）で learnState がオンになる。learnState がオンのセルだけにつ</nobr></div>
</span></font>

<div style="position:absolute;top:65799;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=53><b>Page 53</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:66981;left:437"><nobr><b>53</b></nobr></div>
<div style="position:absolute;top:65953;left:128"><nobr>いて、シナプスを追加する（これは樹状突起セグメントの中で完全にアクティブになっ</nobr></div>
<div style="position:absolute;top:65980;left:128"><nobr>たカラムを強調しすぎないようにするためである）。</nobr></div>
</span></font>

<div style="position:absolute;top:67061;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=54><b>Page 54</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:68243;left:437"><nobr><b>54</b></nobr></div>
<div style="position:absolute;top:67215;left:154"><nobr>以下のデータ構造が時間プーリング疑似コードで使用されている。</nobr></div>
<div style="position:absolute;top:67272;left:136"><nobr>cell(c,i)</nobr></div>
<div style="position:absolute;top:67270;left:306"><nobr>すべてのセルのリスト。iとcで指し示される。 </nobr></div>
<div style="position:absolute;top:67304;left:136"><nobr>cellsPerColumn</nobr></div>
<div style="position:absolute;top:67302;left:306"><nobr>各カラムのセルの数</nobr></div>
<div style="position:absolute;top:67335;left:136"><nobr>activeColumns(<i>t</i>)</nobr></div>
<div style="position:absolute;top:67333;left:306"><nobr>フィード・フォワード入力によって勝者となったカラム（空</nobr></div>
<div style="position:absolute;top:67360;left:306"><nobr>間プーリング関数の出力）のインデックスのリスト</nobr></div>
<div style="position:absolute;top:67390;left:136"><nobr>activeState(c, i, t)</nobr></div>
<div style="position:absolute;top:67388;left:306"><nobr>各セルが一つずつ持つ論理値のベクトル。カラムc セルi時刻t</nobr></div>
<div style="position:absolute;top:67415;left:306"><nobr>におけるアクティブ状態を表す。これは現在のフィード・フ</nobr></div>
<div style="position:absolute;top:67442;left:306"><nobr>ォワード入力と過去の時間的文脈から与えられる。</nobr></div>
<div style="position:absolute;top:67471;left:306"><nobr>activeState(c, i, t) が1なら、そのセルは現在フィード・フォワ</nobr></div>
<div style="position:absolute;top:67496;left:306"><nobr>ード入力を持ち、適切な時間的文脈を持つ。</nobr></div>
<div style="position:absolute;top:67526;left:136"><nobr>predictiveState</nobr></div>
<div style="position:absolute;top:67553;left:136"><nobr>(c, i, t)</nobr></div>
<div style="position:absolute;top:67523;left:306"><nobr>各セルが一つずつ持つ論理値のベクトル。カラムc セルi時刻t</nobr></div>
<div style="position:absolute;top:67550;left:306"><nobr>における予測状態を表す。これは他のカラムのフィード・フ</nobr></div>
<div style="position:absolute;top:67577;left:306"><nobr>ォワード状態と過去の時間的文脈から与えられる。</nobr></div>
<div style="position:absolute;top:67607;left:306"><nobr>predictiveState(c, i, t) が1なら、そのセルは現在の時間的文脈</nobr></div>
<div style="position:absolute;top:67631;left:306"><nobr>からフィード・フォワード入力を予測している。</nobr></div>
<div style="position:absolute;top:67662;left:136"><nobr>learnState(c, i, t)</nobr></div>
<div style="position:absolute;top:67659;left:306"><nobr>カラムc セルi が学習対象のセルとして選択されたことを表</nobr></div>
<div style="position:absolute;top:67686;left:306"><nobr>す論理値</nobr></div>
<div style="position:absolute;top:67716;left:136"><nobr>activationThreshold</nobr></div>
<div style="position:absolute;top:67714;left:306"><nobr>あるセグメントをアクティブにするしきい値。あるセグメン</nobr></div>
<div style="position:absolute;top:67741;left:306"><nobr>ト　に　接　続　さ　れ　た　ア　ク　テ　ィ　ブ　な　シ　ナ　プ　ス　の　数　が</nobr></div>
<div style="position:absolute;top:67770;left:306"><nobr>activationThreshold より大きければ、セグメントはアクティ</nobr></div>
<div style="position:absolute;top:67795;left:306"><nobr>ブになる。</nobr></div>
<div style="position:absolute;top:67825;left:136"><nobr>learningRadius</nobr></div>
<div style="position:absolute;top:67823;left:306"><nobr>横方向の接続を持つ、時間プーリングセルの周囲の領域の範</nobr></div>
<div style="position:absolute;top:67850;left:306"><nobr>囲</nobr></div>
<div style="position:absolute;top:67880;left:136"><nobr>initialPerm</nobr></div>
<div style="position:absolute;top:67878;left:306"><nobr>シナプスの永続値の初期値</nobr></div>
<div style="position:absolute;top:67912;left:136"><nobr>connectedPerm</nobr></div>
<div style="position:absolute;top:67909;left:306"><nobr>あるシナプスの永続値がこの値より大きければ、それが接続</nobr></div>
<div style="position:absolute;top:67936;left:306"><nobr>していることを表す</nobr></div>
<div style="position:absolute;top:67966;left:136"><nobr>minThreshold</nobr></div>
<div style="position:absolute;top:67964;left:306"><nobr>学習の際の、アクティブなセグメントの最小数</nobr></div>
<div style="position:absolute;top:67998;left:136"><nobr>newSynapseCount  学習のときにセグメントに追加されるシナプスの最大数</nobr></div>
<div style="position:absolute;top:68030;left:136"><nobr>permanenceInc </nobr></div>
<div style="position:absolute;top:68027;left:306"><nobr>アクティビティによる学習が発生したとき、シナプスの永続</nobr></div>
<div style="position:absolute;top:68054;left:306"><nobr>値を増加させる量</nobr></div>
<div style="position:absolute;top:68084;left:136"><nobr>permanenceDec</nobr></div>
<div style="position:absolute;top:68082;left:306"><nobr>アクティビティによる学習が発生したとき、シナプスの永続</nobr></div>
<div style="position:absolute;top:68109;left:306"><nobr>値を減少させる量 </nobr></div>
</span></font>

<div style="position:absolute;top:68323;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=55><b>Page 55</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:69505;left:437"><nobr><b>55</b></nobr></div>
<div style="position:absolute;top:68480;left:136"><nobr>segmentUpdate</nobr></div>
<div style="position:absolute;top:68478;left:306"><nobr>与えられたセグメントを更新するときに必要な情報を保持す</nobr></div>
<div style="position:absolute;top:68505;left:306"><nobr>るデータ構造で、以下の3項目からなる。a) セグメントの添</nobr></div>
<div style="position:absolute;top:68532;left:306"><nobr>字（新しいセグメントのときは-1）、b) 既存のアクティブな</nobr></div>
<div style="position:absolute;top:68559;left:306"><nobr>シナプスのリスト、c) このセグメントが順序セグメントとマ</nobr></div>
<div style="position:absolute;top:68586;left:306"><nobr>ークされべきかどうかを表すフラグ（デフォルト値はfalse）。</nobr></div>
<div style="position:absolute;top:68616;left:136"><nobr>segmentUpdateList</nobr></div>
<div style="position:absolute;top:68616;left:306"><nobr>segmentUpdate 構造体のリスト。segmentUpdateList(c,i) は</nobr></div>
<div style="position:absolute;top:68641;left:306"><nobr>カラムc セルi の変更内容のリストである。</nobr></div>
<div style="position:absolute;top:68702;left:155"><nobr>以下の補助関数が上記のコードで使用されている。</nobr></div>
<div style="position:absolute;top:68759;left:136"><nobr>segmentActive</nobr></div>
<div style="position:absolute;top:68786;left:136"><nobr>(s, t, state) </nobr></div>
<div style="position:absolute;top:68757;left:306"><nobr>セグメントs 時刻t において、state で与えられた状態によっ</nobr></div>
<div style="position:absolute;top:68784;left:306"><nobr>てアクティブになった接続状態のシナプスの数が</nobr></div>
<div style="position:absolute;top:68813;left:306"><nobr>activationThreshold より大きい時、真を返す。state パラメー</nobr></div>
<div style="position:absolute;top:68838;left:306"><nobr>タは activeState 又は learnState である。</nobr></div>
<div style="position:absolute;top:68868;left:136"><nobr>getActiveSegment</nobr></div>
<div style="position:absolute;top:68895;left:136"><nobr>(c, i, t, state) </nobr></div>
<div style="position:absolute;top:68866;left:306"><nobr>与えられたカラムc セルi について、segmentActive(s,t, state)</nobr></div>
<div style="position:absolute;top:68893;left:306"><nobr>が真になるセグメントの添字を返す。もし複数のセグメント</nobr></div>
<div style="position:absolute;top:68920;left:306"><nobr>がアクティブであれば、順序セグメントがあればそれが優先</nobr></div>
<div style="position:absolute;top:68947;left:306"><nobr>する。そうでなければもっともアクティビティが高いものが</nobr></div>
<div style="position:absolute;top:68974;left:306"><nobr>優先する。</nobr></div>
<div style="position:absolute;top:69004;left:136"><nobr>getBestMatchingSeg</nobr></div>
<div style="position:absolute;top:69031;left:136"><nobr>ment(c, i, t) </nobr></div>
<div style="position:absolute;top:69002;left:306"><nobr>与えられたカラムc セルi について、アクティブなシナプスが</nobr></div>
<div style="position:absolute;top:69029;left:306"><nobr>最も多いセグメントを探す。この関数は積極的にベストマッ</nobr></div>
<div style="position:absolute;top:69056;left:306"><nobr>チを見つける。シナプスの永続値は connectedPerm より小</nobr></div>
<div style="position:absolute;top:69083;left:306"><nobr>さくても許される。アクティブなシナプスの数は</nobr></div>
<div style="position:absolute;top:69112;left:306"><nobr>activationThreshold より小さくても許される。ただし、</nobr></div>
<div style="position:absolute;top:69139;left:306"><nobr>minThreshold より大きくなければならない。この関数はセグ</nobr></div>
<div style="position:absolute;top:69164;left:306"><nobr>メントの添字を返す。もしセグメントが見つからなかったら</nobr></div>
<div style="position:absolute;top:69193;left:306"><nobr>-1 を返す。</nobr></div>
<div style="position:absolute;top:69221;left:136"><nobr>getBestMatchingCell</nobr></div>
<div style="position:absolute;top:69248;left:136"><nobr>(c) </nobr></div>
<div style="position:absolute;top:69218;left:306"><nobr>与えられたカラムについて、ベストマッチセグメント（上記</nobr></div>
<div style="position:absolute;top:69245;left:306"><nobr>参照）を持つセルを返す。もしどのセルにもマッチするセグ</nobr></div>
<div style="position:absolute;top:69272;left:306"><nobr>メントがなければ、最もセグメントの数が少ないセルを返す。</nobr></div>
</span></font>

<div style="position:absolute;top:69585;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=56><b>Page 56</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:70767;left:437"><nobr><b>56</b></nobr></div>
<div style="position:absolute;top:69742;left:136"><nobr>getSegmentActiveSy</nobr></div>
<div style="position:absolute;top:69769;left:136"><nobr>napses(c, i, t, s,</nobr></div>
<div style="position:absolute;top:69796;left:136"><nobr>newSynapses=</nobr></div>
<div style="position:absolute;top:69823;left:136"><nobr><b>false</b>) </nobr></div>
<div style="position:absolute;top:69740;left:306"><nobr>セグメントs に対して提示された変更のリストを保持する</nobr></div>
<div style="position:absolute;top:69769;left:306"><nobr>segmentUpdate 構造体を返す。activeSynapses を、接続元</nobr></div>
<div style="position:absolute;top:69794;left:306"><nobr>のセルの時刻t における activeState 出力=1 であるようなア</nobr></div>
<div style="position:absolute;top:69821;left:306"><nobr>クティブなシナプスのリストとする（s=-1のときはセグメン</nobr></div>
<div style="position:absolute;top:69848;left:306"><nobr>トが存在しないため、このリストは 空である）。newSynapses</nobr></div>
<div style="position:absolute;top:69875;left:306"><nobr>はオプション引数でデフォルト値は false である。</nobr></div>
<div style="position:absolute;top:69904;left:306"><nobr>newSynapses が　真　の　時　は　、 newSynapseCount -</nobr></div>
<div style="position:absolute;top:69931;left:306"><nobr>count(activeSynapses) 個のシナプスが activeSynapses に</nobr></div>
<div style="position:absolute;top:69956;left:306"><nobr>追加される。これらのシナプスは、時刻t において learnState</nobr></div>
<div style="position:absolute;top:69983;left:306"><nobr>出力=1 であるセルの中からランダムに選択される。</nobr></div>
<div style="position:absolute;top:70013;left:136"><nobr>adaptSegments</nobr></div>
<div style="position:absolute;top:70040;left:136"><nobr>(segmentList,</nobr></div>
<div style="position:absolute;top:70067;left:136"><nobr>positiveReinforceme</nobr></div>
<div style="position:absolute;top:70094;left:136"><nobr>nt)</nobr></div>
<div style="position:absolute;top:70011;left:306"><nobr>この関数は segmentUpdate のリスト要素について繰り返</nobr></div>
<div style="position:absolute;top:70038;left:306"><nobr>し、各セグメントを強化をする。segmentUpdate の各要素に</nobr></div>
<div style="position:absolute;top:70065;left:306"><nobr>ついて、以下の変更が実行される。positiveReinforcement が</nobr></div>
<div style="position:absolute;top:70092;left:306"><nobr>真のとき、アクティブなリスト上のシナプスの永続値は</nobr></div>
<div style="position:absolute;top:70121;left:306"><nobr>permanenceInc だけ増加させる。他のすべてのシナプスは永</nobr></div>
<div style="position:absolute;top:70146;left:306"><nobr>続　値　を</nobr></div>
<div style="position:absolute;top:70148;left:408"><nobr>permanenceDec だ　け　減　少　さ　せ　る　。</nobr></div>
<div style="position:absolute;top:70175;left:306"><nobr>positiveReinforcement が偽のとき、アクティブなリスト上の</nobr></div>
<div style="position:absolute;top:70200;left:306"><nobr>シナプスは永続値を permanenceDec だけ減少させる。これ</nobr></div>
<div style="position:absolute;top:70227;left:306"><nobr>らの処理の後、segmentUpdate の中にまだ存在しないシナプ</nobr></div>
<div style="position:absolute;top:70254;left:306"><nobr>スについて、永続値 initialPerm にて追加する。 </nobr></div>
</span></font>

<div style="position:absolute;top:70847;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=57><b>Page 57</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:72029;left:437"><nobr><b>57</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:71058;left:128"><nobr>付録 <b>A: </b>生体ニューロンと <b>HTM </b>セルの比較</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:71380;left:155"><nobr>上の画像は左側が生体ニューロンの写真、中央が単純な人工ニューロン、右側が</nobr></div>
<div style="position:absolute;top:71409;left:128"><nobr>HTM のニューロンあるいはセルを示している。この付録の目的は HTM セルを実物のニ</nobr></div>
<div style="position:absolute;top:71434;left:128"><nobr>ューロンや単純な人工ニューロンと比べることで、それをより深く理解し、またどのよ</nobr></div>
<div style="position:absolute;top:71461;left:128"><nobr>うに動作するかを示すことにある。</nobr></div>
<div style="position:absolute;top:71488;left:155"><nobr>実物のニューロンは途方もなく複雑で変化に富んでいる。ここではその最も普遍的</nobr></div>
<div style="position:absolute;top:71515;left:128"><nobr>な原理に注目し、また我々のモデルに関わる部分に限定する。実物のニューロンの多く</nobr></div>
<div style="position:absolute;top:71542;left:128"><nobr>の詳細は無視するものの、HTM 大脳皮質性学習アルゴリズムで用いられているセルは</nobr></div>
<div style="position:absolute;top:71569;left:128"><nobr>多くのニューラルネットワークで用いられている人工ニューロンよりもはるかに現実</nobr></div>
<div style="position:absolute;top:71596;left:128"><nobr>に即している。HTM セルに含まれるすべての要素は HTM リージョンの演算に必要であ</nobr></div>
<div style="position:absolute;top:71623;left:128"><nobr>る。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:71703;left:128"><nobr>生体ニューロン</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:71752;left:155"><nobr>ニューロンは脳内で情報を伝えるセル<font style="font-size:8px">59</font>である。上記左の画像は標準的な興奮性の</nobr></div>
<div style="position:absolute;top:71779;left:128"><nobr>ニューロンである。ニューロンの外見の大部分は枝分かれした樹状突起で占められてい</nobr></div>
<div style="position:absolute;top:71806;left:128"><nobr>る。ニューロンへのすべての興奮性の入力は、樹状突起に沿って配置されたシナプスを</nobr></div>
<div style="position:absolute;top:71833;left:128"><nobr>経由して入る。近年、ニューロンに関する知識は有為な発展を遂げた。最大の発見は、</nobr></div>
<div style="position:absolute;top:71860;left:128"><nobr>ニューロンの樹状突起が入力を細胞体<font style="font-size:8px">60</font>に繋ぐ単なる導線ではないと分かったことで</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:71945;left:128"><nobr>59 <font style="font-size:12px">cell を本書では一貫して「セル」と訳したが、生物の細胞を意味する。</font></nobr></div>
<div style="position:absolute;top:71965;left:128"><nobr>60 <font style="font-size:12px">cell body。ニューロン中央の膨らんだ部分。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:72109;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=58><b>Page 58</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:73291;left:437"><nobr><b>58</b></nobr></div>
<div style="position:absolute;top:72263;left:128"><nobr>ある。今では樹状突起はそれ自体、複雑な非線形処理部品であることが分かっている。</nobr></div>
<div style="position:absolute;top:72288;left:128"><nobr>HTM 大脳皮質性学習アルゴリズムはこの非線形の特性を利用している。</nobr></div>
<div style="position:absolute;top:72317;left:155"><nobr>ニューロンはいくつかの部分に分かれている。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:72385;left:128"><nobr>細胞体</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:72419;left:155"><nobr>細胞体はニューロンの中央にある小さな体積を持つ部分である。セルの出力、軸索<font style="font-size:8px">61</font></nobr></div>
<div style="position:absolute;top:72446;left:128"><nobr>は、細胞体から出ている。セルへの入力は樹状突起に沿って配置されたシナプスであり、</nobr></div>
<div style="position:absolute;top:72473;left:128"><nobr>それは細胞体に入力される。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:72541;left:128"><nobr>主要樹状突起<b><font style="font-size:10px">62</font></b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:72575;left:155"><nobr>細胞体に最も近い部分にある樹状突起の枝は主要樹状突起と呼ばれる。図では主要</nobr></div>
<div style="position:absolute;top:72602;left:128"><nobr>樹状突起のいくつかを緑色の線で示した。</nobr></div>
<div style="position:absolute;top:72629;left:155"><nobr>主要樹状突起上の複数のアクティブなシナプスは、細胞体に対して概ね線形の加算</nobr></div>
<div style="position:absolute;top:72656;left:128"><nobr>的効果がある。5 つのアクティブなシナプスは 1 つのアクティブなシナプスに比べて概</nobr></div>
<div style="position:absolute;top:72683;left:128"><nobr>ね 5 倍の脱分極<font style="font-size:8px">63</font>を細胞体に対して引き起こす。対照的に、ある一つのシナプスが後続</nobr></div>
<div style="position:absolute;top:72710;left:128"><nobr>の素早い活動電位<font style="font-size:8px">64</font>によって繰り返しアクティブになったとしても、2 番目、3 番目と</nobr></div>
<div style="position:absolute;top:72737;left:128"><nobr>続く活動電位による細胞体への影響は、最初のものよりずっと小さくなる。</nobr></div>
<div style="position:absolute;top:72764;left:155"><nobr>このため、主要樹状突起への入力は細胞体に対して線形に加わること、単一のシナ</nobr></div>
<div style="position:absolute;top:72791;left:128"><nobr>プスに届いた複数の素早いパルスの影響は一つのパルスより少し大きいだけであるこ</nobr></div>
<div style="position:absolute;top:72818;left:128"><nobr>とが言える。</nobr></div>
<div style="position:absolute;top:72845;left:155"><nobr>新皮質のリージョンへのフィード・フォワード接続は主要樹状突起に優先的に接続</nobr></div>
<div style="position:absolute;top:72872;left:128"><nobr>されている。これは少なくとも、各リージョンのニューロンのうち主要な入力層である</nobr></div>
<div style="position:absolute;top:72899;left:128"><nobr>第 4 層のニューロンについて報告されている。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:72967;left:128"><nobr>末梢樹状突起<b><font style="font-size:10px">65</font></b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:73001;left:155"><nobr>細胞体から遠くにある樹状突起の枝は末梢樹状突起と呼ばれる。図では末梢樹状突</nobr></div>
<div style="position:absolute;top:73028;left:128"><nobr>起のいくつかを青色の線で示した。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:73114;left:128"><nobr>61 <font style="font-size:12px">axon</font></nobr></div>
<div style="position:absolute;top:73131;left:128"><nobr>62 <font style="font-size:12px">proximal dendrite</font></nobr></div>
<div style="position:absolute;top:73150;left:128"><nobr>63 <font style="font-size:12px">depolarization。神経細胞内の電位は通常は-70~-60mV 程度。ニューロンが刺激を受けたためにこ</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:73171;left:141"><nobr>の電位が上がることを脱分極という。脱分極により電位があるしきい値を超えるとニューロンが発火す</nobr></div>
<div style="position:absolute;top:73191;left:141"><nobr>る。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:73208;left:128"><nobr>64 <font style="font-size:12px">action potential。なんらかの刺激に応じて細胞膜に生じる一過性の膜電位の変化。</font></nobr></div>
<div style="position:absolute;top:73226;left:128"><nobr>65 <font style="font-size:12px">distal dendrite </font></nobr></div>
</span></font>

<div style="position:absolute;top:73371;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=59><b>Page 59</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:74553;left:437"><nobr><b>59</b></nobr></div>
<div style="position:absolute;top:73525;left:155"><nobr>末梢樹状突起は主要樹状突起よりも細い。これらは樹状突起の木の中の他の樹状突</nobr></div>
<div style="position:absolute;top:73552;left:128"><nobr>起の枝に接続されていて、細胞体に直接接続されていない。これらの違いにより末梢樹</nobr></div>
<div style="position:absolute;top:73579;left:128"><nobr>状突起はユニークな電気・化学特性を持っている。末梢樹状突起で一つのシナプスがア</nobr></div>
<div style="position:absolute;top:73606;left:128"><nobr>クティブになっても、細胞体に対して最小限の影響しか及ぼさない。シナプスで局所的</nobr></div>
<div style="position:absolute;top:73633;left:128"><nobr>に発生した脱分極は、それが細胞体に届くときには弱くなっている。このことは長年の</nobr></div>
<div style="position:absolute;top:73660;left:128"><nobr>なぞであった。ニューロンのシナプスの大多数を占める末梢のシナプスはあまり多くの</nobr></div>
<div style="position:absolute;top:73687;left:128"><nobr>ことをしていないように思えた。</nobr></div>
<div style="position:absolute;top:73714;left:155"><nobr>今では末梢樹状突起の各断片が半独立の処理領域として働くことが分かっている。</nobr></div>
<div style="position:absolute;top:73741;left:128"><nobr>もしその樹状突起の短い区間内で十分な数のシナプスが同時にアクティブになると、樹</nobr></div>
<div style="position:absolute;top:73768;left:128"><nobr>状突起のパルスを生成することができ、それは細胞体にまで届いて大きな影響を及ぼす</nobr></div>
<div style="position:absolute;top:73795;left:128"><nobr>ことができる。例えば 40μm 間隔の 20 個のアクティブなシナプスは樹状突起のパルス</nobr></div>
<div style="position:absolute;top:73822;left:128"><nobr>を生成するだろう。</nobr></div>
<div style="position:absolute;top:73849;left:155"><nobr>従って、末梢樹状突起は域内同時発生事象の検出器のように働くと言える。</nobr></div>
<div style="position:absolute;top:73876;left:155"><nobr>末梢樹状突起上のシナプスは、圧倒的にそのリージョン内の付近の他のセルから形</nobr></div>
<div style="position:absolute;top:73903;left:128"><nobr>成されている。</nobr></div>
<div style="position:absolute;top:73930;left:155"><nobr>画像では上方向に伸びる大きな樹状突起の枝が見られる。これは先端樹状突起<font style="font-size:8px">66</font>と</nobr></div>
<div style="position:absolute;top:73957;left:128"><nobr>呼ばれる。ある理論によると、この構造によりニューロンは付近にいくつかの末梢樹状</nobr></div>
<div style="position:absolute;top:73984;left:128"><nobr>突起を形成し、この付近を通る軸索により容易に接続することができるようにしている</nobr></div>
<div style="position:absolute;top:74011;left:128"><nobr>という。この解釈によれば、先端樹状突起はセルの延長として働くと考えられる。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:74079;left:128"><nobr>シナプス</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:74113;left:155"><nobr>標準的なニューロンには数千個のシナプスがある。これらの大多数(多分 90%)は末</nobr></div>
<div style="position:absolute;top:74140;left:128"><nobr>梢樹状突起にあり、残りは主要樹状突起にあると思われる。</nobr></div>
<div style="position:absolute;top:74167;left:155"><nobr>長年に渡って、学習はシナプスの影響度ないし「重み」を強くしたり弱くしたりす</nobr></div>
<div style="position:absolute;top:74194;left:128"><nobr>ることを含むものと仮定されてきた。このような影響は観測されるものの、各シナプス</nobr></div>
<div style="position:absolute;top:74221;left:128"><nobr>はどこか確率的な様子である。アクティブになったとき、それが神経伝達物質<font style="font-size:8px">67</font>を放出</nobr></div>
<div style="position:absolute;top:74248;left:128"><nobr>することに信頼性がない。よって脳が用いているアルゴリズムが各シナプスの重みの精</nobr></div>
<div style="position:absolute;top:74275;left:128"><nobr>度や忠実度に依存しているはずがない。</nobr></div>
<div style="position:absolute;top:74302;left:155"><nobr>さらに今では、シナプス全体が素早く形成されたり切断したりすることが分かって</nobr></div>
<div style="position:absolute;top:74329;left:128"><nobr>いる。この柔軟性は学習の強力な表現形式であり、素早く知識を獲得できることをより</nobr></div>
<div style="position:absolute;top:74356;left:128"><nobr>よく説明している。シナプスは軸索と樹状突起がある距離の範囲内にあるときにだけ形</nobr></div>
<div style="position:absolute;top:74383;left:128"><nobr>成されうることから、シナプス「候補」の概念が得られた。これらの仮定から、学習は</nobr></div>
<div style="position:absolute;top:74410;left:128"><nobr>主にシナプス候補から有効なシナプスが形成されることで行われると言える。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:74470;left:128"><nobr>66 <font style="font-size:12px">apical dendrite。apical は「頂点の，頂上の」という意味。</font></nobr></div>
<div style="position:absolute;top:74488;left:128"><nobr>67 <font style="font-size:12px">neurotransmitter </font></nobr></div>
</span></font>

<div style="position:absolute;top:74633;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=60><b>Page 60</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:75815;left:437"><nobr><b>60</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:74828;left:128"><nobr>ニューロンの出力</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:74862;left:155"><nobr>ニューロンの出力は軸索に沿って伝搬するパルス<font style="font-size:8px">68</font>あるいは「活動電位」である。</nobr></div>
<div style="position:absolute;top:74889;left:128"><nobr>軸索はセルから伸びて、ほとんど常に二つに分かれる。枝の一つは水平に伸びて近くの</nobr></div>
<div style="position:absolute;top:74916;left:128"><nobr>他のセルと数多く接続する。他の枝は他の層のセルや脳内の他の場所へと遠く伸びる。</nobr></div>
<div style="position:absolute;top:74943;left:128"><nobr>上記のニューロンの画像では軸索は見えない。２本の矢印を追加して軸索を示した。</nobr></div>
<div style="position:absolute;top:74970;left:155"><nobr>ニューロンの実際の出力は常にパルスであるが、この解釈には異なる見方ができる。</nobr></div>
<div style="position:absolute;top:74997;left:128"><nobr>有力な見方としては（特に新皮質に関しては）、パルスの発生頻度が重要というもので</nobr></div>
<div style="position:absolute;top:75024;left:128"><nobr>ある。よってセルの出力はスカラー値と見なすことができる。</nobr></div>
<div style="position:absolute;top:75051;left:155"><nobr>いくつかのニューロンは数個の連続したパルスを短時間に素早く出力する「バース</nobr></div>
<div style="position:absolute;top:75078;left:128"><nobr>ト」反応を示すこともあり、これは通常のパルスのパターンとは異なる。</nobr></div>
<div style="position:absolute;top:75132;left:155"><nobr>ニューロンに関する上記の記述は、ニューロンを手短に説明したつもりである。こ</nobr></div>
<div style="position:absolute;top:75159;left:128"><nobr>れは HTM セルの特徴に関連する属性に注目して述べたもので、多くの詳細は無視して</nobr></div>
<div style="position:absolute;top:75186;left:128"><nobr>いる。ここで述べたすべての特徴が幅広く受け入れられているとは必ずしも言えない。</nobr></div>
<div style="position:absolute;top:75213;left:128"><nobr>これらをここで述べたのは、我々のモデルにとって必要だからである。ニューロンにつ</nobr></div>
<div style="position:absolute;top:75240;left:128"><nobr>いて知られていることを述べるなら有に数冊の本にもなり、ニューロンの活発な研究は</nobr></div>
<div style="position:absolute;top:75267;left:128"><nobr>現在も続けられている。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:75348;left:128"><nobr>単純な人工ニューロン</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:75396;left:155"><nobr>この付録の最初に示した中央の図は、多くの古典的な人工ニューラルネットワーク</nobr></div>
<div style="position:absolute;top:75423;left:128"><nobr>モデルで使われているニューロンに模した構成要素を示している。これらの人工ニュー</nobr></div>
<div style="position:absolute;top:75450;left:128"><nobr>ロンはシナプスの集合を持ち、各シナプスはウェイトを持っている。各シナプスはスカ</nobr></div>
<div style="position:absolute;top:75477;left:128"><nobr>ラー値のアクティブ化を受け取り、それにシナプスのウェイトが掛け合わされる。すべ</nobr></div>
<div style="position:absolute;top:75504;left:128"><nobr>てのシナプスの出力は非線形の方法で足し合わされ、人工ニューロンの出力となる。学</nobr></div>
<div style="position:absolute;top:75531;left:128"><nobr>習はシナプスのウェイトを調整することで行われ、その調整は恐らく非線形の関数とな</nobr></div>
<div style="position:absolute;top:75558;left:128"><nobr>る。このタイプの人工ニューロン、そしてそのバリエーションは、コンピュータを利用</nobr></div>
<div style="position:absolute;top:75585;left:128"><nobr>した価値ある道具として多くのアプリケーションにおいて有益であることが実証され</nobr></div>
<div style="position:absolute;top:75612;left:128"><nobr>てきた。しかしながら、それは生体ニューロンの多くの複雑さを捉えておらず、その多</nobr></div>
<div style="position:absolute;top:75639;left:128"><nobr>くの処理能力を活用していない。実物のニューロンが脳内でどのような全体効果を生み</nobr></div>
<div style="position:absolute;top:75666;left:128"><nobr>出すかを理解しモデル化したいのなら、我々はもっと精巧なニューロンモデルが必要で</nobr></div>
<div style="position:absolute;top:75693;left:128"><nobr>ある。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:75750;left:128"><nobr>68 <font style="font-size:12px">spike。短時間の尖った波形のこと。pulse とは少し違うが、パルスと訳した。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:75895;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=61><b>Page 61</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:77077;left:437"><nobr><b>61</b></nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:76105;left:128"><nobr><b>HTM </b>セル</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:76151;left:155"><nobr>図の右側は、HTM 大脳皮質性学習アルゴリズムで用いられているセルを図示して</nobr></div>
<div style="position:absolute;top:76178;left:128"><nobr>いる。HTM セルは実物のニューロンの多くの重要な能力を捉えているが、いくつかの</nobr></div>
<div style="position:absolute;top:76205;left:128"><nobr>単純化も行っている。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:76273;left:128"><nobr>主要樹状突起</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:76307;left:155"><nobr>各 HTM セルは単一の主要樹状突起を持つ。セルへのすべてのフィード・フォワー</nobr></div>
<div style="position:absolute;top:76334;left:128"><nobr>ド入力はシナプス（緑色の点で示した）経由で入力される。アクティブなシナプスの効</nobr></div>
<div style="position:absolute;top:76361;left:128"><nobr>果は線形に加算され、フィード・フォワード入力によるセルのアクティブ化を生み出す。</nobr></div>
<div style="position:absolute;top:76388;left:155"><nobr>我々は、カラム内のすべてのセルが同じフィード・フォワード応答を持つよう求め</nobr></div>
<div style="position:absolute;top:76415;left:128"><nobr>ている。実物のニューロンではこれは恐らく抑制タイプのセルによって行われる。HTM</nobr></div>
<div style="position:absolute;top:76442;left:128"><nobr>では我々は単にカラム中のすべてのセルが単一の主要樹状突起を共有するように強制</nobr></div>
<div style="position:absolute;top:76469;left:128"><nobr>することにした。</nobr></div>
<div style="position:absolute;top:76496;left:155"><nobr>隣のセルとの競合に決して勝つことができないようなセルができることを避けるた</nobr></div>
<div style="position:absolute;top:76523;left:128"><nobr>め、HTM セルはその隣と比較して十分に勝利していないときには、そのフィード・フ</nobr></div>
<div style="position:absolute;top:76550;left:128"><nobr>ォワード入力によるアクティブ化をブーストする。よってセル間には常に競合が存在す</nobr></div>
<div style="position:absolute;top:76577;left:128"><nobr>る。ここでも、我々はこれをセル間ではなくカラム間の競合として HTM でモデル化し</nobr></div>
<div style="position:absolute;top:76604;left:128"><nobr>た。この競合は図では示されていない。</nobr></div>
<div style="position:absolute;top:76631;left:155"><nobr>最後に、主要樹状突起はリージョンへのすべての入力の部分集合となるシナプス候</nobr></div>
<div style="position:absolute;top:76658;left:128"><nobr>補の集合を一つ持っている。セルが学習すると、その主要樹状突起上のすべてのシナプ</nobr></div>
<div style="position:absolute;top:76685;left:128"><nobr>ス候補の「永続」値を増加ないし減少させる。しきい値を超えたシナプス候補だけが有</nobr></div>
<div style="position:absolute;top:76712;left:128"><nobr>効となる。</nobr></div>
<div style="position:absolute;top:76739;left:155"><nobr>既に述べたように、シナプス候補の概念は生物学からもたらされた。生物学では、</nobr></div>
<div style="position:absolute;top:76766;left:128"><nobr>シナプスを形成するのに十分に近くにある軸索と樹状突起とを意味する。我々はこの概</nobr></div>
<div style="position:absolute;top:76793;left:128"><nobr>念を拡張して、HTM セルで接続する可能性のある、より大きな集合を意味することと</nobr></div>
<div style="position:absolute;top:76820;left:128"><nobr>した。生体ニューロンの樹状突起と軸索は学習によって成長したり縮退したりすること</nobr></div>
<div style="position:absolute;top:76847;left:128"><nobr>ができ、よってシナプス候補の集合は成長に伴って変化する。HTM セルのシナプス候</nobr></div>
<div style="position:absolute;top:76874;left:128"><nobr>補の集合を大きめにすることで、我々は概ね、軸索や樹状突起の成長と同じ結果を得た。</nobr></div>
<div style="position:absolute;top:76901;left:128"><nobr>シナプス候補の集合は図示されていない。</nobr></div>
<div style="position:absolute;top:76928;left:155"><nobr>カラム間の競合、シナプス候補の集合による学習、あまり活用されていないカラム</nobr></div>
<div style="position:absolute;top:76955;left:128"><nobr>のブーストの組み合わせにより、HTM ニューロンのリージョンは脳に見られるのと同</nobr></div>
<div style="position:absolute;top:76982;left:128"><nobr>様の強力な可塑性を得た。HTM リージョンは入力の変化に応じて各カラムが何を表す</nobr></div>
</span></font>

<div style="position:absolute;top:77157;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=62><b>Page 62</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:78339;left:437"><nobr><b>62</b></nobr></div>
<div style="position:absolute;top:77311;left:128"><nobr>のかを（主要樹状突起上のシナプスの変更によって）自動的に調整し、カラム数の増加</nobr></div>
<div style="position:absolute;top:77338;left:128"><nobr>ないし減少を自動的に調整するだろう。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:77406;left:128"><nobr>末梢樹状突起</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:77440;left:155"><nobr>各 HTM セルは末梢樹状突起セグメントのリストを管理している。各セグメントは</nobr></div>
<div style="position:absolute;top:77467;left:128"><nobr>しきい値検出器として働く。任意のセグメント上のアクティブなシナプス（冒頭の図で</nobr></div>
<div style="position:absolute;top:77494;left:128"><nobr>青い点で示した）の数がしきい値を超えると、そのセグメントはアクティブになり、そ</nobr></div>
<div style="position:absolute;top:77521;left:128"><nobr>れに接続されたセルが予測状態になる。セルの予測状態はアクティブなセグメントの</nobr></div>
<div style="position:absolute;top:77546;left:128"><nobr>OR である。</nobr></div>
<div style="position:absolute;top:77575;left:155"><nobr>樹状突起セグメントは、以前のある時点で互いに同時にアクティブになった複数の</nobr></div>
<div style="position:absolute;top:77602;left:128"><nobr>セルへの接続を形成することでリージョンの状態を記憶する。そのセグメントは、以前</nobr></div>
<div style="position:absolute;top:77629;left:128"><nobr>にフィード・フォワード入力によってアクティブになったセルの状態を記憶する。よっ</nobr></div>
<div style="position:absolute;top:77656;left:128"><nobr>てそのセグメントはセルがアクティブになることを予測する状態を探す。樹状突起セグ</nobr></div>
<div style="position:absolute;top:77683;left:128"><nobr>メントの標準的なしきい値は 15 である。あるセグメント上の有効なシナプスが 15 個</nobr></div>
<div style="position:absolute;top:77710;left:128"><nobr>同時にアクティブになると、その樹状突起はアクティブになる。数百から数千個の周囲</nobr></div>
<div style="position:absolute;top:77737;left:128"><nobr>のセルがアクティブになるかも知れないが、15 個の接続だけで十分により大きなパタ</nobr></div>
<div style="position:absolute;top:77764;left:128"><nobr>ーンを理解することができる。</nobr></div>
<div style="position:absolute;top:77791;left:155"><nobr>各末梢樹状突起セグメントはそれに関連付けられたシナプス候補の集合を持つ。そ</nobr></div>
<div style="position:absolute;top:77818;left:128"><nobr>のシナプス候補の集合はリージョン内のすべてのセルの部分集合である。そのセグメン</nobr></div>
<div style="position:absolute;top:77845;left:128"><nobr>トが学習するに従い、それらすべてのシナプス候補の永続値を増加ないし減少させる。</nobr></div>
<div style="position:absolute;top:77872;left:128"><nobr>しきい値を超えたシナプス候補だけが有効である。</nobr></div>
<div style="position:absolute;top:77899;left:155"><nobr>ある実装では、我々はセルあたり固定の数の樹状突起セグメントを用いた。他のあ</nobr></div>
<div style="position:absolute;top:77926;left:128"><nobr>る実装では、訓練を通じてセグメントを追加ないし削除するようにした。両方の方法が</nobr></div>
<div style="position:absolute;top:77953;left:128"><nobr>機能する。セルあたりの樹状突起セグメントの数を固定にすると、同じセグメントに対</nobr></div>
<div style="position:absolute;top:77980;left:128"><nobr>していくつかの異なるシナプスの集合を保存することができる。例えば、セグメント上</nobr></div>
<div style="position:absolute;top:78007;left:128"><nobr>に 20 個の有効なシナプスがあり、しきい値が 15 とする。（一般に我々はノイズへの</nobr></div>
<div style="position:absolute;top:78034;left:128"><nobr>耐性を改善するためしきい値をシナプスの数よりも少なくしたい。）これでそのセグメ</nobr></div>
<div style="position:absolute;top:78061;left:128"><nobr>ントは周囲のセルの特定の一つの状態を理解できるようになる。もし周囲のセルのまっ</nobr></div>
<div style="position:absolute;top:78088;left:128"><nobr>たく異なる状態を表現する、20 個の他のシナプスをその同じセグメントに追加したら</nobr></div>
<div style="position:absolute;top:78115;left:128"><nobr>何が起こるだろうか。するとそのセグメントは、あるパターンの 8 個のアクティブなシ</nobr></div>
<div style="position:absolute;top:78142;left:128"><nobr>ナプスと他のパターンの 7 個のアクティブなシナプスを持つことで間違ってアクティ</nobr></div>
<div style="position:absolute;top:78169;left:128"><nobr>ブになるかも知れないので、エラーが起こる可能性がもたらされる。我々は実験的に、</nobr></div>
<div style="position:absolute;top:78194;left:128"><nobr>20 個の異なるパターンまでならエラーなしで一つのセグメントに保存することができ</nobr></div>
<div style="position:absolute;top:78223;left:128"><nobr>ると分かった。従って十数個の樹状突起セグメントを持つ HTM セルは多くの異なる予</nobr></div>
<div style="position:absolute;top:78250;left:128"><nobr>測に関与することができる。 </nobr></div>
</span></font>

<div style="position:absolute;top:78419;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=63><b>Page 63</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:79601;left:437"><nobr><b>63</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:78614;left:128"><nobr>シナプス</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:78646;left:155"><nobr>HTM セルのシナプスは二値の重みを持つ。HTM モデルのシナプスの重みをスカラ</nobr></div>
<div style="position:absolute;top:78675;left:128"><nobr>ー値にすることを妨げるものは何もないが、疎分散パターンを用いることにより、我々</nobr></div>
<div style="position:absolute;top:78702;left:128"><nobr>は今のところスカラー値の重みを使う必要性がない。</nobr></div>
<div style="position:absolute;top:78729;left:155"><nobr>しかしながら、HTM セルは「永続値」というスカラー値を持ち、これを学習を通</nobr></div>
<div style="position:absolute;top:78756;left:128"><nobr>じて調整する。永続値 0.0 は有効でないシナプス候補を表し、それが有効なシナプスに</nobr></div>
<div style="position:absolute;top:78783;left:128"><nobr>至るまでまったく進展していないことを表す。しきい値（標準的には 0.2）を超える永</nobr></div>
<div style="position:absolute;top:78810;left:128"><nobr>続値は接続したばかりで容易に切断するシナプスを表す。高い永続値、例えば 0.9 は、</nobr></div>
<div style="position:absolute;top:78837;left:128"><nobr>接続状態でしかも容易には切断しないシナプスを表す。</nobr></div>
<div style="position:absolute;top:78862;left:155"><nobr>HTM セルの主要樹状突起セグメントや末梢樹状突起セグメントにある有効なシナ</nobr></div>
<div style="position:absolute;top:78891;left:128"><nobr>プスの数は固定ではない。それはセルがパターンに触れるに従って変化する。例えば、</nobr></div>
<div style="position:absolute;top:78918;left:128"><nobr>末梢樹状突起の有効なシナプスの数はデータの時間的構造に依存する。リージョンへの</nobr></div>
<div style="position:absolute;top:78945;left:128"><nobr>入力に時間的に永続的なパターンが何もないときは、末梢セグメントのすべてのシナプ</nobr></div>
<div style="position:absolute;top:78972;left:128"><nobr>スは低い永続値を持ち、わずかな数のシナプスだけが有効になるだろう。入力列にたく</nobr></div>
<div style="position:absolute;top:78999;left:128"><nobr>さんの時間的構造があるときは、高い永続値を持つ有効なシナプスが多数見られるだろ</nobr></div>
<div style="position:absolute;top:79026;left:128"><nobr>う。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:79094;left:128"><nobr>セル出力</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:79126;left:155"><nobr>HTM セルは 2 つの異なる二値出力を持つ： 1) セルがフィード・フォワード入力</nobr></div>
<div style="position:absolute;top:79155;left:128"><nobr>によって（主要樹状突起経由で）アクティブである、2) セルが横方向の接続により（末</nobr></div>
<div style="position:absolute;top:79182;left:128"><nobr>梢樹状突起経由で）アクティブである。前者を「アクティブ状態」と呼び、後者を「予</nobr></div>
<div style="position:absolute;top:79209;left:128"><nobr>測状態」と呼ぶ。</nobr></div>
<div style="position:absolute;top:79236;left:155"><nobr>冒頭の図では、この 2 つの出力は正方形の細胞体から出ている 2 つの線で表されて</nobr></div>
<div style="position:absolute;top:79263;left:128"><nobr>いる。左側の線はフィード・フォワードによるアクティブ状態、右側の線は予測状態で</nobr></div>
<div style="position:absolute;top:79290;left:128"><nobr>ある。</nobr></div>
<div style="position:absolute;top:79317;left:155"><nobr>フィード・フォワードによるアクティブ状態だけがリージョン内の他のセルに接続</nobr></div>
<div style="position:absolute;top:79344;left:128"><nobr>され、これにより予測は常に現在の入力（及び文脈）に基づいて行われる。予測に基づ</nobr></div>
<div style="position:absolute;top:79371;left:128"><nobr>いて予測が行われることは望ましくない。もしそうなると、数回処理を繰り返しただけ</nobr></div>
<div style="position:absolute;top:79398;left:128"><nobr>でリージョン内のほとんどすべてのセルが予測状態になるだろう。</nobr></div>
<div style="position:absolute;top:79425;left:155"><nobr>リージョンの出力はすべてのセルの状態を表すベクトルである。もし階層構造の次</nobr></div>
<div style="position:absolute;top:79452;left:128"><nobr>のリージョンがあるなら、このベクトルがその入力となる。この出力はアクティブ状態</nobr></div>
<div style="position:absolute;top:79479;left:128"><nobr>と予測状態の OR である。アクティブ状態と予測状態を結合することで、我々のリージ</nobr></div>
<div style="position:absolute;top:79506;left:128"><nobr>ョンの出力は入力よりも安定する（ゆっくりと変化する）。このような安定性はリージ</nobr></div>
<div style="position:absolute;top:79533;left:128"><nobr>ョンの推論における重要な特性である。 </nobr></div>
</span></font>

<div style="position:absolute;top:79681;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=64><b>Page 64</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:80863;left:437"><nobr><b>64</b></nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:79888;left:128"><nobr>参考文献</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:79937;left:155"><nobr>ニューロサイエンスをより深く学ぶための参考文献について我々はよく尋ねられる。</nobr></div>
<div style="position:absolute;top:79964;left:128"><nobr>ニューロサイエンスの分野はたいへん膨大で、全般的知識を得るには多くの異なる文献</nobr></div>
<div style="position:absolute;top:79991;left:128"><nobr>にあたらねばならない。新しい発見は学術ジャーナルとして出版されるが、読み解くの</nobr></div>
<div style="position:absolute;top:80018;left:128"><nobr>が難しく大学関係者でない限り入手も難しい。</nobr></div>
<div style="position:absolute;top:80045;left:155"><nobr>この付録で述べた話題に関してより専門的知識を得たい読者のために、入手可能な</nobr></div>
<div style="position:absolute;top:80072;left:128"><nobr>本を 2 冊示す。</nobr></div>
<div style="position:absolute;top:80129;left:191"><nobr>Stuart, Greg, Spruston, Nelson, Hausser, Michael, <i>Dendrites, second edition</i></nobr></div>
<div style="position:absolute;top:80156;left:191"><nobr>(New York: Oxford University Press, 2008) </nobr></div>
<div style="position:absolute;top:80207;left:155"><nobr>この本は樹状突起に関するあらゆることの良い情報源である。16 章では HTM 大脳</nobr></div>
<div style="position:absolute;top:80234;left:128"><nobr>皮質性学習アルゴリズムが用いている樹状突起セグメントの非線形な性質について述</nobr></div>
<div style="position:absolute;top:80261;left:128"><nobr>べられている。この章は、この分野で数多くの考察をした Bartlett Mel によって書か</nobr></div>
<div style="position:absolute;top:80288;left:128"><nobr>れている。</nobr></div>
<div style="position:absolute;top:80345;left:191"><nobr>Mountcastle, Vernon B. Perceptual Neuroscience: <i>The Cerebral Cortex</i></nobr></div>
<div style="position:absolute;top:80372;left:191"><nobr>(Cambridge, Mass.: Harvard University Press, 1998) </nobr></div>
<div style="position:absolute;top:80423;left:155"><nobr>この本は新皮質に関するあらゆることに関する良い入門書である。いくつかの章で</nobr></div>
<div style="position:absolute;top:80450;left:128"><nobr>は細胞の種類とその接続関係について述べている。樹状突起の性質に関する最新の知識</nobr></div>
<div style="position:absolute;top:80477;left:128"><nobr>を幅広く得るには古すぎるが、読者は皮質性ニューロンに関するすぐれた見識が得られ</nobr></div>
<div style="position:absolute;top:80504;left:128"><nobr>るだろう。 </nobr></div>
</span></font>

<div style="position:absolute;top:80943;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=65><b>Page 65</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:82125;left:437"><nobr><b>65</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:81154;left:128"><nobr>付録 <b>B: </b>新皮質の層と <b>HTM </b>リージョンの比較</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:81206;left:155"><nobr>ここでは HTM リージョンと生体新皮質のリージョンの間の関係について述べる。</nobr></div>
<div style="position:absolute;top:81233;left:155"><nobr>特に、HTM 大脳皮質性学習アルゴリズム、及びそのカラムとセルが、新皮質の層</nobr></div>
<div style="position:absolute;top:81260;left:128"><nobr>やカラム構造とどのような関係にあるかについて述べる。新皮質の「層」の概念やそれ</nobr></div>
<div style="position:absolute;top:81287;left:128"><nobr>が HTM の層とどう関係するのかについて、多くの人が困惑している。本稿がこの混乱</nobr></div>
<div style="position:absolute;top:81314;left:128"><nobr>を解決し、また HTM 大脳皮質性学習アルゴリズムの生物学的基礎に関して読者がより</nobr></div>
<div style="position:absolute;top:81341;left:128"><nobr>深い見識を得られれば幸いである。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:81421;left:128"><nobr>新皮質の神経回路網</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:81470;left:155"><nobr>人の新皮質は面積約 1,000cm<font style="font-size:8px">2</font>、厚さ 2mm のニューロンの皮である。この皮を視覚</nobr></div>
<div style="position:absolute;top:81497;left:128"><nobr>化するには、食事に使うナプキンの布と考えてみれば、新皮質の面積と厚さのちょうど</nobr></div>
<div style="position:absolute;top:81524;left:128"><nobr>良い近似になっている。新皮質は十数種類の機能的なリージョンに分かれていて、その</nobr></div>
<div style="position:absolute;top:81551;left:128"><nobr>いくつかは視覚に関係し、あるいは聴覚、言語などに関係している。顕微鏡で見ると、</nobr></div>
<div style="position:absolute;top:81578;left:128"><nobr>異なるリージョンの物理的な特徴は驚くほど良く似ている。</nobr></div>
<div style="position:absolute;top:81605;left:155"><nobr>新皮質全体を通じて各リージョンには器官原理<font style="font-size:8px">69</font>がいくつか見られる。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:82060;left:128"><nobr>69 <font style="font-size:12px">organizing principles。生体器官の働きの原理的しくみ。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:82205;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=66><b>Page 66</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:83387;left:437"><nobr><b>66</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:82967;left:128"><nobr>層</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:83001;left:155"><nobr>新皮質は一般に 6 つの層を持つと言われている。それらの層のうち 5 つはセルを持</nobr></div>
<div style="position:absolute;top:83028;left:128"><nobr>ち、1 つの層はほとんどが接続線である。層は染色技術の出現と共に 100 年以上前に発</nobr></div>
<div style="position:absolute;top:83055;left:128"><nobr>見された。上記の画像（Cajal による）は 3 種類の異なる染色法を用いて新皮質の小さ</nobr></div>
<div style="position:absolute;top:83082;left:128"><nobr>な断片を示したものである。垂直方向の軸索は約 2mm の新皮質の厚さ全体に及んでい</nobr></div>
<div style="position:absolute;top:83109;left:128"><nobr>る。画像の左側は 6 つの層を示している。最上部の第 1 層はセルがない層である。最下</nobr></div>
<div style="position:absolute;top:83136;left:128"><nobr>部の「WM」は白質が始まるところを示しており、セルからの軸索はそこから新皮質の</nobr></div>
<div style="position:absolute;top:83163;left:128"><nobr>他の部分や脳の他の部分へと伸びている。画像の右側は髄鞘を持つ軸索だけを示す染色</nobr></div>
<div style="position:absolute;top:83190;left:128"><nobr>法である。（髄鞘形成<font style="font-size:8px">70</font>とは一部の軸索を覆っている脂肪質の鞘<font style="font-size:8px">71</font>である。ただしすべ</nobr></div>
<div style="position:absolute;top:83217;left:128"><nobr>ての軸索を覆っているのではない）この部分の画像から新皮質の 2 つの主要な器官原理</nobr></div>
<div style="position:absolute;top:83244;left:128"><nobr>である、層とカラムを見ることができる。多くの軸索はニューロンの本体から出た直後</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:83302;left:128"><nobr>70 <font style="font-size:12px">myelination。ずいしょうけいせい。ミエリン化。</font></nobr></div>
<div style="position:absolute;top:83322;left:128"><nobr>71 <font style="font-size:12px">sheath。さや。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:83467;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=67><b>Page 67</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:84649;left:437"><nobr><b>67</b></nobr></div>
<div style="position:absolute;top:83621;left:128"><nobr>に 2 つに枝分かれする。枝の一つは主に水平に伸び、他の枝は主に垂直に伸びる。水平</nobr></div>
<div style="position:absolute;top:83648;left:128"><nobr>の方の枝は同じ層や近くの層の他のセルと多数の接続を成し、そのために染色でこのよ</nobr></div>
<div style="position:absolute;top:83675;left:128"><nobr>うに層が見られる。これは新皮質の断片を表していることを心に留めておいて欲しい。</nobr></div>
<div style="position:absolute;top:83702;left:128"><nobr>多くの軸索がこの画像で示された部分から出たり入ったりしているので、軸索は画像に</nobr></div>
<div style="position:absolute;top:83729;left:128"><nobr>見られるものよりも長い。新皮質の 1mm の立方体に含まれる軸索や樹状突起の総延長</nobr></div>
<div style="position:absolute;top:83756;left:128"><nobr>は 2km から 4km に及ぶと見積もられている。</nobr></div>
<div style="position:absolute;top:83783;left:155"><nobr>画像の中央部はニューロンの本体だけを示す染色法で、樹状突起や軸索は見えない。</nobr></div>
<div style="position:absolute;top:83810;left:128"><nobr>ニューロンの大きさや密度が層によって変化する様子を見ることができる。この画像で</nobr></div>
<div style="position:absolute;top:83837;left:128"><nobr>はカラムは少ししか分からない。第 1 層にいくつかのニューロンがあることに気づかれ</nobr></div>
<div style="position:absolute;top:83864;left:128"><nobr>たかも知れない。でも第 1 層のニューロンの数はあまりに少ないので、この層はやはり</nobr></div>
<div style="position:absolute;top:83891;left:128"><nobr>セルのない層と呼ばれている。ニューロ科学者は新皮質の 1mm の立方体ごとに約</nobr></div>
<div style="position:absolute;top:83916;left:128"><nobr>100,000 個程度のニューロンがあると見積もっている。</nobr></div>
<div style="position:absolute;top:83945;left:155"><nobr>画像の左側はほんのわずかな数のニューロンの本体、軸索、樹状突起だけを示す染</nobr></div>
<div style="position:absolute;top:83972;left:128"><nobr>色法である。異なる層や異なるセルごとに、樹状突起の「主軸」の大きさは異なってい</nobr></div>
<div style="position:absolute;top:83999;left:128"><nobr>る様子を見ることができる。いくつかの「先端樹状突起」<font style="font-size:8px">72</font>も見られ、それは細胞体か</nobr></div>
<div style="position:absolute;top:84026;left:128"><nobr>らそびえ立ち、他の層と接続している。先端樹状突起が存在するか否か、及びその接続</nobr></div>
<div style="position:absolute;top:84053;left:128"><nobr>先は各層ごとに特徴がある。</nobr></div>
<div style="position:absolute;top:84080;left:155"><nobr>まとめると、新皮質の層とカラム構造<font style="font-size:8px">73</font>はニューロンの皮が染色され顕微鏡で観察</nobr></div>
<div style="position:absolute;top:84107;left:128"><nobr>されることで明らかになった。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:84175;left:128"><nobr>リージョンの違いによる層のバリエーション</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:84209;left:155"><nobr>新皮質のリージョンの違いによって層の厚さにバリエーションがあり、層の数につ</nobr></div>
<div style="position:absolute;top:84236;left:128"><nobr>いても多少違う。このバリエーションはどの動物を研究するかに依存し、どのリージョ</nobr></div>
<div style="position:absolute;top:84263;left:128"><nobr>ンを観察するかにも依存し、また観察した人によっても違う。例えば上記の画像では、</nobr></div>
<div style="position:absolute;top:84290;left:128"><nobr>第 2 層と第 3 層は容易に識別できるが一般的にはそうではない。いくつかの科学者は彼</nobr></div>
<div style="position:absolute;top:84317;left:128"><nobr>らが研究したリージョンではこの 2 つの層を識別できないと報告しており、第 2 層と第</nobr></div>
<div style="position:absolute;top:84342;left:128"><nobr>3 層をまとめて「第 2/3 層」と呼ぶこともしばしばある。他の科学者は逆の方向に向か</nobr></div>
<div style="position:absolute;top:84371;left:128"><nobr>い、例えば 3A と 3B のようなサブレイヤを定義している。</nobr></div>
<div style="position:absolute;top:84398;left:155"><nobr>第 4 層は、新皮質のリージョンの中で感覚器官にもっとも近い部分で最もよく定義</nobr></div>
<div style="position:absolute;top:84425;left:128"><nobr>されている。いくつかの動物（例えばヒトやサル）では、第 1 視覚野の第 4 層は明確に</nobr></div>
<div style="position:absolute;top:84452;left:128"><nobr>細分化されている。他の動物ではそれは細分化されていない。第 4 層は感覚器官から遠</nobr></div>
<div style="position:absolute;top:84479;left:128"><nobr>いリージョンでは階層構造から消えて無くなっている。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:84565;left:128"><nobr>72 <font style="font-size:12px">apical dendrite</font></nobr></div>
<div style="position:absolute;top:84584;left:128"><nobr>73 <font style="font-size:12px">columnar organization。一般には柱状構造。他と統一するためカラム構造とした。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:84729;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=68><b>Page 68</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:85911;left:437"><nobr><b>68</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:84882;left:128"><nobr>カラム</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:84916;left:155"><nobr>新皮質の 2 つ目の主要な器官原理はカラムである。いくつかのカラム構造は染色さ</nobr></div>
<div style="position:absolute;top:84943;left:128"><nobr>れた画像にも見られるが、カラムに関する多くの証拠は異なる入力に対してセルがどの</nobr></div>
<div style="position:absolute;top:84970;left:128"><nobr>ように反応するかに基づいている。</nobr></div>
<div style="position:absolute;top:84997;left:155"><nobr>科学者が針を使って、何がニューロンをアクティブにするのかを見てみると、異な</nobr></div>
<div style="position:absolute;top:85024;left:128"><nobr>る層を横断する垂直方向に揃った複数のニューロンがだいたい同じ入力に反応するこ</nobr></div>
<div style="position:absolute;top:85051;left:128"><nobr>とを見つけた。</nobr></div>
<div style="position:absolute;top:85537;left:155"><nobr>この図は、網膜からの情報を処理する最初の皮質性リージョンである V1 の、セル</nobr></div>
<div style="position:absolute;top:85564;left:128"><nobr>のいくつかの応答特性を示している。</nobr></div>
<div style="position:absolute;top:85591;left:155"><nobr>最初の発見の一つは、V1 のほとんどのセルは網膜の特定の領域で、異なる角度の</nobr></div>
<div style="position:absolute;top:85618;left:128"><nobr>線や縁に反応するということであった。カラム状に垂直に配列された複数のセルすべて</nobr></div>
<div style="position:absolute;top:85645;left:128"><nobr>が、同じ角度の縁に反応する。図を注意深く見れば、各区画の最上部に異なる角度の小</nobr></div>
<div style="position:absolute;top:85672;left:128"><nobr>さな線が描かれていることが分かるだろう。これらの線はその場所のセルがどの角度の</nobr></div>
<div style="position:absolute;top:85699;left:128"><nobr>線に反応するかを示している。垂直に配列された複数のセル（うすい垂直の縞模様の一</nobr></div>
<div style="position:absolute;top:85726;left:128"><nobr>つに含まれる）は同じ角度の線に反応する。</nobr></div>
<div style="position:absolute;top:85751;left:155"><nobr>V1 にはいくつかの他のカラム型の特徴があり、そのうちの 2 つが図示されている。</nobr></div>
<div style="position:absolute;top:85780;left:128"><nobr>左目と右目の情報の似た組み合わせにセルが反応する「眼球優位性カラム」<font style="font-size:8px">74</font>がある。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:85846;left:128"><nobr>74 <font style="font-size:12px">ocular dominance column。片方の眼からの入力に強く反応するセルの集まり。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:85991;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=69><b>Page 69</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:87173;left:437"><nobr><b>69</b></nobr></div>
<div style="position:absolute;top:86145;left:128"><nobr>そしてセルが主に色を感知する「ブロブ」<font style="font-size:8px">75</font>がある。眼球優位性カラムは図の大きなブ</nobr></div>
<div style="position:absolute;top:86172;left:128"><nobr>ロックである。各眼球優位性カラムは角度のカラムを含む。「ブロブ」は濃い色の楕円</nobr></div>
<div style="position:absolute;top:86199;left:128"><nobr>である。</nobr></div>
<div style="position:absolute;top:86226;left:155"><nobr>新皮質の一般的な規則は、角度と眼球優位性のようにいくつかの異なる応答特性が</nobr></div>
<div style="position:absolute;top:86253;left:128"><nobr>互いに重ね合わさっているということである。皮質の表面を水平に移動してゆくに従っ</nobr></div>
<div style="position:absolute;top:86280;left:128"><nobr>て、セルから出力される応答特性の組み合わせは変化する。しかしながら、垂直に配列</nobr></div>
<div style="position:absolute;top:86307;left:128"><nobr>されたニューロンは同じ応答特性の組み合わせを共有している。聴覚・視覚・体性感覚</nobr></div>
<div style="position:absolute;top:86334;left:128"><nobr>野についてはこのような垂直の配列になっている。新皮質のあらゆる場所でそうなって</nobr></div>
<div style="position:absolute;top:86361;left:128"><nobr>いるのかについては科学者達の間でいくつかの議論があるが、全部ではなく多くの部分</nobr></div>
<div style="position:absolute;top:86388;left:128"><nobr>について言うならそれは正しいようである。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:86456;left:128"><nobr>ミニカラム</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:86490;left:155"><nobr>新皮質の最小のカラム構造はミニカラムである。ミニカラムは直径約 30μm で、セ</nobr></div>
<div style="position:absolute;top:86517;left:128"><nobr>ルを持つ 5 つの層全体に及ぶ 80-100 個のニューロンが含まれている。新皮質全体はミ</nobr></div>
<div style="position:absolute;top:86544;left:128"><nobr>ニカラムから構成されている。小さなスパゲッティのかけらを端同士を積み重ねたもの</nobr></div>
<div style="position:absolute;top:86571;left:128"><nobr>を思い浮かべるとよい。ミニカラムの間にはセルが少ししかないわずかなすきまがあり、</nobr></div>
<div style="position:absolute;top:86598;left:128"><nobr>染色された画像でそれを見ることができる。</nobr></div>
<div style="position:absolute;top:87003;left:155"><nobr>左側は新皮質の一部の断片に見られるニューロンの細胞体を示す染色画像である。</nobr></div>
<div style="position:absolute;top:87030;left:128"><nobr>ミニカラムの垂直の構造がこの画像から明白に分かる。右側はミニカラムの概念図であ</nobr></div>
<div style="position:absolute;top:87057;left:128"><nobr>る（Peters と Yilmez による）。実際にはこれよりずっと細い。カラムの中の各層に複</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:87108;left:128"><nobr>75 <font style="font-size:12px">blob。小塊、小球体。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:87253;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=70><b>Page 70</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:88435;left:437"><nobr><b>70</b></nobr></div>
<div style="position:absolute;top:87407;left:128"><nobr>数のニューロンがあることに注意してほしい。ミニカラムのすべてのニューロンが類似</nobr></div>
<div style="position:absolute;top:87434;left:128"><nobr>の入力に反応する。例えば、先ほど示した V1 の図では、ミニカラムは特定の眼球優位</nobr></div>
<div style="position:absolute;top:87461;left:128"><nobr>性を伴い、特定の角度の線に反応するセルを含んでいる。隣にあるミニカラムのセルは</nobr></div>
<div style="position:absolute;top:87488;left:128"><nobr>少し違う角度の線に反応し、違う眼球優位性を示すのかも知れない。</nobr></div>
<div style="position:absolute;top:87515;left:155"><nobr>抑制ニューロンがミニカラムを定義する本質的な役割を果たしている。それらは画</nobr></div>
<div style="position:absolute;top:87542;left:128"><nobr>像や図に示されていないが、抑制ニューロンはミニカラムの間のまっすぐな線に沿って</nobr></div>
<div style="position:absolute;top:87569;left:128"><nobr>軸索を送っており、ミニカラムの一部を物理的に分離している。抑制ニューロンはまた、</nobr></div>
<div style="position:absolute;top:87596;left:128"><nobr>ミニカラム中のニューロンが同じ入力に反応するよう強制することに役立っていると</nobr></div>
<div style="position:absolute;top:87623;left:128"><nobr>信じられている。</nobr></div>
<div style="position:absolute;top:87650;left:155"><nobr>ミニカラムは HTM 大脳皮質性学習アルゴリズムで用いられているカラムの原型で</nobr></div>
<div style="position:absolute;top:87677;left:128"><nobr>ある。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:87745;left:128"><nobr>カラム反応の例外</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:87779;left:155"><nobr>カラム反応の例外が一つあって、それは HTM 大脳皮質性学習アルゴリズムにも関</nobr></div>
<div style="position:absolute;top:87806;left:128"><nobr>係する。科学者は通常、実験動物に単純な刺激を与えることでセルが何に反応するのか</nobr></div>
<div style="position:absolute;top:87833;left:128"><nobr>を発見する。例えば、動物の視覚空間の小さな部分に 1 つの線を見せて、V1 のセルの</nobr></div>
<div style="position:absolute;top:87860;left:128"><nobr>応答特性を調べようとするかも知れない。単純な入力を用いると、科学者はセルが常に</nobr></div>
<div style="position:absolute;top:87887;left:128"><nobr>同じ入力に反応することを発見するかも知れない。しかしながら、もしその単純な入力</nobr></div>
<div style="position:absolute;top:87914;left:128"><nobr>が自然な場面の動画像に組み込まれたなら、セルはもっと選択的になる。あるセルが高</nobr></div>
<div style="position:absolute;top:87941;left:128"><nobr>い信頼性で独立した垂線に反応するとしても、その垂線が自然な場面の複雑な動画像に</nobr></div>
<div style="position:absolute;top:87968;left:128"><nobr>組み込まれた場合は必ずしも反応するとは限らない。</nobr></div>
<div style="position:absolute;top:87993;left:155"><nobr>HTM 大脳皮質性学習アルゴリズムではカラム中のすべての HTM セルが同じフィ</nobr></div>
<div style="position:absolute;top:88022;left:128"><nobr>ード・フォワード応答特性を共有しているが、時間的なシーケンスを学習すると HTM</nobr></div>
<div style="position:absolute;top:88049;left:128"><nobr>カラムの 1 つのセルだけがアクティブになる。このメカニズムは可変長シーケンスを表</nobr></div>
<div style="position:absolute;top:88076;left:128"><nobr>現する手段であり、ニューロンについて先ほど説明した特徴と似ている。文脈を伴わな</nobr></div>
<div style="position:absolute;top:88103;left:128"><nobr>い単純な入力はカラム中のすべてのセルをアクティブにする。同じ入力でも、学習した</nobr></div>
<div style="position:absolute;top:88130;left:128"><nobr>シーケンスに含まれるときは 1 つのセルだけがアクティブになる。ミニカラム中で一度</nobr></div>
<div style="position:absolute;top:88157;left:128"><nobr>に 1 つのニューロンだけがアクティブになると提唱しているわけではない。HTM 大脳</nobr></div>
<div style="position:absolute;top:88184;left:128"><nobr>皮質性学習アルゴリズムが提唱しているのは、予期しない入力に対してはカラム中のあ</nobr></div>
<div style="position:absolute;top:88211;left:128"><nobr>る層のすべてのニューロンがアクティブになり、予期した入力に対してはその一部のニ</nobr></div>
<div style="position:absolute;top:88238;left:128"><nobr>ューロンがアクティブになるということである。 </nobr></div>
</span></font>

<div style="position:absolute;top:88515;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=71><b>Page 71</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:89697;left:437"><nobr><b>71</b></nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:88681;left:128"><nobr>なぜ層とカラムがあるのか？</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:88729;left:155"><nobr>新皮質になぜ層があり、なぜカラムがあるのか、はっきりしたことは誰も知らない。</nobr></div>
<div style="position:absolute;top:88754;left:128"><nobr>HTM 大脳皮質性学習アルゴリズムは、カラム状に構成したセルの層が可変長の状態遷</nobr></div>
<div style="position:absolute;top:88783;left:128"><nobr>移を記憶する大容量メモリとなりうることを示した。もっと単純に言えば、セルの層は</nobr></div>
<div style="position:absolute;top:88810;left:128"><nobr>たくさんのシーケンスを学習できるということである。同じフィード・フォワード反応</nobr></div>
<div style="position:absolute;top:88837;left:128"><nobr>を共有するセルのカラムは可変長の遷移を学習するための鍵となるメカニズムである。</nobr></div>
<div style="position:absolute;top:88864;left:155"><nobr>この仮説はなぜカラムが必要なのかを説明しているが、しかし 5 つの層については</nobr></div>
<div style="position:absolute;top:88891;left:128"><nobr>どうだろうか？ もし 1 層の皮質でシーケンスを学習して予測できるのであれば、なぜ</nobr></div>
<div style="position:absolute;top:88918;left:128"><nobr>新皮質に 5 つの層が見られるのであろうか？</nobr></div>
<div style="position:absolute;top:88945;left:155"><nobr>我々が提唱するのは、新皮質に観察される異なる層はすべて同じ基本メカニズムを</nobr></div>
<div style="position:absolute;top:88972;left:128"><nobr>用いてシーケンスを学習しているが、各層で学習したシーケンスは異なる方法で使用さ</nobr></div>
<div style="position:absolute;top:88999;left:128"><nobr>れているのだろうというものである。これについて我々が理解していないことはたくさ</nobr></div>
<div style="position:absolute;top:89026;left:128"><nobr>んあるが、我々の一般的な考えを述べることはできる。その前に、各層のニューロンが</nobr></div>
<div style="position:absolute;top:89053;left:128"><nobr>何に接続しているのかを述べると理解の助けとなるだろう。</nobr></div>
<div style="position:absolute;top:89458;left:155"><nobr>上の図は 2 つの新皮質のリージョンとそれらの間の主要な接続関係を示している。</nobr></div>
<div style="position:absolute;top:89485;left:128"><nobr>このような接続は新皮質の中の互いに関係し合う 2 つのリージョンで一般によく見受</nobr></div>
<div style="position:absolute;top:89512;left:128"><nobr>けられる。左の箱は、右の（箱の）リージョンよりも低い階層構造にある皮質性のリー</nobr></div>
<div style="position:absolute;top:89539;left:128"><nobr>ジョンを表しているので、フィード・フォワード情報は図の左から右へと流れる。各リ</nobr></div>
<div style="position:absolute;top:89566;left:128"><nobr>ージョンは層に分けられている。第 2 層と第 3 層は一緒にして第 2/3 層として表されて</nobr></div>
<div style="position:absolute;top:89593;left:128"><nobr>いる。 </nobr></div>
</span></font>

<div style="position:absolute;top:89777;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=72><b>Page 72</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:90959;left:437"><nobr><b>72</b></nobr></div>
<div style="position:absolute;top:89931;left:155"><nobr>色のついた線は異なる層からのニューロンの出力を表している。これらはその層の</nobr></div>
<div style="position:absolute;top:89958;left:128"><nobr>ニューロンから出ている軸索の束である。軸索はすぐに 2 つに分かれることを思い出し</nobr></div>
<div style="position:absolute;top:89985;left:128"><nobr>て欲しい。一つの枝は主にそれと同じ層の中で、リージョン内で水平方向に広がる。よ</nobr></div>
<div style="position:absolute;top:90012;left:128"><nobr>って各層のすべてのセルは相互によく接続し合っている。ニューロンと水平方向の接続</nobr></div>
<div style="position:absolute;top:90039;left:128"><nobr>は図に示されていない。</nobr></div>
<div style="position:absolute;top:90064;left:155"><nobr>2 つのフィード・フォワード・パス<font style="font-size:8px">76</font>がある。オレンジ色で示した直接パスと、緑色</nobr></div>
<div style="position:absolute;top:90093;left:128"><nobr>で示した間接パスである。第 4 層は主要なフィード・フォワード入力層で、両方のフィ</nobr></div>
<div style="position:absolute;top:90120;left:128"><nobr>ード・フォワード・パスから入力を受け取る。第 4 層は第 3 層に向かう。</nobr></div>
<div style="position:absolute;top:90147;left:155"><nobr>第 3 層は直接フィード・フォワード・パスの始点でもある。よって、直接フィード・</nobr></div>
<div style="position:absolute;top:90174;left:128"><nobr>フォワード・パスは第 4 層と第 3 層に限定されている。</nobr></div>
<div style="position:absolute;top:90201;left:155"><nobr>いくつかのフィード・フォワード接続は第 4 層を飛ばして直接第 3 層に至る。そし</nobr></div>
<div style="position:absolute;top:90228;left:128"><nobr>て、上記で述べたように、第 4 層はセンサ入力から遠くにあるリージョンでは消えて無</nobr></div>
<div style="position:absolute;top:90255;left:128"><nobr>くなっている。そこでは直接フォワード・パスは単に第 3 層から次のリージョンの第 3</nobr></div>
<div style="position:absolute;top:90282;left:128"><nobr>層に繋がっている。</nobr></div>
<div style="position:absolute;top:90307;left:155"><nobr>2 つめのフィード・フォワード・パス（緑色で示した）は第 5 層から始まる。第 3</nobr></div>
<div style="position:absolute;top:90336;left:128"><nobr>層のセルは次のリージョンに至る道筋の中で第 5 層へと接続している。皮質性の皮から</nobr></div>
<div style="position:absolute;top:90363;left:128"><nobr>出発した後、第 5 層のセルからの軸索は再び枝分かれする。1 つの枝は運動の生成に関</nobr></div>
<div style="position:absolute;top:90390;left:128"><nobr>わる脳内の皮質下部<font style="font-size:8px">77</font>へと向かう。これらの軸索は運動指令（下方向の矢印で示した）</nobr></div>
<div style="position:absolute;top:90417;left:128"><nobr>であると信じられている。他の枝は脳内の視床<font style="font-size:8px">78</font>と呼ばれる門として働く部分へと向か</nobr></div>
<div style="position:absolute;top:90444;left:128"><nobr>う。視床は次のリージョンに情報を通したり止めたりする。</nobr></div>
<div style="position:absolute;top:90471;left:155"><nobr>最後に、黄色で示した主要フィードバック・パスが第 6 層から第 1 層に向かってい</nobr></div>
<div style="position:absolute;top:90498;left:128"><nobr>る。第 2, 3, 5 層のセルは先端樹状突起（図に示されていない）を経由して第 1 層に向</nobr></div>
<div style="position:absolute;top:90525;left:128"><nobr>かっている。第 6 層は第 5 層から入力を受け取る。</nobr></div>
<div style="position:absolute;top:90552;left:155"><nobr>この説明は層から層への接続に関して知られていることを限定的に概説したもので</nobr></div>
<div style="position:absolute;top:90579;left:128"><nobr>ある。しかし、すべての層がシーケンスを学習するのになぜ複数の層が存在するのかに</nobr></div>
<div style="position:absolute;top:90606;left:128"><nobr>ついての我々の仮説を理解するには十分であろう。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:90687;left:128"><nobr>異なる層が何をするのかに関する仮説</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:90735;left:155"><nobr>我々は第 3, 4, 5 層がすべてフィード・フォワード層でありシーケンスを学習してい</nobr></div>
<div style="position:absolute;top:90762;left:128"><nobr>ると提唱した。第 4 層は一次シーケンスを学習する。第 3 層は可変長シーケンスを学習</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:90855;left:128"><nobr>76 <font style="font-size:12px">pathway。通り道。</font></nobr></div>
<div style="position:absolute;top:90874;left:128"><nobr>77 <font style="font-size:12px">sub-cortical area。大脳皮質の下の神経中枢。</font></nobr></div>
<div style="position:absolute;top:90894;left:128"><nobr>78 <font style="font-size:12px">thalamus。ししょう。 </font></nobr></div>
</span></font>

<div style="position:absolute;top:91039;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=73><b>Page 73</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:92221;left:437"><nobr><b>73</b></nobr></div>
<div style="position:absolute;top:91193;left:128"><nobr>する。第 5 層はタイミングを含む可変長シーケンスを学習する。これらのそれぞれにつ</nobr></div>
<div style="position:absolute;top:91220;left:128"><nobr>いて、より詳しく見ていこう。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:15px;font-family:Times">
<div style="position:absolute;top:91273;left:128"><nobr>第<i><font style="font-size:14px">4</font></i>層</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:91299;left:155"><nobr>HTM 大脳皮質性学習アルゴリズムを用いて一次シーケンスを学習するのは容易で</nobr></div>
<div style="position:absolute;top:91328;left:128"><nobr>ある。もしカラム中のセルが互いに抑制するように強制しなかったとしたら、つまりカ</nobr></div>
<div style="position:absolute;top:91355;left:128"><nobr>ラム中のセルが以前の入力の文脈を区別しなかったとしたら、一次学習が起こる。新皮</nobr></div>
<div style="position:absolute;top:91382;left:128"><nobr>質では、同じカラム内のセルを抑制する効果を取り除くことで成されるだろう。我々の</nobr></div>
<div style="position:absolute;top:91409;left:128"><nobr>コンピュータモデルである HTM 大脳皮質性学習アルゴリズムでは、単にカラムごとに</nobr></div>
<div style="position:absolute;top:91434;left:128"><nobr>1 つのセルを割り当てることで同様の結果を生む。</nobr></div>
<div style="position:absolute;top:91463;left:155"><nobr>一次シーケンスは入力の空間的変形<font style="font-size:8px">79</font>を表す不変表現<font style="font-size:8px">80</font>を作る上で必要とされるも</nobr></div>
<div style="position:absolute;top:91490;left:128"><nobr>のである。例えば視覚では、x-y 変換、縮尺、回転はすべて空間的変形である。移動す</nobr></div>
<div style="position:absolute;top:91517;left:128"><nobr>る物体について、一次の記憶を持つ HTM リージョンを訓練すると、異なる空間的パタ</nobr></div>
<div style="position:absolute;top:91544;left:128"><nobr>ーンが同等であることを学習する。結果の HTM セルは「複雑型細胞」と呼ばれるもの</nobr></div>
<div style="position:absolute;top:91571;left:128"><nobr>のように振舞う。その HTM セルはある範囲の空間的変形に対してアクティブな状態</nobr></div>
<div style="position:absolute;top:91598;left:128"><nobr>（予測状態）を保つ。</nobr></div>
<div style="position:absolute;top:91623;left:155"><nobr>Numenta では、視覚についてこのメカニズムが期待通りに機能することを検証す</nobr></div>
<div style="position:absolute;top:91652;left:128"><nobr>る実験を行い、いくつかの空間的不変性が各レベルで達成された。これらの実験の詳細</nobr></div>
<div style="position:absolute;top:91679;left:128"><nobr>はこの付録の範囲を超える。</nobr></div>
<div style="position:absolute;top:91706;left:155"><nobr>第 4 層で一次シーケンスを学習していることは、第 4 層で複雑型細胞が見られるこ</nobr></div>
<div style="position:absolute;top:91733;left:128"><nobr>とや、なぜ新皮質の高階層のリージョンで第 4 層が消えて無くなるのかということと符</nobr></div>
<div style="position:absolute;top:91760;left:128"><nobr>合している。階層構造を上がるにつれて、その時点での表現はすでに不変のものになっ</nobr></div>
<div style="position:absolute;top:91787;left:128"><nobr>ているためそれ以上空間的不変性を学習することはできなくなる。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:15px;font-family:Times">
<div style="position:absolute;top:91840;left:128"><nobr>第<i><font style="font-size:14px">3</font></i>層</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:91868;left:155"><nobr>第 3 層は第 2 章で述べた HTM 大脳皮質性学習アルゴリズムに最も近い。それは可</nobr></div>
<div style="position:absolute;top:91895;left:128"><nobr>変シーケンスを学習し、予測を行い、その予測は入力よりも安定している。第 3 層は常</nobr></div>
<div style="position:absolute;top:91922;left:128"><nobr>に階層構造の次のリージョンに向かい、そのため階層構造の中で時間的安定性がより増</nobr></div>
<div style="position:absolute;top:91949;left:128"><nobr>加するようになる。可変シーケンス記憶は「方位選択性複雑型細胞」<font style="font-size:8px">81</font>と呼ばれるニュ</nobr></div>
<div style="position:absolute;top:91976;left:128"><nobr>ーロンに形成され、それは第 3 層で最初に観察された。方位選択性複雑型細胞は例えば</nobr></div>
<div style="position:absolute;top:92003;left:128"><nobr>左に動いている線と右に動いている線など、時間的文脈による識別をする。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:92122;left:128"><nobr>79 <font style="font-size:12px">spatial transformation</font></nobr></div>
<div style="position:absolute;top:92139;left:128"><nobr>80 <font style="font-size:12px">invariant representation</font></nobr></div>
<div style="position:absolute;top:92156;left:128"><nobr>81 <font style="font-size:12px">directionally-tuned complex cell </font></nobr></div>
</span></font>

<div style="position:absolute;top:92301;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=74><b>Page 74</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:93483;left:437"><nobr><b>74</b></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:15px;font-family:Times">
<div style="position:absolute;top:92454;left:128"><nobr>第<i><font style="font-size:14px">5</font></i>層</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:92482;left:155"><nobr>最後のフィード・フォワード層は第 5 層である。我々は第 5 層が第 3 層と似ている</nobr></div>
<div style="position:absolute;top:92509;left:128"><nobr>が 3 つの違いがあると提唱する。第一の違いは第 5 層が時間の概念を付加するというこ</nobr></div>
<div style="position:absolute;top:92536;left:128"><nobr>とである。第 3 層は次に「何」が起こるかを予測するが、それが「いつ」起こるかを教</nobr></div>
<div style="position:absolute;top:92563;left:128"><nobr>えてくれない。しかしながら、話し言葉を理解するときには音の間の相対的なタイミン</nobr></div>
<div style="position:absolute;top:92590;left:128"><nobr>グが重要であるように、多くのことでタイミングが必要となる。別の例として運動動作</nobr></div>
<div style="position:absolute;top:92617;left:128"><nobr>がある。筋肉の活性化のタイミングを揃えることは本質的である。我々は、第 5 層のニ</nobr></div>
<div style="position:absolute;top:92644;left:128"><nobr>ューロンが期待した時刻の後にだけ次の状態を予測すると提唱する。この仮説を裏付け</nobr></div>
<div style="position:absolute;top:92671;left:128"><nobr>る生物学上の詳細がいくつかある。一つは第 5 層が新皮質の運動出力層であるというこ</nobr></div>
<div style="position:absolute;top:92698;left:128"><nobr>とである。いま一つは第 5 層が視床の一部から発して第 1 層から来る入力（図に示され</nobr></div>
<div style="position:absolute;top:92725;left:128"><nobr>ていない）を受け取るということである。我々はまた、この情報こそが時間をコード化</nobr></div>
<div style="position:absolute;top:92752;left:128"><nobr>したものであり、視床を経由して第 1 層に入力される多くのセル（図に示されていない）</nobr></div>
<div style="position:absolute;top:92779;left:128"><nobr>にこの情報が分散されると提唱する。</nobr></div>
<div style="position:absolute;top:92806;left:155"><nobr>第 3 層と第 5 層の間の第二の違いは第 3 層が可能な限り未来を予測して時間的安定</nobr></div>
<div style="position:absolute;top:92833;left:128"><nobr>性をもたらすことが望ましいということである。第 2 章で述べた HTM 大脳皮質性学習</nobr></div>
<div style="position:absolute;top:92860;left:128"><nobr>アルゴリズムはこれを行う。対照的に、第 5 層については次の項目（ある特定の時点の）</nobr></div>
<div style="position:absolute;top:92887;left:128"><nobr>を予測することしか求めていない。我々はこの違いをモデル化していないが、遷移が常</nobr></div>
<div style="position:absolute;top:92914;left:128"><nobr>に時間を伴って保存されるならそれは自然に起こる。</nobr></div>
<div style="position:absolute;top:92941;left:155"><nobr>第 3 層と第 5 層の間の第三の違いは図から見て取れる。第 5 層の出力は常に皮質下</nobr></div>
<div style="position:absolute;top:92968;left:128"><nobr>部の運動中枢に向かい、そのフィード・フォワード・パスは視床の門を通る。第 5 層の</nobr></div>
<div style="position:absolute;top:92995;left:128"><nobr>出力は、あるときは次のリージョンへと通過し、またあるときは止められる。我々（及</nobr></div>
<div style="position:absolute;top:93022;left:128"><nobr>び他の人）はこの門の働きが潜在的注意<font style="font-size:8px">82</font>に関係すると提唱する（潜在的注意は運動行</nobr></div>
<div style="position:absolute;top:93049;left:128"><nobr>動を伴わずに貴方が入力に注目することである）。</nobr></div>
<div style="position:absolute;top:93076;left:155"><nobr>まとめると、第 5 層は特定のタイミング、注意、運動行動を結びつける。これらが</nobr></div>
<div style="position:absolute;top:93103;left:128"><nobr>互いにどのように関わりあうかについては多くの謎が残されている。我々が言いたいポ</nobr></div>
<div style="position:absolute;top:93130;left:128"><nobr>イントは、HTM 大脳皮質性学習アルゴリズムのバリエーションが特定のタイミングを</nobr></div>
<div style="position:absolute;top:93157;left:128"><nobr>容易に組み入れることができ、別々の皮質の層を結合することができるということであ</nobr></div>
<div style="position:absolute;top:93184;left:128"><nobr>る。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:15px;font-family:Times">
<div style="position:absolute;top:93237;left:128"><nobr>第<i><font style="font-size:14px">2</font></i>層と第<i><font style="font-size:14px">6</font></i>層</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:93265;left:155"><nobr>第 6 層は下位のリージョンへフィードバックする軸索の起点である。第 2 層につい</nobr></div>
<div style="position:absolute;top:93292;left:128"><nobr>てはほとんど知られていない。上で述べたように、第 2 層が第 3 層と比べてユニークな</nobr></div>
<div style="position:absolute;top:93319;left:128"><nobr>点があるかどうかですら、しばしば議論となっている。我々はいまのところこの質問に</nobr></div>
<div style="position:absolute;top:93346;left:128"><nobr>関してこれ以上言えることはほとんどないが、他のすべての層と同様に第 2 層と第 6</nobr></div>
<div style="position:absolute;top:93373;left:128"><nobr>層はたくさんの水平方向の接続パターンを持ち、カラム単位で反応する特徴があること</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:93418;left:128"><nobr>82 <font style="font-size:12px">covert attention </font></nobr></div>
</span></font>

<div style="position:absolute;top:93563;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=75><b>Page 75</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:94745;left:437"><nobr><b>75</b></nobr></div>
<div style="position:absolute;top:93717;left:128"><nobr>だけは指摘することができる。よって我々はこれらもまた、HTM 大脳皮質性学習アル</nobr></div>
<div style="position:absolute;top:93744;left:128"><nobr>ゴリズムの一形態を実行していると提唱する。</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:16px;font-family:Times">
<div style="position:absolute;top:93816;left:128"><nobr><b>HTM </b>リージョンは新皮質の何に相当するか？</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:93846;left:155"><nobr>我々は 2 種類の HTM 大脳皮質性学習アルゴリズムを実装した。一方は可変長記憶</nobr></div>
<div style="position:absolute;top:93873;left:128"><nobr>のためにカラムごとに複数のセルを持たせるもので、他方は一次記憶のためにカラムご</nobr></div>
<div style="position:absolute;top:93900;left:128"><nobr>とに単一のセルを持たせるものである。我々はこの 2 種類が新皮質の第 3 層と第 4 層</nobr></div>
<div style="position:absolute;top:93927;left:128"><nobr>に相当すると信じる。これら 2 種類を単一の HTM リージョンに結合することを我々は</nobr></div>
<div style="position:absolute;top:93954;left:128"><nobr>まだ試みていない。</nobr></div>
<div style="position:absolute;top:93979;left:155"><nobr>HTM 大脳皮質性学習アルゴリズム（カラムごとに複数のセルを持つ）が新皮質の</nobr></div>
<div style="position:absolute;top:94008;left:128"><nobr>第 3 層に最も近いものの、我々のモデルは脳にもない柔軟性を持っている。よって我々</nobr></div>
<div style="position:absolute;top:94035;left:128"><nobr>は新皮質のどの層にも相当しない複合型のセルを持つ層を創ることができる。例えば、</nobr></div>
<div style="position:absolute;top:94062;left:128"><nobr>我々のモデルでは樹状突起セグメント上でシナプスが形成される順序が分かる。我々は</nobr></div>
<div style="position:absolute;top:94089;left:128"><nobr>この情報を使って、将来起こることのすべてをより一般的に予測した上で次に何が起こ</nobr></div>
<div style="position:absolute;top:94116;left:128"><nobr>るかを予測することができる。我々は多分、同様にしてタイミング特有のことを追加で</nobr></div>
<div style="position:absolute;top:94143;left:128"><nobr>きるだろう。従って単一の層の HTM リージョンに第 3 層と第 5 層の機能を結合したも</nobr></div>
<div style="position:absolute;top:94170;left:128"><nobr>のを作ることが可能だろう。</nobr></div>
</span></font>
<font size=3 color="#548dd4" face="Times"><span style="font-size:19px;font-family:Times;color:#548dd4">
<div style="position:absolute;top:94251;left:128"><nobr>まとめ</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:94297;left:155"><nobr>HTM 大脳皮質性学習アルゴリズムは我々が新皮質の神経器官の基本構成要素と信</nobr></div>
<div style="position:absolute;top:94326;left:128"><nobr>じているものを具現化するものである。それは水平接続されたニューロンの層がどのよ</nobr></div>
<div style="position:absolute;top:94353;left:128"><nobr>うにして疎分散表現のシーケンスを学習するのかを示している。HTM 大脳皮質性学習</nobr></div>
<div style="position:absolute;top:94380;left:128"><nobr>アルゴリズムの各バリエーションが、互いに関連するが異なる目的を持つ、新皮質の異</nobr></div>
<div style="position:absolute;top:94407;left:128"><nobr>なる層で使われる。</nobr></div>
<div style="position:absolute;top:94434;left:155"><nobr>我々は新皮質リージョンへのフィード・フォワード入力は、第 4 層であれ第 3 層で</nobr></div>
<div style="position:absolute;top:94461;left:128"><nobr>あれ、主要樹状突起に主に入力されると提唱する。それは抑制セルの働きにより、入力</nobr></div>
<div style="position:absolute;top:94488;left:128"><nobr>の疎分散表現を作成する。我々はまた、第 2, 3, 4, 5, 6 層のセルがこの疎分散表現を共</nobr></div>
<div style="position:absolute;top:94515;left:128"><nobr>有していると提唱する。このことは、それらの層をまたがるカラム中のすべてのセルが</nobr></div>
<div style="position:absolute;top:94542;left:128"><nobr>同じフィード・フォワード入力に反応するように強制することによって達成される。</nobr></div>
<div style="position:absolute;top:94569;left:155"><nobr>我々は第 4 層のセルが、もしそれが存在するなら、HTM 大脳皮質性学習アルゴリ</nobr></div>
<div style="position:absolute;top:94596;left:128"><nobr>ズムを用いて一次の時間的遷移を学習すると提唱する。これは空間的遷移に対して不変</nobr></div>
<div style="position:absolute;top:94623;left:128"><nobr>の表現を構成する。第 3 層のセルは HTM 大脳皮質性学習アルゴリズムを用いて可変長</nobr></div>
<div style="position:absolute;top:94650;left:128"><nobr>の時間的遷移を学習し、皮質の階層を上っていって安定した表現を構成する。第 5 層の</nobr></div>
<div style="position:absolute;top:94677;left:128"><nobr>セルはタイミングを伴う可変長の遷移を学習する。第 2 層と第 6 層については特に提唱</nobr></div>
</span></font>

<div style="position:absolute;top:94825;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=76><b>Page 76</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:96007;left:437"><nobr><b>76</b></nobr></div>
<div style="position:absolute;top:94979;left:128"><nobr>するものはない。しかしながら、これらの層でよく見られる水平接続を考えると、何ら</nobr></div>
<div style="position:absolute;top:95006;left:128"><nobr>かの形でシーケンス記憶を学習していると考えられる。 </nobr></div>
</span></font>

<div style="position:absolute;top:96087;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=77><b>Page 77</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:97269;left:437"><nobr><b>77</b></nobr></div>
</span></font>
<font size=3 color="#365f91" face="Times"><span style="font-size:19px;font-family:Times;color:#365f91">
<div style="position:absolute;top:96298;left:128"><nobr>用語の説明</nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:96350;left:155"><nobr>ノート： ここでの定義はこの文書で使われている用語の意味であり、一般的な意味</nobr></div>
<div style="position:absolute;top:96377;left:128"><nobr>とは異なるものもある。説明文中で大文字で示されたもの<font style="font-size:8px">83</font>は、この用語説明で説明さ</nobr></div>
<div style="position:absolute;top:96404;left:128"><nobr>れていることを示す。</nobr></div>
<div style="position:absolute;top:96459;left:136"><nobr>アクティブ状態</nobr></div>
<div style="position:absolute;top:96486;left:136"><nobr>（Active State）</nobr></div>
<div style="position:absolute;top:96459;left:306"><nobr>フィード・フォワード（Feed-Forward）入力によってセル</nobr></div>
<div style="position:absolute;top:96486;left:306"><nobr>（Cells）がアクティブになった状態 </nobr></div>
<div style="position:absolute;top:96520;left:136"><nobr>ボトムアップ</nobr></div>
<div style="position:absolute;top:96547;left:136"><nobr>（Bottom-Up）<font style="font-size:8px">84</font></nobr></div>
<div style="position:absolute;top:96520;left:306"><nobr>フィード・フォワード（Feed-Forward）と同義語</nobr></div>
<div style="position:absolute;top:96575;left:136"><nobr>セル（Cells）</nobr></div>
<div style="position:absolute;top:96577;left:306"><nobr>HTMにおいて、ニューロン（Neuron）に対応するもの。セル</nobr></div>
<div style="position:absolute;top:96602;left:306"><nobr>（Cells）はHTMのリージョンにおいてカラムを構成する。</nobr></div>
<div style="position:absolute;top:96630;left:136"><nobr>同時発生アクティビ</nobr></div>
<div style="position:absolute;top:96657;left:136"><nobr>ティ（Coincident</nobr></div>
<div style="position:absolute;top:96686;left:136"><nobr>Activity）</nobr></div>
<div style="position:absolute;top:96630;left:306"><nobr>同時に2個又はそれ以上のセルがアクティブになること </nobr></div>
<div style="position:absolute;top:96711;left:136"><nobr>カラム（Column）</nobr></div>
<div style="position:absolute;top:96711;left:306"><nobr>１個又はそれ以上のセルのグループで、HTMリージョンの中</nobr></div>
<div style="position:absolute;top:96739;left:306"><nobr>で1単位として機能するもの。カラム中のセルは、同じフィー</nobr></div>
<div style="position:absolute;top:96766;left:306"><nobr>ド・フォワード入力の異なる文脈を表現する。</nobr></div>
<div style="position:absolute;top:96793;left:136"><nobr>樹状突起セグメント</nobr></div>
<div style="position:absolute;top:96820;left:136"><nobr>（Dendrite</nobr></div>
<div style="position:absolute;top:96850;left:136"><nobr>Segment）</nobr></div>
<div style="position:absolute;top:96793;left:306"><nobr>シナプスが集約した単位で、セルやカラムに結び付けられる。</nobr></div>
<div style="position:absolute;top:96823;left:306"><nobr>HTMには二つの異なるタイプの樹状突起セグメントがある。</nobr></div>
<div style="position:absolute;top:96847;left:306"><nobr>一つは、あるセルの横方向の接続に結び付けられる。樹状突</nobr></div>
<div style="position:absolute;top:96874;left:306"><nobr>起セグメントのアクティブなシナプスの数がしきい値を超え</nobr></div>
<div style="position:absolute;top:96901;left:306"><nobr>ると、結び付けられたセルが予測状態になる。もう一方は、</nobr></div>
<div style="position:absolute;top:96928;left:306"><nobr>あるカラムのフィード・フォワード接続に結び付けられる。</nobr></div>
<div style="position:absolute;top:96955;left:306"><nobr>あるカラムのアクティブなシナプスの数がしきい値を超える</nobr></div>
<div style="position:absolute;top:96982;left:306"><nobr>と、フィード・フォワードによるアクティブ状態になる。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:97165;left:128"><nobr>83 <font style="font-size:12px">用語説明では、例えば Cell の場合「セル（Cell）」のように示した。</font></nobr></div>
<div style="position:absolute;top:97184;left:128"><nobr>84 <font style="font-size:12px">原文では Bottom-Up と Feed-Forward の 2 種類の用語が現れるが、同様の意味であるとされている</font></nobr></div>
</span></font>
<font size=3 face="Times"><span style="font-size:12px;font-family:Times">
<div style="position:absolute;top:97205;left:141"><nobr>ため、常に「フィード・フォワード」と訳した。 </nobr></div>
</span></font>

<div style="position:absolute;top:97349;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=78><b>Page 78</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:98531;left:437"><nobr><b>78</b></nobr></div>
<div style="position:absolute;top:97504;left:136"><nobr>望ましい密度</nobr></div>
<div style="position:absolute;top:97531;left:136"><nobr>（Desired Density）</nobr></div>
<div style="position:absolute;top:97504;left:306"><nobr>リージョン（ Region ）へのフィード・フォワード</nobr></div>
<div style="position:absolute;top:97531;left:306"><nobr>（Feed-Forward）入力によってアクティブになるカラム</nobr></div>
<div style="position:absolute;top:97558;left:306"><nobr>（Column）の望ましいパーセンテージ。このパーセンテージ</nobr></div>
<div style="position:absolute;top:97585;left:306"><nobr>は、フィード・フォワード入力のファンアウト<font style="font-size:8px">85</font>に依存して変</nobr></div>
<div style="position:absolute;top:97612;left:306"><nobr>化する半径<font style="font-size:8px">86</font>内にのみ適用される。パーセンテージは個別の入</nobr></div>
<div style="position:absolute;top:97639;left:306"><nobr>力に応じて変化するものなのでここでは「望ましい」と呼ん</nobr></div>
<div style="position:absolute;top:97666;left:306"><nobr>でいる。</nobr></div>
<div style="position:absolute;top:97694;left:136"><nobr>フィード・フォワー</nobr></div>
<div style="position:absolute;top:97721;left:136"><nobr>ド（Feed-Forward）</nobr></div>
<div style="position:absolute;top:97694;left:306"><nobr>階層構造（Hierarchy）の中で、入力が低いレベル（Level）か</nobr></div>
<div style="position:absolute;top:97721;left:306"><nobr>ら高いレベル（Level）に向かって移動すること（しばしば、</nobr></div>
<div style="position:absolute;top:97750;left:306"><nobr>Bottom-Upと呼ぶ） </nobr></div>
<div style="position:absolute;top:97780;left:136"><nobr>フィードバック</nobr></div>
<div style="position:absolute;top:97807;left:136"><nobr>（Feedback）</nobr></div>
<div style="position:absolute;top:97780;left:306"><nobr>階層構造（Hierarchy）の中で、高いレベル（Level）から低い</nobr></div>
<div style="position:absolute;top:97807;left:306"><nobr>レベル（Level）に向かって移動すること（しばしば、Top-Down</nobr></div>
<div style="position:absolute;top:97834;left:306"><nobr>と呼ぶ）</nobr></div>
<div style="position:absolute;top:97862;left:136"><nobr>一次予測（First Order</nobr></div>
<div style="position:absolute;top:97891;left:136"><nobr>Prediction）</nobr></div>
<div style="position:absolute;top:97862;left:306"><nobr>過去の入力には無関係に、現在の入力だけに依存して予測す</nobr></div>
<div style="position:absolute;top:97889;left:306"><nobr>ること。可変長予測（Variable Order Prediction）参照。</nobr></div>
<div style="position:absolute;top:97923;left:136"><nobr>HTM（Hierarchical</nobr></div>
<div style="position:absolute;top:97950;left:136"><nobr>Temporal Memory）</nobr></div>
<div style="position:absolute;top:97921;left:306"><nobr>新皮質の構造的・アルゴリズム的機能のいくつかを模写する</nobr></div>
<div style="position:absolute;top:97948;left:306"><nobr>技術</nobr></div>
<div style="position:absolute;top:97980;left:136"><nobr>階層構造（Hierarchy）　要素間の接続がフィード・フォワード（Feed-Forward）ない</nobr></div>
<div style="position:absolute;top:98007;left:306"><nobr>しフィードバック（Feedback）によってユニークに識別され</nobr></div>
<div style="position:absolute;top:98034;left:306"><nobr>るネットワーク </nobr></div>
<div style="position:absolute;top:98064;left:136"><nobr>HTM大脳皮質性学習</nobr></div>
<div style="position:absolute;top:98089;left:136"><nobr>アルゴリズム（HTM</nobr></div>
<div style="position:absolute;top:98118;left:136"><nobr>Cortical Learning</nobr></div>
<div style="position:absolute;top:98145;left:136"><nobr>Algorithms）</nobr></div>
<div style="position:absolute;top:98062;left:306"><nobr>空間プーリング（Spatial Pooling）、時間プーリング（Temporal</nobr></div>
<div style="position:absolute;top:98091;left:306"><nobr>Pooling）、学習と忘却を行う関数一式。HTMリージョン（HTM</nobr></div>
<div style="position:absolute;top:98118;left:306"><nobr>Region）を構成する。またの名をHTM学習アルゴリズム（HTM</nobr></div>
<div style="position:absolute;top:98145;left:306"><nobr>Learning Algorithms）と言う。</nobr></div>
<div style="position:absolute;top:98173;left:136"><nobr>HTMネットワーク</nobr></div>
<div style="position:absolute;top:98198;left:136"><nobr>（HTM Network）</nobr></div>
<div style="position:absolute;top:98173;left:306"><nobr>HTMリージョン（HTM Region）の階層構造（Hierarchy）</nobr></div>
<div style="position:absolute;top:98228;left:136"><nobr>HTMリージョン</nobr></div>
<div style="position:absolute;top:98253;left:136"><nobr>（HTM Region）</nobr></div>
<div style="position:absolute;top:98228;left:306"><nobr>HTMにおいて、記憶と予測（Prediction）を行う主要構成要素。</nobr></div>
<div style="position:absolute;top:98255;left:306"><nobr>HTMリージョン（HTM Region）は、カラムの中に配置された</nobr></div>
<div style="position:absolute;top:98280;left:306"><nobr>高度に相互接続された層からなる。現状のHTMリージョン</nobr></div>
<div style="position:absolute;top:98307;left:306"><nobr>（HTM Region）は一層のセルからなるが、新皮質では（そし</nobr></div>
<div style="position:absolute;top:98334;left:306"><nobr>て完璧なHTMでは）リージョンは複数のセルの層からなる。</nobr></div>
<div style="position:absolute;top:98361;left:306"><nobr>階層構造の中の位置という文脈で呼ばれるとき、リージョン</nobr></div>
<div style="position:absolute;top:98388;left:306"><nobr>はレベルと呼ばれることがある。</nobr></div>
</span></font>
<font size=2 face="Times"><span style="font-size:7px;font-family:Times">
<div style="position:absolute;top:98448;left:128"><nobr>85 <font style="font-size:12px">fan-out。広がり具合</font></nobr></div>
<div style="position:absolute;top:98466;left:128"><nobr>86 <font style="font-size:12px">radius </font></nobr></div>
</span></font>

<div style="position:absolute;top:98611;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=79><b>Page 79</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:99793;left:437"><nobr><b>79</b></nobr></div>
<div style="position:absolute;top:98766;left:136"><nobr>推論（Inference）</nobr></div>
<div style="position:absolute;top:98766;left:306"><nobr>空間的ないし時間的入力パターンが、以前に学習したパター</nobr></div>
<div style="position:absolute;top:98793;left:306"><nobr>ンと似ていると認識すること </nobr></div>
<div style="position:absolute;top:98833;left:136"><nobr>抑制半径（Inhibition</nobr></div>
<div style="position:absolute;top:98862;left:136"><nobr>Radius）</nobr></div>
<div style="position:absolute;top:98833;left:306"><nobr>カラム（Column）の周囲の領域で、その範囲でアクティブな</nobr></div>
<div style="position:absolute;top:98860;left:306"><nobr>カラムが抑制をする範囲を定義する </nobr></div>
<div style="position:absolute;top:98897;left:136"><nobr>横方向の接続</nobr></div>
<div style="position:absolute;top:98924;left:136"><nobr>（Lateral</nobr></div>
<div style="position:absolute;top:98953;left:136"><nobr>Connections）</nobr></div>
<div style="position:absolute;top:98897;left:306"><nobr>同じリージョン内でのセル（Cells）間の接続関係</nobr></div>
<div style="position:absolute;top:98978;left:136"><nobr>レベル（Level）</nobr></div>
<div style="position:absolute;top:98978;left:306"><nobr>階層構造（Hierarchy）の中の HTMリージョン（HTM Region）</nobr></div>
<div style="position:absolute;top:99024;left:136"><nobr>ニューロン（Neuron）　脳内で情報処理を行うセル（Cells）。本書では、特に生物学</nobr></div>
<div style="position:absolute;top:99051;left:306"><nobr>的な意味でセルを示すときにニューロンという用語を用い、</nobr></div>
<div style="position:absolute;top:99078;left:306"><nobr>単にセルと表記したときはHTMの計算単位を意味する。 </nobr></div>
<div style="position:absolute;top:99105;left:136"><nobr>永続値</nobr></div>
<div style="position:absolute;top:99132;left:136"><nobr>（Permanence）</nobr></div>
<div style="position:absolute;top:99105;left:306"><nobr>シナプス候補（Potential Synapse）の接続状態を表すスカラ</nobr></div>
<div style="position:absolute;top:99132;left:306"><nobr>ー値。永続値がしきい値を下回るときシナプスは形成されて</nobr></div>
<div style="position:absolute;top:99159;left:306"><nobr>いないことを表す。永続値がしきい値を超えていたら、その</nobr></div>
<div style="position:absolute;top:99186;left:306"><nobr>シナプスは有効である。HTMリージョン（HTM Region）の学</nobr></div>
<div style="position:absolute;top:99213;left:306"><nobr>習はシナプス候補（Potential Synapse）の永続値を変更する</nobr></div>
<div style="position:absolute;top:99240;left:306"><nobr>ことで達成される。 </nobr></div>
<div style="position:absolute;top:99268;left:136"><nobr>シナプス候補</nobr></div>
<div style="position:absolute;top:99295;left:136"><nobr>（Potential</nobr></div>
<div style="position:absolute;top:99324;left:136"><nobr>Synapse）</nobr></div>
<div style="position:absolute;top:99268;left:306"><nobr>ある樹状突起セグメント（Dendrite Segment）でシナプスを</nobr></div>
<div style="position:absolute;top:99295;left:306"><nobr>形成する可能性があるセル（Cells）の部分集合。ある時刻に</nobr></div>
<div style="position:absolute;top:99322;left:306"><nobr>おいては、シナプス候補の一部分だけが、有効なシナプスと</nobr></div>
<div style="position:absolute;top:99349;left:306"><nobr>なる。有効なシナプスは永続値に基づいて決まる。</nobr></div>
<div style="position:absolute;top:99377;left:136"><nobr>予測（Prediction）</nobr></div>
<div style="position:absolute;top:99377;left:306"><nobr>フィード・フォワード（Feed-Forward）入力によって、セル</nobr></div>
<div style="position:absolute;top:99404;left:306"><nobr>（Cells）が近い将来アクティブになるであろうということを、</nobr></div>
<div style="position:absolute;top:99431;left:306"><nobr>（予測状態の）アクティブ化によって示すこと。HTMリージ</nobr></div>
<div style="position:absolute;top:99458;left:306"><nobr>ョン（HTM Region）はしばしば、将来起こりうる入力を同時</nobr></div>
<div style="position:absolute;top:99485;left:306"><nobr>に多数予測する。</nobr></div>
<div style="position:absolute;top:99513;left:136"><nobr>受容野（Receptive</nobr></div>
<div style="position:absolute;top:99542;left:136"><nobr>Field）</nobr></div>
<div style="position:absolute;top:99513;left:306"><nobr>カラム（Column）ないしセル（Cells）が接続されている入力</nobr></div>
<div style="position:absolute;top:99540;left:306"><nobr>の集合。HTMリージョン（HTM Region）への入力がビットの</nobr></div>
<div style="position:absolute;top:99569;left:306"><nobr>2D配列で構成されていとき、受容野は入力空間内のある半径</nobr></div>
<div style="position:absolute;top:99594;left:306"><nobr>範囲で表現することができる。</nobr></div>
<div style="position:absolute;top:99621;left:136"><nobr>センサー（Sensor） HTMネットワーク（HTM Network）への入力源</nobr></div>
<div style="position:absolute;top:99649;left:136"><nobr>疎分散表現</nobr></div>
<div style="position:absolute;top:99676;left:136"><nobr>（Sparse Distributed</nobr></div>
<div style="position:absolute;top:99706;left:136"><nobr>Representation）</nobr></div>
<div style="position:absolute;top:99649;left:306"><nobr>多くのビットで構成され、そのうちのわずかなパーセンテー</nobr></div>
<div style="position:absolute;top:99676;left:306"><nobr>ジだけがアクティブであり、単一のビットだけでは意味を表</nobr></div>
<div style="position:absolute;top:99703;left:306"><nobr>現するには不十分であるような表現。  </nobr></div>
</span></font>

<div style="position:absolute;top:99873;left:0"><hr><table border=0 width=100%><tr><td bgcolor=eeeeee align=right><font face=arial,sans-serif><a name=80><b>Page 80</b></a></font></td></tr></table></div><font size=3 face="Times"><span style="font-size:14px;font-family:Times">
<div style="position:absolute;top:101055;left:437"><nobr><b>80</b></nobr></div>
<div style="position:absolute;top:100028;left:136"><nobr>空間プーリング</nobr></div>
<div style="position:absolute;top:100055;left:136"><nobr>（Spatial Pooling）</nobr></div>
<div style="position:absolute;top:100028;left:306"><nobr>入力に対して疎分散表現を計算する処理。空間プーリングの</nobr></div>
<div style="position:absolute;top:100055;left:306"><nobr>一つの特徴は、オーバラップする入力パターンを同じ疎分散</nobr></div>
<div style="position:absolute;top:100082;left:306"><nobr>表現に対応付けられることである。</nobr></div>
<div style="position:absolute;top:100110;left:136"><nobr>サブサンプリング</nobr></div>
<div style="position:absolute;top:100137;left:136"><nobr>（Sub-Sampling）</nobr></div>
<div style="position:absolute;top:100110;left:306"><nobr>大きなパターンのうちのほんのわずかなアクティブビットを</nobr></div>
<div style="position:absolute;top:100137;left:306"><nobr>マッチングするだけで、大きな分散パターンを認識すること </nobr></div>
<div style="position:absolute;top:100164;left:136"><nobr>シナプス（Synapse）　学習によって形成されるセル（Cells）間の接続 </nobr></div>
<div style="position:absolute;top:100192;left:136"><nobr>時間プーリング</nobr></div>
<div style="position:absolute;top:100219;left:136"><nobr>（Temporal Pooling）</nobr></div>
<div style="position:absolute;top:100192;left:306"><nobr>入力パターンのシーケンスの表現を計算する処理。結果の表</nobr></div>
<div style="position:absolute;top:100219;left:306"><nobr>現は入力よりも安定したものになる。</nobr></div>
<div style="position:absolute;top:100262;left:136"><nobr>トップダウン</nobr></div>
<div style="position:absolute;top:100289;left:136"><nobr>（Top-Down）</nobr></div>
<div style="position:absolute;top:100262;left:306"><nobr>フィードバック（Feedback）の同義語</nobr></div>
<div style="position:absolute;top:100317;left:136"><nobr>可変長予測（Variable</nobr></div>
<div style="position:absolute;top:100346;left:136"><nobr>Order Prediction）</nobr></div>
<div style="position:absolute;top:100317;left:306"><nobr>それが依存する直前の文脈の量が変化するような予測。一次</nobr></div>
<div style="position:absolute;top:100344;left:306"><nobr>予測（First Order Prediction）参照。</nobr></div>
<div style="position:absolute;top:100371;left:306"><nobr>直前の文脈を維持管理するためのメモリを必要に応じて割り</nobr></div>
<div style="position:absolute;top:100398;left:306"><nobr>当てるため、「可変長」と呼ばれる。そのため可変長予測を</nobr></div>
<div style="position:absolute;top:100425;left:306"><nobr>実装するメモリシステムは、指数関数的に増大するメモリを</nobr></div>
<div style="position:absolute;top:100452;left:306"><nobr>必要とすることなく、文脈を時間的に後戻りすることができ</nobr></div>
<div style="position:absolute;top:100479;left:306"><nobr>る。 </nobr></div>
</span></font>
</body>
</html>
